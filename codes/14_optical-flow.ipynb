{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('../temp/videos')\n",
    "output_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_neighbour_flows(flow: np.ndarray, window_size: int = 4) -> np.ndarray:\n",
    "\n",
    "    # a single frame\n",
    "    if flow.ndim == 3:\n",
    "        new_shape = (1, flow.shape[0] // window_size, flow.shape[1] // window_size, 2)\n",
    "\n",
    "    # multiple frames\n",
    "    elif flow.ndim == 4:\n",
    "        new_shape = (flow.shape[0], flow.shape[1] // window_size, flow.shape[2] // window_size, 2)\n",
    "\n",
    "    new_flow = np.zeros(new_shape, dtype=flow.dtype)\n",
    "\n",
    "    # down sample flow\n",
    "    for i in range(0, flow.shape[1], window_size):\n",
    "        for j in range(0, flow.shape[2], window_size):\n",
    "            new_flow[:, i // window_size, j // window_size] = np.mean(flow[:, i:i+window_size, j:j+window_size], axis=(1, 2))\n",
    "\n",
    "    return new_flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"https://media.xiph.org/video/derf/y4m/tt_sif.y4m\")\n",
    "\n",
    "fps = round(cap.get(cv2.CAP_PROP_FPS))\n",
    "frames = []\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        frames.append(frame)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video.shape: (112, 240, 352, 3)\n",
      "video.dtype: uint8\n",
      "type(video): <class 'numpy.ndarray'>\n",
      "frame per second (fps): 30\n"
     ]
    }
   ],
   "source": [
    "# color space: BGR\n",
    "frames = np.array(frames)\n",
    "\n",
    "# log\n",
    "print(f\"video.shape: {frames.shape}\")\n",
    "print(f\"video.dtype: {frames.dtype}\")\n",
    "print(f\"type(video): {type(frames)}\")\n",
    "print(f\"frame per second (fps): {fps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_frames = np.array([cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) for frame in frames])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Optical FLow](https://www.mathworks.com/discovery/optical-flow.html)\n",
    "- Definition\n",
    "   - It refers to the apparent motion of objects, surfaces, and edges in a visual scene caused by the relative motion between an observer (camera) and the scene.\n",
    "- Classic methods:\n",
    "   - [Lucas-Kanade](https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323)\n",
    "   - [Farneback](https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga5d10ebbd59fe09c5f650289ec0ece5af)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Optical Flow using Farneback method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows = np.zeros(shape=(frames.shape[0] - 1, frames.shape[1], frames.shape[2], 2), dtype=np.float32)\n",
    "\n",
    "for i in range(len(frames) - 1):\n",
    "    flows[i] = cv2.calcOpticalFlowFarneback(\n",
    "        prev=gray_frames[i],\n",
    "        next=gray_frames[i + 1],\n",
    "        flow=None,\n",
    "        pyr_scale=.5,\n",
    "        levels=3,\n",
    "        winsize=7,\n",
    "        iterations=3,\n",
    "        poly_n=7,\n",
    "        poly_sigma=1.5,\n",
    "        flags=0\n",
    "    )\n",
    "\n",
    "\n",
    "window_size = 8\n",
    "grouped_flows = group_neighbour_flows(flows, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "start_frame = 0\n",
    "fig = plt.figure(figsize=(16, 8), constrained_layout=True)\n",
    "gs = fig.add_gridspec(2, 2)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.imshow(cv2.cvtColor(frames[start_frame], cv2.COLOR_BGR2RGB))\n",
    "ax1.set_title(f\"frame: {start_frame}\")\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "ax2.imshow(cv2.cvtColor(frames[start_frame], cv2.COLOR_BGR2RGB))\n",
    "ax2.set_title(f\"frame: {start_frame + 1}\")\n",
    "ax2.axis('off')\n",
    "\n",
    "x, y = np.meshgrid(range(grouped_flows.shape[2]), range(grouped_flows.shape[1]))\n",
    "ax3 = fig.add_subplot(gs[:, 1])\n",
    "ax3.quiver(x, y, grouped_flows[start_frame, :, :, 0], grouped_flows[start_frame, :, :, 1], angles='xy', scale_units='xy', scale=1, color='k')\n",
    "ax3.set_title(f\"motion: {start_frame} -> {start_frame+1}\")\n",
    "ax3.invert_yaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(16, 8), layout='tight')\n",
    "gs = gridspec.GridSpec(nrows=2, ncols=2, width_ratios=[1, 2])\n",
    "\n",
    "ax0 = plt.subplot(gs[0, 0])\n",
    "ax1 = plt.subplot(gs[1, 0])\n",
    "ax2 = plt.subplot(gs[:, 1])\n",
    "\n",
    "# create a grid of x, y coordinates\n",
    "height, width = grouped_flows.shape[1:3]\n",
    "x, y = np.meshgrid(range(width), range(height))\n",
    "\n",
    "\n",
    "# updates the figure frame by frame\n",
    "def update(i):\n",
    "    for ax in fig.axes:\n",
    "        ax.cla()\n",
    "        ax.axis('off')\n",
    "\n",
    "    ax0.imshow(cv2.cvtColor(frames[i], cv2.COLOR_BGR2RGB))\n",
    "    ax0.set(title=f\"frame: {i + 1}\")\n",
    "\n",
    "    ax1.imshow(cv2.cvtColor(frames[i + 1], cv2.COLOR_BGR2RGB))\n",
    "    ax1.set(title=f\"frame: {i + 2}\")\n",
    "\n",
    "    ax2.quiver(x, y, grouped_flows[i, :, :, 0], grouped_flows[i, :, :, 1], angles='xy', scale_units='xy', scale=1, color='k')\n",
    "    ax2.invert_yaxis()\n",
    "    ax2.set(title=f\"frame {i + 1}\")\n",
    "\n",
    "\n",
    "# create an animation\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(frames) - 1)\n",
    "\n",
    "# save the animation as a video file\n",
    "ani.save(filename=f\"{output_path}/optical_flow_1.mp4\", writer='ffmpeg', fps=fps // 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Optical Flow using Lucas-Kanade method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
