{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_path = Path('../output/videos')\n",
        "output_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def group_neighbour_flows(flow: np.ndarray, window_size: int = 4) -> np.ndarray:\n",
        "\n",
        "    # a single frame\n",
        "    if flow.ndim == 3:\n",
        "        new_shape = (1, flow.shape[0] // window_size, flow.shape[1] // window_size, 2)\n",
        "\n",
        "    # multiple frames\n",
        "    elif flow.ndim == 4:\n",
        "        new_shape = (flow.shape[0], flow.shape[1] // window_size, flow.shape[2] // window_size, 2)\n",
        "\n",
        "    new_flow = np.zeros(new_shape, dtype=flow.dtype)\n",
        "\n",
        "    # down sample flow\n",
        "    for i in range(0, flow.shape[1], window_size):\n",
        "        for j in range(0, flow.shape[2], window_size):\n",
        "            new_flow[:, i // window_size, j // window_size] = np.mean(flow[:, i:i+window_size, j:j+window_size], axis=(1, 2))\n",
        "\n",
        "    return new_flow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load a video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(\"https://media.xiph.org/video/derf/y4m/tt_sif.y4m\")\n",
        "\n",
        "fps = round(cap.get(cv2.CAP_PROP_FPS))\n",
        "frames = []\n",
        "\n",
        "while (cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if ret == True:\n",
        "        frames.append(frame)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "video.shape: (112, 240, 352, 3)\n",
            "video.dtype: uint8\n",
            "type(video): <class 'numpy.ndarray'>\n",
            "frame per second (fps): 30\n"
          ]
        }
      ],
      "source": [
        "# color space: BGR\n",
        "frames = np.array(frames)\n",
        "\n",
        "# log\n",
        "print(f\"video.shape: {frames.shape}\")\n",
        "print(f\"video.dtype: {frames.dtype}\")\n",
        "print(f\"type(video): {type(frames)}\")\n",
        "print(f\"frame per second (fps): {fps}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "gray_frames = np.array([cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) for frame in frames])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# [Optical FLow](https://www.mathworks.com/discovery/optical-flow.html)\n",
        "- Definition\n",
        "   - It refers to the apparent motion of objects, surfaces, and edges in a visual scene caused by the relative motion between an observer (camera) and the scene.\n",
        "- Classic methods:\n",
        "   - [Lucas-Kanade](https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323)\n",
        "   - [Farneback](https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga5d10ebbd59fe09c5f650289ec0ece5af)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dense Optical Flow using Farneback method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "flows = np.zeros(shape=(frames.shape[0] - 1, frames.shape[1], frames.shape[2], 2), dtype=np.float32)\n",
        "\n",
        "for i in range(len(frames) - 1):\n",
        "    flows[i] = cv2.calcOpticalFlowFarneback(\n",
        "        prev=gray_frames[i],\n",
        "        next=gray_frames[i + 1],\n",
        "        flow=None,\n",
        "        pyr_scale=.5,\n",
        "        levels=3,\n",
        "        winsize=7,\n",
        "        iterations=3,\n",
        "        poly_n=7,\n",
        "        poly_sigma=1.5,\n",
        "        flags=0\n",
        "    )\n",
        "\n",
        "\n",
        "window_size = 8\n",
        "grouped_flows = group_neighbour_flows(flows, window_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot\n",
        "start_frame = 0\n",
        "fig = plt.figure(figsize=(16, 8), constrained_layout=True)\n",
        "gs = fig.add_gridspec(2, 2)\n",
        "\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "ax1.imshow(cv2.cvtColor(frames[start_frame], cv2.COLOR_BGR2RGB))\n",
        "ax1.set_title(f\"frame: {start_frame}\")\n",
        "ax1.axis('off')\n",
        "\n",
        "ax2 = fig.add_subplot(gs[1, 0])\n",
        "ax2.imshow(cv2.cvtColor(frames[start_frame], cv2.COLOR_BGR2RGB))\n",
        "ax2.set_title(f\"frame: {start_frame + 1}\")\n",
        "ax2.axis('off')\n",
        "\n",
        "x, y = np.meshgrid(range(grouped_flows.shape[2]), range(grouped_flows.shape[1]))\n",
        "ax3 = fig.add_subplot(gs[:, 1])\n",
        "ax3.quiver(x, y, grouped_flows[start_frame, :, :, 0], grouped_flows[start_frame, :, :, 1], angles='xy', scale_units='xy', scale=1, color='k')\n",
        "ax3.set_title(f\"motion: {start_frame} -> {start_frame+1}\")\n",
        "ax3.invert_yaxis()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(figsize=(16, 8), layout='tight')\n",
        "gs = gridspec.GridSpec(nrows=2, ncols=2, width_ratios=[1, 2])\n",
        "\n",
        "ax0 = plt.subplot(gs[0, 0])\n",
        "ax1 = plt.subplot(gs[1, 0])\n",
        "ax2 = plt.subplot(gs[:, 1])\n",
        "\n",
        "# create a grid of x, y coordinates\n",
        "height, width = grouped_flows.shape[1:3]\n",
        "x, y = np.meshgrid(range(width), range(height))\n",
        "\n",
        "\n",
        "# updates the figure frame by frame\n",
        "def update(i):\n",
        "    for ax in fig.axes:\n",
        "        ax.cla()\n",
        "        ax.axis('off')\n",
        "\n",
        "    ax0.imshow(cv2.cvtColor(frames[i], cv2.COLOR_BGR2RGB))\n",
        "    ax0.set(title=f\"frame: {i + 1}\")\n",
        "\n",
        "    ax1.imshow(cv2.cvtColor(frames[i + 1], cv2.COLOR_BGR2RGB))\n",
        "    ax1.set(title=f\"frame: {i + 2}\")\n",
        "\n",
        "    ax2.quiver(x, y, grouped_flows[i, :, :, 0], grouped_flows[i, :, :, 1], angles='xy', scale_units='xy', scale=1, color='k')\n",
        "    ax2.invert_yaxis()\n",
        "    ax2.set(title=f\"frame {i + 1}\")\n",
        "\n",
        "\n",
        "# create an animation\n",
        "ani = animation.FuncAnimation(fig, update, frames=len(frames) - 1)\n",
        "\n",
        "# save the animation as a video file\n",
        "ani.save(filename=f\"{output_path}/optical_flow_1.mp4\", writer='ffmpeg', fps=fps // 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sparse Optical Flow using Lucas-Kanade method"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "author_name": "Amirhossein Heydari",
    "author_email": "AmirhosseinHeydari78@gmail.com",
    "author_github": "https://github.com/mr-pylin",
    "origin_repo": "https://github.com/mr-pylin/media-processing-workshop"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}