{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üìù **Author:** Amirhossein Heydari - üìß **Email:** <amirhosseinheydari78@gmail.com> - üìç **Origin:** [mr-pylin/media-processing-workshop](https://github.com/mr-pylin/media-processing-workshop)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Table of contents**<a id='toc0_'></a>    \n",
        "- [Dependencies](#toc1_)    \n",
        "- [Load Images](#toc2_)    \n",
        "- [Image Enhancement](#toc3_)    \n",
        "  - [Spatial Domain: Intensity Transformation](#toc3_1_)    \n",
        "    - [Negative Transform](#toc3_1_1_)    \n",
        "      - [Manual](#toc3_1_1_1_)    \n",
        "      - [Using OpenCV](#toc3_1_1_2_)    \n",
        "      - [Using PIL](#toc3_1_1_3_)    \n",
        "    - [Logarithm Transform](#toc3_1_2_)    \n",
        "      - [Manual](#toc3_1_2_1_)    \n",
        "    - [Power-Law (Gamma) Transform](#toc3_1_3_)    \n",
        "      - [Manual](#toc3_1_3_1_)    \n",
        "    - [Piecewise-Linear Transform](#toc3_1_4_)    \n",
        "      - [Manual](#toc3_1_4_1_)    \n",
        "\n",
        "<!-- vscode-jupyter-toc-config\n",
        "\tnumbering=false\n",
        "\tanchor=true\n",
        "\tflat=false\n",
        "\tminLevel=1\n",
        "\tmaxLevel=6\n",
        "\t/vscode-jupyter-toc-config -->\n",
        "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc1_'></a>[Dependencies](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc2_'></a>[Load Images](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "im_1 = cv2.imread(\"../assets/images/dip_3rd/CH03_Fig0354(a)(einstein_orig).tif\", flags=cv2.IMREAD_GRAYSCALE)\n",
        "im_2 = cv2.imread(\"../assets/images/dip_3rd/CH03_Fig0309(a)(washed_out_aerial_image).tif\", flags=cv2.IMREAD_GRAYSCALE)\n",
        "im_3 = cv2.cvtColor(\n",
        "    cv2.imread(\"../assets/images/dip_3rd/CH06_Fig0638(a)(lenna_RGB).tif\"),\n",
        "    cv2.COLOR_BGR2RGB,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_1 = Image.fromarray(im_1)\n",
        "img_2 = Image.fromarray(im_2)\n",
        "img_3 = Image.fromarray(im_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot\n",
        "fig, axs = plt.subplots(1, 3, figsize=(12, 4), layout=\"constrained\")\n",
        "images = [im_1, im_2, im_3]\n",
        "titles = [\n",
        "    \"CH03_Fig0354(a)(einstein_orig).tif\",\n",
        "    \"CH03_Fig0309(a)(washed_out_aerial_image).tif\",\n",
        "    \"CH06_Fig0638(a)(lenna_RGB).tif\",\n",
        "]\n",
        "for ax, img, title in zip(axs, images, titles):\n",
        "    ax.imshow(img, vmin=0, vmax=255, cmap=\"gray\" if img.ndim == 2 else None)\n",
        "    ax.set_title(title)\n",
        "    ax.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc3_'></a>[Image Enhancement](#toc0_)\n",
        "\n",
        "Image enhancement is the procedure of improving the quality for a specific purpose!\n",
        "\n",
        "- Spatial Domain\n",
        "  - **Intensity Transformation**\n",
        "  - Histogram Processing\n",
        "  - Spatial Filtering\n",
        "- Frequency Domain\n",
        "  - Fourier Transform\n",
        "  - Cosine Transform\n",
        "- Spatial-Frequency Domain\n",
        "  - Wavelet Transform (Multi-resolution Analysis)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_1_'></a>[Spatial Domain: Intensity Transformation](#toc0_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_1_1_'></a>[Negative Transform](#toc0_)\n",
        "\n",
        "- It is an intensity transformation technique where each pixel's intensity value is inverted.\n",
        "- Often making previously dark details more perceptible due to human vision characteristics.\n",
        "\n",
        "$$s = (L - 1) - r$$\n",
        "\n",
        "üìù **Docs**:\n",
        "\n",
        "- `numpy.iinfo`: [numpy.org/doc/stable/reference/generated/numpy.iinfo.html](https://numpy.org/doc/stable/reference/generated/numpy.iinfo.html)\n",
        "- `cv2.bitwise_not`: [docs.opencv.org/master/d2/de8/group__core__array.html#ga0002cf8b418479f4cb49a75442baee2f](https://docs.opencv.org/master/d2/de8/group__core__array.html#ga0002cf8b418479f4cb49a75442baee2f)\n",
        "- `PIL.ImageOps.invert`: [pillow.readthedocs.io/en/stable/reference/ImageOps.html#PIL.ImageOps.invert](https://pillow.readthedocs.io/en/stable/reference/ImageOps.html#PIL.ImageOps.invert)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc3_1_1_1_'></a>[Manual](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "im_1_negative = (2 ** np.iinfo(im_1.dtype).bits - 1) - im_1\n",
        "im_2_negative = (2 ** np.iinfo(im_2.dtype).bits - 1) - im_2\n",
        "im_3_negative = (2 ** np.iinfo(im_3.dtype).bits - 1) - im_3\n",
        "\n",
        "# plot\n",
        "fig, axs = plt.subplots(2, 3, figsize=(12, 8), layout=\"constrained\")\n",
        "images = [[im_1, im_2, im_3], [im_1_negative, im_2_negative, im_3_negative]]\n",
        "titles = [[\"Original\", \"Original\", \"Original\"], [\"Negative\", \"Negative\", \"Negative\"]]\n",
        "for i in range(2):\n",
        "    for j in range(3):\n",
        "        axs[i, j].imshow(images[i][j], vmin=0, vmax=255, cmap=\"gray\" if images[i][j].ndim == 2 else None)\n",
        "        axs[i, j].set(title=titles[i][j], xticks=[], yticks=[])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc3_1_1_2_'></a>[Using OpenCV](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "im_1_negative = cv2.bitwise_not(im_1)\n",
        "im_2_negative = cv2.bitwise_not(im_2)\n",
        "im_3_negative = cv2.bitwise_not(im_3)\n",
        "\n",
        "# plot\n",
        "fig, axs = plt.subplots(2, 3, figsize=(12, 8), layout=\"constrained\")\n",
        "images = [[im_1, im_2, im_3], [im_1_negative, im_2_negative, im_3_negative]]\n",
        "titles = [[\"Original\", \"Original\", \"Original\"], [\"Negative\", \"Negative\", \"Negative\"]]\n",
        "for i in range(2):\n",
        "    for j in range(3):\n",
        "        axs[i, j].imshow(images[i][j], vmin=0, vmax=255, cmap=\"gray\" if images[i][j].ndim == 2 else None)\n",
        "        axs[i, j].set(title=titles[i][j], xticks=[], yticks=[])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc3_1_1_3_'></a>[Using PIL](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "im_1_negative = ImageOps.invert(img_1)\n",
        "im_2_negative = ImageOps.invert(img_2)\n",
        "im_3_negative = ImageOps.invert(img_3)\n",
        "\n",
        "# plot\n",
        "fig, axs = plt.subplots(2, 3, figsize=(12, 8), layout=\"constrained\")\n",
        "images = [[im_1, im_2, im_3], [im_1_negative, im_2_negative, im_3_negative]]\n",
        "titles = [\"Original\", \"Negative\"]\n",
        "for i in range(2):\n",
        "    for j in range(3):\n",
        "        axs[i, j].imshow(images[i][j], cmap=\"gray\", vmin=0, vmax=255)\n",
        "        axs[i, j].set(title=titles[i], xticks=[], yticks=[])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_1_2_'></a>[Logarithm Transform](#toc0_)\n",
        "\n",
        "- It's a **nonlinear** transformation particularly for **compressing** high-intensity values and **expanding** low-intensity values.\n",
        "- This makes them useful in applications where details in **darker regions** need to be **enhanced** while **preventing bright regions** from dominating the image.\n",
        "- Avoid normalizing to `[0,1]` **before** applying logarithm because it **weakens** the transformation.\n",
        "\n",
        "$$s = c \\cdot ln(1 + r)$$\n",
        "\n",
        "- $c$ is a scaling constant, typically chosen as : $\\frac{255}{ln(1 + 255)}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc3_1_2_1_'></a>[Manual](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "im_2_fft_abs = np.abs(np.fft.fftshift(np.fft.fft2(im_2)))\n",
        "\n",
        "# log\n",
        "print(f\"im_2_fft_abs.dtype              : {im_2_fft_abs.dtype}\")\n",
        "print(f\"im_2_fft_abs.min()              : {im_2_fft_abs.min()}\")\n",
        "print(f\"im_2_fft_abs.max()              : {im_2_fft_abs.max()}\")\n",
        "print(f\"np.quantile(im_2_fft_abs, 0.25) : {np.quantile(im_2_fft_abs, 0.25)}\")\n",
        "print(f\"np.quantile(im_2_fft_abs, 0.5)  : {np.quantile(im_2_fft_abs, 0.5)}\")\n",
        "print(f\"np.quantile(im_2_fft_abs, 0.75) : {np.quantile(im_2_fft_abs, 0.75)}\")\n",
        "print(f\"np.quantile(im_2_fft_abs, 0.99) : {np.quantile(im_2_fft_abs, 0.99)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "im_1_log = np.log1p(im_1)\n",
        "im_2_log = np.log1p(im_2) * 20\n",
        "im_3_log = np.log1p(im_3) * 40\n",
        "im_2_fft_abs_log = np.log1p(im_2_fft_abs)\n",
        "\n",
        "# normalize to [0, 255]\n",
        "im_1_log = (im_1_log / im_1_log.max()) * 255\n",
        "im_2_log = (im_2_log / im_2_log.max()) * 255\n",
        "im_3_log = (im_3_log / im_3_log.max()) * 255\n",
        "im_2_fft_abs_log = (im_2_fft_abs_log / im_2_fft_abs_log.max()) * 255\n",
        "\n",
        "# convert to uint8\n",
        "im_1_log = im_1_log.astype(np.uint8)\n",
        "im_2_log = im_2_log.astype(np.uint8)\n",
        "im_3_log = im_3_log.astype(np.uint8)\n",
        "im_2_fft_abs_log = im_2_fft_abs_log.astype(np.uint8)\n",
        "\n",
        "# plot\n",
        "fig, axs = plt.subplots(2, 4, figsize=(16, 8), layout=\"constrained\")\n",
        "images = [[im_1, im_2, im_3, im_2_fft_abs], [im_1_log, im_2_log, im_3_log, im_2_fft_abs_log]]\n",
        "titles = [\"Original\", \"Logarithm\"]\n",
        "for i, row in enumerate(images):\n",
        "    for j, img in enumerate(row):\n",
        "        axs[i, j].imshow(img, cmap=\"gray\" if j != 2 else None)\n",
        "        axs[i, j].set(title=titles[i], xticks=[], yticks=[])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_1_3_'></a>[Power-Law (Gamma) Transform](#toc0_)\n",
        "\n",
        "- It is a **nonlinear** intensity transformation used for **contrast enhancement** when facing an **underexposed** or **overexposed** image.\n",
        "- First rescale the image to the range `[0,1]` before applying the transformation.\n",
        "\n",
        "**Effect of Gamma Value:**\n",
        "\n",
        "- 0 < $\\gamma$ < 1 (Enhances dark regions)\n",
        "  - Expands **low-intensity** values while compressing **high-intensity** values (useful for **brightening** dark images).\n",
        "- $\\gamma$ > 1 (Enhances bright regions)\n",
        "  - Expands **high-intensity** values while compressing **low-intensity** values (useful for **darkening** bright images).\n",
        "\n",
        "$$s = c \\cdot r^\\gamma$$\n",
        "\n",
        "- To keep the output within `[0,255]`, $c$ is usually set as: $\\frac{255}{255^\\gamma}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc3_1_3_1_'></a>[Manual](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# normalize images to range [0, 1]\n",
        "im_1_norm = im_1 / 255.0\n",
        "im_2_norm = im_2 / 255.0\n",
        "im_3_norm = im_3 / 255.0\n",
        "\n",
        "# power-law\n",
        "im_1_power_1 = np.clip((im_1_norm**0.5 * 255), 0, 255).astype(np.uint8)\n",
        "im_1_power_2 = np.clip((im_1_norm**1.5 * 255), 0, 255).astype(np.uint8)\n",
        "im_2_power_1 = np.clip((im_2_norm**0.5 * 255), 0, 255).astype(np.uint8)\n",
        "im_2_power_2 = np.clip((im_2_norm**3 * 255), 0, 255).astype(np.uint8)\n",
        "im_3_power_1 = np.clip((im_3_norm**0.5 * 255), 0, 255).astype(np.uint8)\n",
        "im_3_power_2 = np.clip((im_3_norm**2 * 255), 0, 255).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot\n",
        "fig, axs = plt.subplots(3, 3, figsize=(10, 10), layout=\"constrained\")\n",
        "images = [\n",
        "    [im_1, im_1_power_1, im_1_power_2],\n",
        "    [im_2, im_2_power_1, im_2_power_2],\n",
        "    [im_3, im_3_power_1, im_3_power_2],\n",
        "]\n",
        "titles = [[\"Original\", \"p=0.5\", \"p=1.5\"], [\"Original\", \"p=0.5\", \"p=3\"], [\"Original\", \"p=0.5\", \"p=2\"]]\n",
        "for i, row in enumerate(images):\n",
        "    for j, img in enumerate(row):\n",
        "        axs[i, j].imshow(img, cmap=\"gray\" if i < 2 else None, vmin=0, vmax=255)\n",
        "        axs[i, j].set(title=titles[i][j], xticks=[], yticks=[])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_1_4_'></a>[Piecewise-Linear Transform](#toc0_)\n",
        "\n",
        "- A class of intensity transformations where the image's pixel values are mapped through a **series of linear segments**.\n",
        "- Useful for enhancing **specific ranges** of intensities while leaving others **unchanged**.\n",
        "\n",
        "$$\n",
        "T(r) =\n",
        "\\begin{cases}\n",
        "a_1 r + b_1, & \\text{if } r \\in [0, r_1] \\\\\n",
        "a_2 r + b_2, & \\text{if } r \\in [r_1, r_2] \\\\\n",
        "a_3 r + b_3, & \\text{if } r \\in [r_2, 255]\n",
        "\\end{cases}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc3_1_4_1_'></a>[Manual](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# image binarization (quantization)\n",
        "im_1_bin = im_1.copy()\n",
        "im_1_bin[im_1 < 140] = 0\n",
        "im_1_bin[im_1 >= 140] = 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# contrast stretching\n",
        "im_1_stretch = im_1.copy()\n",
        "im_1_stretch[im_1 < 50] = 0\n",
        "im_1_stretch[im_1 > 200] = 255\n",
        "\n",
        "roi = np.bitwise_and(im_1_stretch >= 50, im_1_stretch <= 200)\n",
        "roi_min = np.min(im_1_stretch[roi])\n",
        "roi_max = np.max(im_1_stretch[roi])\n",
        "\n",
        "im_1_stretch[roi] = ((im_1_stretch[roi] - roi_min) / (roi_max - roi_min)) * 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# advanced power-law [piecewise nonlinear transform]\n",
        "im_1_pow = im_1.copy() / 255.0\n",
        "arr_ct_4_copy = im_1_pow.copy()\n",
        "im_1_pow[arr_ct_4_copy < 0.5] = im_1_pow[arr_ct_4_copy < 0.5] ** 1.3\n",
        "im_1_pow[arr_ct_4_copy >= 0.5] = im_1_pow[arr_ct_4_copy >= 0.5] ** 0.7\n",
        "im_1_pow = np.clip(im_1_pow * 255, 0, 255).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot\n",
        "fig, axs = plt.subplots(1, 4, figsize=(12, 5), layout=\"constrained\")\n",
        "images = [im_1, im_1_bin, im_1_stretch, im_1_pow]\n",
        "titles = [\"Original\", \"Image binarization\", \"Contrast stretching\", \"Power-law transform\"]\n",
        "for ax, img, title in zip(axs, images, titles):\n",
        "    ax.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
        "    ax.set(title=title, xticks=[], yticks=[])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "author_email": "AmirhosseinHeydari78@gmail.com",
    "author_github": "https://github.com/mr-pylin",
    "author_name": "Amirhossein Heydari",
    "kernelspec": {
      "display_name": "media-processing-workshop-9l4de3Xu-py3.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "origin_repo": "https://github.com/mr-pylin/media-processing-workshop"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
