{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
    "    <div style=\"text-align: left; flex: 4;\">\n",
    "        <strong>Author:</strong> Amirhossein Heydari ‚Äî \n",
    "        üìß <a href=\"mailto:amirhosseinheydari78@gmail.com\">amirhosseinheydari78@gmail.com</a> ‚Äî \n",
    "        üêô <a href=\"https://github.com/mr-pylin/media-processing-workshop\" target=\"_blank\" rel=\"noopener\">github.com/mr-pylin</a>\n",
    "    </div>\n",
    "    <div style=\"display: flex; justify-content: flex-end; flex: 1; gap: 8px; align-items: center; padding: 0;\">\n",
    "        <a href=\"https://opencv.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/libraries/opencv/logo/OpenCV_logo_no_text-1.svg\"\n",
    "                 alt=\"OpenCV Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "        <a href=\"https://pillow.readthedocs.io/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/libraries/pillow/logo/pillow-logo-248x250.png\"\n",
    "                 alt=\"PIL Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "        <a href=\"https://scikit-image.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/libraries/scikit-image/logo/logo.png\"\n",
    "                 alt=\"scikit-image Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "        <a href=\"https://scipy.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/libraries/scipy/logo/logo.svg\"\n",
    "                 alt=\"SciPy Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "    </div>\n",
    "</div>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Dependencies](#toc1_)    \n",
    "- [Load Images](#toc2_)    \n",
    "  - [Image Degradation](#toc2_1_)    \n",
    "- [Spatial Domain: Spatial Filtering](#toc3_)    \n",
    "  - [Linear Filters](#toc3_1_)    \n",
    "    - [Smoothing (Low-Pass) Filters](#toc3_1_1_)    \n",
    "      - [Averaging Filter](#toc3_1_1_1_)    \n",
    "        - [Using OpenCV](#toc3_1_1_1_1_)    \n",
    "        - [Using Scipy](#toc3_1_1_1_2_)    \n",
    "      - [Convolution Boundary Handling](#toc3_1_1_2_)    \n",
    "      - [Gaussian Filter](#toc3_1_1_3_)    \n",
    "        - [Manual](#toc3_1_1_3_1_)    \n",
    "        - [Using OpenCV](#toc3_1_1_3_2_)    \n",
    "        - [Using SciPy](#toc3_1_1_3_3_)    \n",
    "    - [Sharpening (High Pass) Filters](#toc3_1_2_)    \n",
    "      - [Laplacian Filter](#toc3_1_2_1_)    \n",
    "      - [Unsharp Masking](#toc3_1_2_2_)    \n",
    "      - [High-Boost Filtering](#toc3_1_2_3_)    \n",
    "    - [Edge Detection Filters](#toc3_1_3_)    \n",
    "      - [First-Order Derivative Filters](#toc3_1_3_1_)    \n",
    "        - [Roberts](#toc3_1_3_1_1_)    \n",
    "        - [Prewitt](#toc3_1_3_1_2_)    \n",
    "        - [Sobel](#toc3_1_3_1_3_)    \n",
    "        - [Scharr](#toc3_1_3_1_4_)    \n",
    "      - [Second-Order Derivative Filters](#toc3_1_3_2_)    \n",
    "        - [Laplacian Operator (D4)](#toc3_1_3_2_1_)    \n",
    "        - [Laplacian with Diagonals (D8)](#toc3_1_3_2_2_)    \n",
    "        - [Laplacian of Gaussian (LoG)](#toc3_1_3_2_3_)    \n",
    "        - [Difference of Gaussian (DoG)](#toc3_1_3_2_4_)    \n",
    "  - [Nonlinear Filters](#toc3_2_)    \n",
    "    - [Order-Statistic Filters](#toc3_2_1_)    \n",
    "      - [Median Filter](#toc3_2_1_1_)    \n",
    "        - [Manual](#toc3_2_1_1_1_)    \n",
    "        - [Using OpenCV](#toc3_2_1_1_2_)    \n",
    "      - [Maximum and Minimum Filters](#toc3_2_1_2_)    \n",
    "        - [Using OpenCV](#toc3_2_1_2_1_)    \n",
    "      - [Percentile Filters](#toc3_2_1_3_)    \n",
    "    - [Bilateral Filter](#toc3_2_2_)    \n",
    "    - [Marr-Hildreth Edge Detector](#toc3_2_3_)    \n",
    "    - [Canny Edge Detector](#toc3_2_4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Dependencies](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from numpy.typing import NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable automatic figure display (plt.show() required)  \n",
    "# this ensures consistency with .py scripts and gives full control over when plots appear\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set NumPy arrays to print wider lines (120 chars)\n",
    "np.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a reproducible random number generator\n",
    "rng = np.random.default_rng(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Load Images](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_1 = cv2.imread(\"../assets/images/dip_3rd/CH02_Fig0222(b)(cameraman).tif\", cv2.IMREAD_GRAYSCALE)\n",
    "im_2 = cv2.imread(\"../assets/images/dip_3rd/CH06_Fig0638(a)(lenna_RGB).tif\", cv2.IMREAD_COLOR_RGB)\n",
    "\n",
    "# plot\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 4), layout=\"compressed\")\n",
    "axs[0].imshow(im_1, vmin=0, vmax=255, cmap=\"gray\")\n",
    "axs[0].set_title(\"CH02_Fig0222(b)(cameraman).tif\")\n",
    "axs[1].imshow(im_2, vmin=0, vmax=255)\n",
    "axs[1].set_title(\"CH06_Fig0638(a)(lenna_RGB).tif\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Image Degradation](#toc0_)\n",
    "\n",
    "- Check out the [**image-degredation.ipynb**](./utils/image-degredation.ipynb) notebook for more information on the topic of degredation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gaussian_noise(img: NDArray, mean: float = 0, std: float = 25) -> NDArray[np.uint8]:\n",
    "    gaussian_noise = rng.normal(loc=mean, scale=std, size=img.shape)\n",
    "    return np.clip(img.astype(np.float64) + gaussian_noise, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_salt_and_pepper_noise(img: NDArray, salt_prob: float = 0.05, pepper_prob: float = 0.05) -> NDArray:\n",
    "    new_img = img.copy()\n",
    "\n",
    "    mask = rng.random(img.shape[:2])\n",
    "    salt_mask = mask < salt_prob\n",
    "    pepper_mask = mask > (1 - pepper_prob)\n",
    "\n",
    "    new_img[salt_mask] = 255\n",
    "    new_img[pepper_mask] = 0\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_averaging_filter(img: NDArray, kernel_size: int) -> NDArray:\n",
    "    kernel = np.ones((kernel_size, kernel_size)) / kernel_size**2\n",
    "    return cv2.filter2D(img, -1, kernel, borderType=cv2.BORDER_CONSTANT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_1_gaussian_noise = apply_gaussian_noise(im_1, mean=0, std=20)\n",
    "im_2_gaussian_noise = apply_gaussian_noise(im_2, mean=0, std=50)\n",
    "im_1_salt_pepper_noise = apply_salt_and_pepper_noise(im_1, salt_prob=0.05, pepper_prob=0.05)\n",
    "im_2_salt_pepper_noise = apply_salt_and_pepper_noise(im_2, salt_prob=0.05, pepper_prob=0.05)\n",
    "im_1_blurred = apply_averaging_filter(im_1, kernel_size=3)\n",
    "im_2_blurred = apply_averaging_filter(im_2, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "images = [\n",
    "    [im_1, im_1_blurred, im_1_gaussian_noise, im_1_salt_pepper_noise],\n",
    "    [im_2, im_2_blurred, im_2_gaussian_noise, im_2_salt_pepper_noise],\n",
    "]\n",
    "titles = [\n",
    "    [\"Original\", \"Blurred\", \"Gaussian Noise\", \"Salt & Pepper Noise\"],\n",
    "    [\"Original\", \"Blurred\", \"Gaussian Noise\", \"Salt & Pepper Noise\"],\n",
    "]\n",
    "cmaps = [[\"gray\"] * 4, [None] * 4]\n",
    "fig, axs = plt.subplots(2, 4, figsize=(16, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Image Degredation\")\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        axs[i, j].imshow(images[i][j], cmap=cmaps[i][j], vmin=0, vmax=255)\n",
    "        axs[i, j].set_title(titles[i][j])\n",
    "        axs[i, j].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Spatial Domain: Spatial Filtering](#toc0_)\n",
    "\n",
    "- It is used to **modify** or **enhance** an image by applying an operation to the pixel values within a **defined neighborhood**.\n",
    "- It processes the image in its **original** form (**pixel values**) rather than **transforming** it into another domain (e.g., **frequency domain**).\n",
    "\n",
    "<figure style=\"text-align:center; margin:0;\">\n",
    "  <img src=\"../assets/images/original/vector/spatial-filtering/spatial-filtering.svg\" alt=\"spatial-filtering.svg\" style=\"max-width:80%; height:auto;\">\n",
    "  <figcaption>Spatial Filtering Concept</figcaption>\n",
    "</figure>\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- Image Filtering: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html)\n",
    "- Operations on arrays: [docs.opencv.org/master/d2/de8/group__core__array.html](https://docs.opencv.org/master/d2/de8/group__core__array.html)\n",
    "- Smoothing Images (tutorial): [docs.opencv.org/master/dc/dd3/tutorial_gausian_median_blur_bilateral_filter.html](https://docs.opencv.org/master/dc/dd3/tutorial_gausian_median_blur_bilateral_filter.html)\n",
    "- Making your own linear filters! (tutorial): [docs.opencv.org/master/d4/dbd/tutorial_filter_2d.html](https://docs.opencv.org/master/d4/dbd/tutorial_filter_2d.html)\n",
    "- Signal processing (`scipy.signal`): [docs.scipy.org/doc/scipy/reference/signal.html](https://docs.scipy.org/doc/scipy/reference/signal.html)\n",
    "- Multidimensional image processing (`scipy.ndimage`): [docs.scipy.org/doc/scipy/reference/ndimage.html](https://docs.scipy.org/doc/scipy/reference/ndimage.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[Linear Filters](#toc0_)\n",
    "\n",
    "- The **output** pixel value is a **weighted sum** of the **input** pixel values in the **neighborhood**.\n",
    "- Linear filtering is mathematically equivalent to **convolution** of the **image** with the **filter mask**.\n",
    "- Convolution involves **flipping** the mask (**rotating it by 180¬∞**) before applying it, but for **symmetric masks**, this step is often **omitted**.\n",
    "- Check out the [**convolution.ipynb**](./base/03-convolution.ipynb) notebook for comprehensive information on the topic of convolution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_1_'></a>[Smoothing (Low-Pass) Filters](#toc0_)\n",
    "\n",
    "- Used to **reduce noise** and **blur** the image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_1_1_'></a>[Averaging Filter](#toc0_)\n",
    "\n",
    "- Replaces each pixel with the average of its neighborhood pixels.\n",
    "- For an averaging filter of size $\\mathbf{N \\times N}$, the mask is a matrix where all elements are equal to $\\mathbf{\\frac{1}{N^2}}$‚Äã:\n",
    "\n",
    "$$\n",
    "H_{\\text{avg}} = \\frac{1}{N^2} \\begin{bmatrix}\n",
    "1 & 1 & \\cdots & 1 \\\\\n",
    "1 & 1 & \\cdots & 1 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "1 & 1 & \\cdots & 1\n",
    "\\end{bmatrix}_{N \\times N}\n",
    "$$\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `cv2.blur`: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga8c45db9afe636703801b0b2e440fce37](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga8c45db9afe636703801b0b2e440fce37)\n",
    "- `cv2.boxFilter`: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gad533230ebf2d42509547d514f7d3fbc3](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gad533230ebf2d42509547d514f7d3fbc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_average_3x3 = np.ones((3, 3), dtype=np.float32) / 9\n",
    "kernel_average_5x5 = np.ones((5, 5), dtype=np.float32) / 25\n",
    "kernel_average_9x9 = np.ones((9, 9), dtype=np.float32) / 81\n",
    "\n",
    "# log\n",
    "print(f\"kernel_average_3x3:\\n{kernel_average_3x3}\\n\")\n",
    "print(f\"kernel_average_5x5:\\n{kernel_average_5x5}\\n\")\n",
    "print(f\"kernel_average_9x9:\\n{kernel_average_9x9}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_1_1_1_'></a>[Using OpenCV](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_1_gauss_averaging_1 = cv2.filter2D(im_1_gaussian_noise, -1, kernel_average_3x3, borderType=cv2.BORDER_CONSTANT)\n",
    "im_1_gauss_averaging_2 = cv2.filter2D(im_1_gaussian_noise, -1, kernel_average_5x5, borderType=cv2.BORDER_CONSTANT)\n",
    "im_1_gauss_averaging_3 = cv2.filter2D(im_1_gaussian_noise, -1, kernel_average_9x9, borderType=cv2.BORDER_CONSTANT)\n",
    "\n",
    "# plot\n",
    "images = [im_1, im_1_gaussian_noise, im_1_gauss_averaging_1, im_1_gauss_averaging_2, im_1_gauss_averaging_3]\n",
    "titles = [\"Original\", \"Gaussian Noise\", \"3x3\", \"5x5\", \"9x9\"]\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Smooth Gaussian Noise with Averaging Kernel using OpenCV\")\n",
    "for i in range(5):\n",
    "    axs[0, i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[i]} [Zoom]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_1_salt_pepper_averaging_1 = cv2.filter2D(\n",
    "    im_1_salt_pepper_noise,\n",
    "    -1,\n",
    "    kernel_average_3x3,\n",
    "    borderType=cv2.BORDER_REFLECT,\n",
    ")\n",
    "im_1_salt_pepper_averaging_2 = cv2.filter2D(\n",
    "    im_1_salt_pepper_noise,\n",
    "    -1,\n",
    "    kernel_average_5x5,\n",
    "    borderType=cv2.BORDER_REFLECT,\n",
    ")\n",
    "im_1_salt_pepper_averaging_3 = cv2.filter2D(\n",
    "    im_1_salt_pepper_noise,\n",
    "    -1,\n",
    "    kernel_average_9x9,\n",
    "    borderType=cv2.BORDER_REFLECT,\n",
    ")\n",
    "\n",
    "# plot\n",
    "images = [\n",
    "    im_1,\n",
    "    im_1_salt_pepper_noise,\n",
    "    im_1_salt_pepper_averaging_1,\n",
    "    im_1_salt_pepper_averaging_2,\n",
    "    im_1_salt_pepper_averaging_3,\n",
    "]\n",
    "titles = [\"Original\", \"Salt & Pepper Noise\", \"3x3\", \"5x5\", \"9x9\"]\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Smooth Salt & Pepper Noise with Averaging Kernel using OpenCV\")\n",
    "for i in range(5):\n",
    "    axs[0, i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[i]} [Zoom]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_1_1_2_'></a>[Using Scipy](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_2_gauss_averaging_1 = np.zeros_like(im_2)\n",
    "for i in range(im_2.shape[2]):\n",
    "    im_2_gauss_averaging_1[:, :, i] = sp.signal.convolve2d(\n",
    "        im_2_gaussian_noise[:, :, i], kernel_average_3x3, mode=\"same\", boundary=\"symm\"\n",
    "    )\n",
    "\n",
    "im_2_gauss_averaging_2 = np.zeros_like(im_2)\n",
    "for i in range(im_2.shape[2]):\n",
    "    im_2_gauss_averaging_2[:, :, i] = sp.signal.convolve2d(\n",
    "        im_2_gaussian_noise[:, :, i], kernel_average_5x5, mode=\"same\", boundary=\"symm\"\n",
    "    )\n",
    "\n",
    "im_2_gauss_averaging_3 = np.zeros_like(im_2)\n",
    "for i in range(im_2.shape[2]):\n",
    "    im_2_gauss_averaging_3[:, :, i] = sp.signal.convolve2d(\n",
    "        im_2_gaussian_noise[:, :, i], kernel_average_9x9, mode=\"same\", boundary=\"symm\"\n",
    "    )\n",
    "\n",
    "# plot\n",
    "images = [im_2, im_2_gaussian_noise, im_2_gauss_averaging_1, im_2_gauss_averaging_2, im_2_gauss_averaging_3]\n",
    "titles = [\"Original\", \"Gaussian Noise\", \"3x3\", \"5x5\", \"9x9\"]\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Smooth Gaussian Noise with Averaging Kernel using SciPy\")\n",
    "for i in range(5):\n",
    "    axs[0, i].imshow(images[i], vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[i][220:320, 220:320], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[i]} [Zoom]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_average_3x3_3d = np.ones((3, 3, 1)) / 9\n",
    "kernel_average_5x5_3d = np.ones((5, 5, 1)) / 25\n",
    "kernel_average_9x9_3d = np.ones((9, 9, 1)) / 81\n",
    "\n",
    "im_2_salt_pepper_averaging_1 = np.clip(\n",
    "    sp.ndimage.convolve(im_2_salt_pepper_noise, kernel_average_3x3_3d, mode=\"constant\", cval=0), 0, 255\n",
    ").astype(np.uint8)\n",
    "im_2_salt_pepper_averaging_2 = np.clip(\n",
    "    sp.ndimage.convolve(im_2_salt_pepper_noise, kernel_average_5x5_3d, mode=\"constant\", cval=0), 0, 255\n",
    ").astype(np.uint8)\n",
    "im_2_salt_pepper_averaging_3 = np.clip(\n",
    "    sp.ndimage.convolve(im_2_salt_pepper_noise, kernel_average_9x9_3d, mode=\"constant\", cval=0), 0, 255\n",
    ").astype(np.uint8)\n",
    "\n",
    "# plot\n",
    "images = [\n",
    "    im_2,\n",
    "    im_2_salt_pepper_noise,\n",
    "    im_2_salt_pepper_averaging_1,\n",
    "    im_2_salt_pepper_averaging_2,\n",
    "    im_2_salt_pepper_averaging_3,\n",
    "]\n",
    "titles = [\"Original\", \"Gaussian Noise\", \"3x3\", \"5x5\", \"9x9\"]\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Smooth Salt & Pepper Noise with Averaging Kernel using SciPy\")\n",
    "for i in range(5):\n",
    "    axs[0, i].imshow(images[i], vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[i][220:320, 220:320], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[i]} [Zoom]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_1_2_'></a>[Convolution Boundary Handling](#toc0_)\n",
    "\n",
    "- Zero padding often introduces undesirable dark or distorted regions near the image boundaries.\n",
    "- It happens because the convolution kernel mixes valid pixel values with zeros outside the image domain.\n",
    "- OpenCV‚Äôs `cv2.filter2D` **does not support `BORDER_WRAP`**. Attempting to use it will raise an assertion error.\n",
    "- For a detailed explanation and examples of these padding types, refer to the [**padding**](./utils/padding.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_average_9x9 = np.ones((9, 9)) / 81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero-padding\n",
    "im_1_gauss_averaging_zp = cv2.filter2D(im_1_gaussian_noise, -1, kernel_average_9x9, borderType=cv2.BORDER_CONSTANT)\n",
    "\n",
    "# reflect padding\n",
    "im_1_gauss_averaging_rfp = cv2.filter2D(im_1_gaussian_noise, -1, kernel_average_9x9, borderType=cv2.BORDER_REFLECT)\n",
    "\n",
    "# replicate padding\n",
    "im_1_gauss_averaging_rpp = cv2.filter2D(im_1_gaussian_noise, -1, kernel_average_9x9, borderType=cv2.BORDER_REPLICATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4), layout=\"compressed\")\n",
    "images = [im_1_gauss_averaging_zp, im_1_gauss_averaging_rfp, im_1_gauss_averaging_rpp]\n",
    "titles = [\"Zero Padding\", \"Reflect Padding\", \"Replicate Padding\"]\n",
    "fig.suptitle(\"Counvolution Boundry Handling\")\n",
    "top, left, size = 0, 0, 32\n",
    "ext = (left - 0.5, top - 0.5, size, size)\n",
    "\n",
    "for i in range(3):\n",
    "    ax = axs[i]\n",
    "    img = images[i]\n",
    "\n",
    "    # main image\n",
    "    ax.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    ax.set_title(titles[i])\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # inset (zoom)\n",
    "    axins = inset_axes(ax, width=\"50%\", height=\"50%\", loc=\"upper center\")\n",
    "    axins.imshow(img[top : top + size, left : left + size], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axins.axis(\"off\")\n",
    "\n",
    "    # square marks\n",
    "    ax.add_patch(patches.Rectangle((ext[0], ext[1]), ext[2], ext[3], fill=False, edgecolor=\"red\", lw=2))\n",
    "    axins.add_patch(patches.Rectangle((-0.5, -0.5), size, size, fill=False, edgecolor=\"red\", lw=2))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_1_3_'></a>[Gaussian Filter](#toc0_)\n",
    "\n",
    "- A more advanced smoothing filter that uses a Gaussian function to weight the pixels in the neighborhood.\n",
    "- Weights decrease with distance from the center, giving more importance to central pixels.\n",
    "- **Gaussian Function Formula**:\n",
    "\n",
    "$$G(x, y) = \\frac{1}{2\\pi \\sigma^2} e^{-\\frac{x^2 + y^2}{2\\sigma^2}}$$\n",
    "\n",
    "- **Generalized Gaussian Mask**:\n",
    "\n",
    "$$H_{\\text{Gaussian}}(i, j) = G\\left(i - \\frac{N-1}{2}, j - \\frac{N-1}{2}\\right)$$\n",
    "\n",
    "- **Normalization**:\n",
    "\n",
    "$$H_{\\text{Gaussian}} = \\frac{1}{\\sum_{i=1}^N \\sum_{j=1}^N G\\left(i - \\frac{N-1}{2}, j - \\frac{N-1}{2}\\right)} \\cdot G\\left(i - \\frac{N-1}{2}, j - \\frac{N-1}{2}\\right)$$\n",
    "\n",
    "- **Note:**  \n",
    "  - A 2D Gaussian kernel can be efficiently constructed as the **outer product of a 1D Gaussian vector** with itself.\n",
    "  - This reduces computation and ensures symmetry in the kernel.\n",
    "\n",
    "$$\n",
    "H_{\\text{Gaussian}}(i, j) = g(i) \\cdot g(j), \\quad \\text{where } g(i) = \\frac{1}{\\sqrt{2\\pi} \\sigma} e^{-\\frac{i^2}{2\\sigma^2}}\n",
    "$$\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- $\\text{kernel size} = 3$\n",
    "- $\\text{scale} = 0.5$\n",
    "\n",
    "$$\n",
    "H_{\\text{Gaussian}} = \\begin{bmatrix}\n",
    "0.011 & 0.084 & 0.011 \\\\\n",
    "0.084 & 0.619 & 0.084 \\\\\n",
    "0.011 & 0.084 & 0.011\n",
    "\\end{bmatrix}_{3 \\times 3}\n",
    "$$\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `cv2.getGaussianKernel`: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gac05a120c1ae92a6060dd0db190a61afa](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gac05a120c1ae92a6060dd0db190a61afa)\n",
    "- `cv2.GaussianBlur`: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gae8bdcd9154ed5ca3cbc1766d960f45c1](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gae8bdcd9154ed5ca3cbc1766d960f45c1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_1_3_1_'></a>[Manual](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel_2d(kernel_size: int, sigma: float) -> NDArray:\n",
    "    if kernel_size % 2 == 0:\n",
    "        raise ValueError(\"kernel size must be odd.\")\n",
    "\n",
    "    half_size = kernel_size // 2\n",
    "    x = np.arange(-half_size, half_size + 1)\n",
    "    y = np.arange(-half_size, half_size + 1)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "    kernel = np.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "    kernel = kernel / np.sum(kernel)\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gaussian kernels\n",
    "kernel_gaussian_3x3_1 = gaussian_kernel_2d(3, sigma=0.5)\n",
    "kernel_gaussian_3x3_2 = gaussian_kernel_2d(3, sigma=0.6)\n",
    "kernel_gaussian_3x3_3 = gaussian_kernel_2d(3, sigma=0.8)\n",
    "\n",
    "# apply kernels manually\n",
    "im_1_gauss_gaussian_1 = cv2.filter2D(im_1_gaussian_noise, -1, kernel_gaussian_3x3_1, borderType=cv2.BORDER_CONSTANT)\n",
    "im_1_gauss_gaussian_2 = cv2.filter2D(im_1_gaussian_noise, -1, kernel_gaussian_3x3_2, borderType=cv2.BORDER_CONSTANT)\n",
    "im_1_gauss_gaussian_3 = cv2.filter2D(im_1_gaussian_noise, -1, kernel_gaussian_3x3_3, borderType=cv2.BORDER_CONSTANT)\n",
    "\n",
    "# log\n",
    "print(f\"kernel_gaussian_3x3_1:\\n{kernel_gaussian_3x3_1}\\n\")\n",
    "print(f\"kernel_gaussian_3x3_2:\\n{kernel_gaussian_3x3_2}\\n\")\n",
    "print(f\"kernel_gaussian_3x3_3:\\n{kernel_gaussian_3x3_3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "images = [im_1, im_1_gaussian_noise, im_1_gauss_gaussian_1, im_1_gauss_gaussian_2, im_1_gauss_gaussian_3]\n",
    "titles = [\"Original\", \"Gaussian Noise\", \"gaussian 3x3\", \"gaussian 3x3 2\", \"gaussian 3x3 3\"]\n",
    "fig.suptitle(\"Smooth Gaussian Noise with Gaussian Kernel using OpenCV\")\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 8), layout=\"compressed\")\n",
    "for i in range(5):\n",
    "    axs[0, i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[i]} [Zoom]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_1_3_2_'></a>[Using OpenCV](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_1_gauss_gaussian_4 = cv2.GaussianBlur(im_1_gaussian_noise, ksize=(3, 3), sigmaX=0.5)\n",
    "im_1_gauss_gaussian_5 = cv2.GaussianBlur(im_1_gaussian_noise, ksize=(3, 3), sigmaX=0.6)\n",
    "im_1_gauss_gaussian_6 = cv2.GaussianBlur(im_1_gaussian_noise, ksize=(3, 3), sigmaX=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "images = [im_1, im_1_gaussian_noise, im_1_gauss_gaussian_4, im_1_gauss_gaussian_5, im_1_gauss_gaussian_6]\n",
    "titles = [\"Original\", \"Gaussian Noise\", \"gaussian 3x3\", \"gaussian 3x3 2\", \"gaussian 3x3 3\"]\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Smooth Gaussian Noise with Gaussian Kernel using OpenCV\")\n",
    "for i in range(5):\n",
    "    axs[0, i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[i]} [Zoom]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_1_3_3_'></a>[Using SciPy](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate = (ksize - 1) / (2 * sigma)\n",
    "im_1_gauss_gaussian_7 = sp.ndimage.gaussian_filter(im_1_gaussian_noise, sigma=0.5, truncate=(3 - 1) / (2 * 0.5))\n",
    "im_1_gauss_gaussian_8 = sp.ndimage.gaussian_filter(im_1_gaussian_noise, sigma=0.6, truncate=(3 - 1) / (2 * 0.6))\n",
    "im_1_gauss_gaussian_9 = sp.ndimage.gaussian_filter(im_1_gaussian_noise, sigma=0.8, truncate=(3 - 1) / (2 * 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "images = [im_1, im_1_gaussian_noise, im_1_gauss_gaussian_7, im_1_gauss_gaussian_8, im_1_gauss_gaussian_9]\n",
    "titles = [\"Original\", \"Gaussian Noise\", \"gaussian 3x3\", \"gaussian 3x3 2\", \"gaussian 3x3 3\"]\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Smooth Gaussian Noise with Gaussian Kernel using SciPy\")\n",
    "for i in range(5):\n",
    "    axs[0, i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[i]} [Zoom]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_2_'></a>[Sharpening (High Pass) Filters](#toc0_)\n",
    "\n",
    "- Used to **enhance edges** and **fine details** in the image.\n",
    "\n",
    "‚úçÔ∏è **Derivative in Discrete World:**:\n",
    "\n",
    "- **Derivatives** cannot be calculated directly in the **Discrete** world and we use **finite difference methods** to **approximate** derivatives.\n",
    "- These methods include **forward difference**, **backward difference**, and **central difference**.\n",
    "  - **Forward Difference**:\n",
    "    - Approximates the derivative using the value at the current point and the next point.\n",
    "    - First-Order Derivative:\n",
    "\n",
    "      $$\\frac{\\partial f}{\\partial x} \\Big|_{(x,y)} = f'(x,y) \\approx \\frac{f(x+1, y) - f(x, y)}{1} = \\begin{bmatrix}0 & 0 & 0 \\\\ 0 & -1 & 1 \\\\ 0 & 0 & 0\\end{bmatrix}$$\n",
    "\n",
    "  - **Backward Difference**:\n",
    "    - Approximates the derivative using the value at the current point and the previous point.\n",
    "    - First-Order Derivative:\n",
    "\n",
    "      $$\\frac{\\partial f}{\\partial x} \\Big|_{(x-1,y)} = f'(x-1,y) \\approx \\frac{f(x, y) - f(x-1, y)}{1} = \\begin{bmatrix}0 & 0 & 0 \\\\ -1 & 1 & 0 \\\\ 0 & 0 & 0\\end{bmatrix}$$\n",
    "\n",
    "  - **Central Difference**:\n",
    "    - Approximates the derivative using the values at the previous and next points.\n",
    "    - First-Order Derivative:\n",
    "\n",
    "      $$\\frac{\\partial f}{\\partial x} \\Big|_{(x,y)} \\approx \\frac{f(x+1, y) - f(x-1, y)}{2 \\times 1} = \\begin{bmatrix}0 & 0 & 0 \\\\ -0.5 & 0 & 0.5 \\\\ 0 & 0 & 0\\end{bmatrix}$$\n",
    "\n",
    "- **Second-Order Derivative**: The second derivative is the derivative of the first derivative. Using the central difference method.\n",
    "\n",
    "  $$\\frac{\\partial^2 f}{\\partial x^2} \\Big|_{(x,y)} \\approx \\frac{f'(x, y) - f'(x-1, y)}{1} = f(x+1, y) + f(x-1, y) - 2f(x, y) = \\begin{bmatrix}0 & 0 & 0 \\\\ 1 & -2 & 1 \\\\ 0 & 0 & 0\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_2_1_'></a>[Laplacian Filter](#toc0_)\n",
    "\n",
    "- The Laplacian is a **second-order derivative** operator that **combines** the second derivatives in both the $x$ and $y$ directions.\n",
    "- It is used for **edge detection** and **sharpening**.\n",
    "- **Discrete Laplacian Formula**:\n",
    "\n",
    "$$\\nabla^2 f(x,y) = \\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2} \\approx f(x+1, y) + f(x-1, y) + f(x, y+1) + f(x, y-1) - 4f(x, y)$$\n",
    "\n",
    "**Laplacian Kernels:**\n",
    "\n",
    "$$\n",
    "\\begin{array}{cccc}\n",
    "\\begin{bmatrix}0 & 1 & 0 \\\\ 1 & -4 & 1 \\\\ 0 & 1 & 0\\end{bmatrix} &\n",
    "\\begin{bmatrix}1 & 1 & 1 \\\\ 1 & -8 & 1 \\\\ 1 & 1 & 1\\end{bmatrix} &\n",
    "\\begin{bmatrix}0 & -1 & 0 \\\\ -1 & 4 & -1 \\\\ 0 & -1 & 0\\end{bmatrix} &\n",
    "\\begin{bmatrix}-1 & -1 & -1 \\\\ -1 & 8 & -1 \\\\ -1 & -1 & -1\\end{bmatrix} \\\\\n",
    "\\text{(a)} & \\text{(b)} & \\text{(c)} & \\text{(d)}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "- **(a):** Laplacian kernel used to implement above formula.\n",
    "- **(b):** Kernel used to implement an extension of this equation that includes the diagonal terms.\n",
    "- **(c) & (d):** Other implementations [equivalent results, but the difference in sign must be kept in mind].\n",
    "\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `cv2.Laplacian`: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gad78703e4c8fe703d479c1860d76429e6](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gad78703e4c8fe703d479c1860d76429e6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laplacian kernels\n",
    "kernel_Laplacian_1 = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]])\n",
    "kernel_Laplacian_2 = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]])\n",
    "\n",
    "# apply laplacian kernels\n",
    "im_1_laplacian_1 = cv2.filter2D(im_1, cv2.CV_32F, kernel_Laplacian_1, borderType=cv2.BORDER_CONSTANT)\n",
    "im_1_laplacian_2 = cv2.filter2D(im_1, cv2.CV_32F, kernel_Laplacian_2, borderType=cv2.BORDER_CONSTANT)\n",
    "im_1_blurred_laplacian_1 = cv2.filter2D(im_1_blurred, cv2.CV_32F, kernel_Laplacian_1, borderType=cv2.BORDER_CONSTANT)\n",
    "im_1_blurred_laplacian_2 = cv2.filter2D(im_1_blurred, cv2.CV_32F, kernel_Laplacian_2, borderType=cv2.BORDER_CONSTANT)\n",
    "im_1_gaussian_noise_laplacian_1 = cv2.filter2D(\n",
    "    im_1_gaussian_noise, cv2.CV_32F, kernel_Laplacian_1, borderType=cv2.BORDER_CONSTANT\n",
    ")\n",
    "im_1_gaussian_noise_laplacian_2 = cv2.filter2D(\n",
    "    im_1_gaussian_noise, cv2.CV_32F, kernel_Laplacian_2, borderType=cv2.BORDER_CONSTANT\n",
    ")\n",
    "\n",
    "# plot\n",
    "images = [\n",
    "    [im_1, im_1_laplacian_1, im_1_laplacian_2],\n",
    "    [im_1_blurred, im_1_blurred_laplacian_1, im_1_blurred_laplacian_2],\n",
    "    [im_1_gaussian_noise, im_1_gaussian_noise_laplacian_1, im_1_gaussian_noise_laplacian_2],\n",
    "]\n",
    "titles = [\n",
    "    [\"Original\", \"kernel_Laplacian_1\", \"kernel_Laplacian_2\"],\n",
    "    [\"Blurred\", \"kernel_Laplacian_1\", \"kernel_Laplacian_2\"],\n",
    "    [\"Gaussian Noise\", \"kernel_Laplacian_1\", \"kernel_Laplacian_2\"],\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(3, 6, figsize=(24, 12), layout=\"compressed\")\n",
    "fig.suptitle(\"Edge Extraction using Laplacian Kernels [Second-Order Derivatives]\")\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axs[i, j].imshow(np.abs(images[i][j]), cmap=\"gray\", vmin=0, vmax=255)\n",
    "        axs[i, j].set_title(titles[i][j])\n",
    "        axs[i, j].axis(\"off\")\n",
    "        axs[i, j + 3].imshow(np.abs(images[i][j])[30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "        axs[i, j + 3].set_title(f\"{titles[i][j]} [Zoom]\")\n",
    "        axs[i, j + 3].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_1_sharp_1 = cv2.subtract(im_1, im_1_laplacian_1, dtype=cv2.CV_8U)\n",
    "im_1_sharp_2 = cv2.subtract(im_1, im_1_laplacian_2, dtype=cv2.CV_8U)\n",
    "im_1_sharp_3 = cv2.subtract(im_1_blurred, im_1_blurred_laplacian_1, dtype=cv2.CV_8U)\n",
    "im_1_sharp_4 = cv2.subtract(im_1_blurred, im_1_blurred_laplacian_2, dtype=cv2.CV_8U)\n",
    "im_1_sharp_5 = cv2.subtract(im_1_gaussian_noise, im_1_gaussian_noise_laplacian_1, dtype=cv2.CV_8U)\n",
    "im_1_sharp_6 = cv2.subtract(im_1_gaussian_noise, im_1_gaussian_noise_laplacian_2, dtype=cv2.CV_8U)\n",
    "\n",
    "# plot\n",
    "images = [\n",
    "    [im_1, im_1_sharp_1, im_1_sharp_2],\n",
    "    [im_1_blurred, im_1_sharp_3, im_1_sharp_4],\n",
    "    [im_1_gaussian_noise, im_1_sharp_5, im_1_sharp_6],\n",
    "]\n",
    "titles = [\n",
    "    [\"Original\", \"im_1_sharp_1\", \"im_1_sharp_2\"],\n",
    "    [\"Blurred\", \"im_1_sharp_1\", \"im_1_sharp_2\"],\n",
    "    [\"Gaussian Noise\", \"im_1_sharp_1\", \"im_1_sharp_2\"],\n",
    "]\n",
    "fig, axs = plt.subplots(3, 6, figsize=(24, 12), layout=\"compressed\")\n",
    "fig.suptitle(\"Image Sharpening using Laplacian Kernels [Second-Order Derivatives]\")\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axs[i, j].imshow(images[i][j], cmap=\"gray\", vmin=0, vmax=255)\n",
    "        axs[i, j].set_title(titles[i][j])\n",
    "        axs[i, j].axis(\"off\")\n",
    "        axs[i, j + 3].imshow(images[i][j][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "        axs[i, j + 3].set_title(f\"{titles[i][j]} [Zoom]\")\n",
    "        axs[i, j + 3].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct image sharpening using laplacian\n",
    "alpha = 1\n",
    "kernel_Laplacian_3 = -kernel_Laplacian_1 + alpha * np.array([[0, 0, 0], [0, 1, 0], [0, 0, 0]])\n",
    "kernel_Laplacian_4 = -kernel_Laplacian_2 + alpha * np.array([[0, 0, 0], [0, 1, 0], [0, 0, 0]])\n",
    "\n",
    "im_1_sharp_7 = np.clip(\n",
    "    cv2.filter2D(im_1, cv2.CV_32F, kernel_Laplacian_3, borderType=cv2.BORDER_CONSTANT),\n",
    "    0,\n",
    "    255,\n",
    ").astype(np.uint8)\n",
    "\n",
    "im_1_sharp_8 = np.clip(\n",
    "    cv2.filter2D(im_1, cv2.CV_32F, kernel_Laplacian_4, borderType=cv2.BORDER_CONSTANT),\n",
    "    0,\n",
    "    255,\n",
    ").astype(np.uint8)\n",
    "\n",
    "im_1_sharp_9 = np.clip(\n",
    "    cv2.filter2D(im_1_blurred, cv2.CV_32F, kernel_Laplacian_3, borderType=cv2.BORDER_CONSTANT),\n",
    "    0,\n",
    "    255,\n",
    ").astype(np.uint8)\n",
    "\n",
    "im_1_sharp_10 = np.clip(\n",
    "    cv2.filter2D(im_1_blurred, cv2.CV_32F, kernel_Laplacian_4, borderType=cv2.BORDER_CONSTANT),\n",
    "    0,\n",
    "    255,\n",
    ").astype(np.uint8)\n",
    "\n",
    "im_1_sharp_11 = np.clip(\n",
    "    cv2.filter2D(im_1_gaussian_noise, cv2.CV_32F, kernel_Laplacian_3, borderType=cv2.BORDER_CONSTANT),\n",
    "    0,\n",
    "    255,\n",
    ").astype(np.uint8)\n",
    "\n",
    "im_1_sharp_12 = np.clip(\n",
    "    cv2.filter2D(im_1_gaussian_noise, cv2.CV_32F, kernel_Laplacian_4, borderType=cv2.BORDER_CONSTANT),\n",
    "    0,\n",
    "    255,\n",
    ").astype(np.uint8)\n",
    "\n",
    "# plot\n",
    "images = [\n",
    "    [im_1, im_1_sharp_7, im_1_sharp_8],\n",
    "    [im_1_blurred, im_1_sharp_9, im_1_sharp_10],\n",
    "    [im_1_gaussian_noise, im_1_sharp_11, im_1_sharp_12],\n",
    "]\n",
    "titles = [\n",
    "    [\"Original\", \"im_1_sharp_7\", \"im_1_sharp_8\"],\n",
    "    [\"Blurred\", \"im_1_sharp_9\", \"im_1_sharp_10\"],\n",
    "    [\"Gaussian Noise\", \"im_1_sharp_11\", \"im_1_sharp_12\"],\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(3, 6, figsize=(24, 12), layout=\"compressed\")\n",
    "fig.suptitle(\"Direct Image Sharpening using Laplacian Kernels\")\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axs[i, j].imshow(images[i][j], cmap=\"gray\", vmin=0, vmax=255)\n",
    "        axs[i, j].set_title(titles[i][j])\n",
    "        axs[i, j].axis(\"off\")\n",
    "        axs[i, j + 3].imshow(images[i][j][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "        axs[i, j + 3].set_title(f\"{titles[i][j]} [Zoom]\")\n",
    "        axs[i, j + 3].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_2_2_'></a>[Unsharp Masking](#toc0_)\n",
    "\n",
    "- A technique that subtracts a smoothed (blurred) version of the image from the original and adds the result back to the original.\n",
    "- **Formula:**\n",
    "\n",
    "$$I_{\\text{sharp}} = I_{\\text{original}} + (I_{\\text{original}} - I_{\\text{smoothed}})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_1_smooth_1 = cv2.filter2D(im_1, -1, kernel_gaussian_3x3_1)\n",
    "im_1_smooth_2 = cv2.filter2D(im_1, -1, kernel_gaussian_3x3_2)\n",
    "im_1_smooth_3 = cv2.filter2D(im_1, -1, kernel_gaussian_3x3_3)\n",
    "\n",
    "im_1_sub_1 = cv2.subtract(im_1, im_1_smooth_1, dtype=cv2.CV_32F)\n",
    "im_1_sub_2 = cv2.subtract(im_1, im_1_smooth_2, dtype=cv2.CV_32F)\n",
    "im_1_sub_3 = cv2.subtract(im_1, im_1_smooth_3, dtype=cv2.CV_32F)\n",
    "\n",
    "im_1_sharp_7 = cv2.add(im_1, im_1_sub_1, dtype=cv2.CV_8U)\n",
    "im_1_sharp_8 = cv2.add(im_1, im_1_sub_2, dtype=cv2.CV_8U)\n",
    "im_1_sharp_9 = cv2.add(im_1, im_1_sub_3, dtype=cv2.CV_8U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "images = [\n",
    "    [im_1, im_1_smooth_1, im_1_smooth_2, im_1_smooth_3],\n",
    "    [im_1 - im_1, im_1_sub_1, im_1_sub_2, im_1_sub_3],\n",
    "    [im_1, im_1_sharp_7, im_1_sharp_8, im_1_sharp_9],\n",
    "]\n",
    "titles = [\n",
    "    [\"Original\", \"im_1_smooth_1\", \"im_1_smooth_2\", \"im_1_smooth_3\"],\n",
    "    [\"Original\", \"im_1_sub_1\", \"im_1_sub_2\", \"im_1_sub_3\"],\n",
    "    [\"Original\", \"im_1_sharp_7\", \"im_1_sharp_8\", \"im_1_sharp_9\"],\n",
    "]\n",
    "fig, axs = plt.subplots(3, 4, figsize=(16, 12), layout=\"compressed\")\n",
    "fig.suptitle(\"Image Sharpening with Unsharp Masking technique\")\n",
    "for i in range(4):\n",
    "    axs[0, i].imshow(images[0][i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[0][i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(np.abs(images[1][i])[30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[1][i]} [Zoom]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "    axs[2, i].imshow(images[2][i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[2, i].set_title(f\"{titles[2][i]} [Zoom]\")\n",
    "    axs[2, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_2_3_'></a>[High-Boost Filtering](#toc0_)\n",
    "\n",
    "- A generalization of unsharp masking where the scaling factor $\\mathbf{k}$ can be greater than $\\mathbf{1}$.\n",
    "- **Formula:**\n",
    "\n",
    "$$I_{\\text{sharp}} = I_{\\text{original}} + k \\cdot (I_{\\text{original}} - I_{\\text{smoothed}})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_1_smooth_1 = cv2.filter2D(im_1, -1, kernel_gaussian_3x3_1)\n",
    "im_1_smooth_2 = cv2.filter2D(im_1, -1, kernel_gaussian_3x3_2)\n",
    "im_1_smooth_3 = cv2.filter2D(im_1, -1, kernel_gaussian_3x3_3)\n",
    "\n",
    "im_1_sub_1 = cv2.subtract(im_1, im_1_smooth_1, dtype=cv2.CV_32F)\n",
    "im_1_sub_2 = cv2.subtract(im_1, im_1_smooth_2, dtype=cv2.CV_32F)\n",
    "im_1_sub_3 = cv2.subtract(im_1, im_1_smooth_3, dtype=cv2.CV_32F)\n",
    "\n",
    "im_1_sharp_7 = cv2.addWeighted(im_1, 1, im_1_sub_1, 2, 0, dtype=cv2.CV_8U)\n",
    "im_1_sharp_8 = cv2.addWeighted(im_1, 1, im_1_sub_2, 2, 0, dtype=cv2.CV_8U)\n",
    "im_1_sharp_9 = cv2.addWeighted(im_1, 1, im_1_sub_3, 2, 0, dtype=cv2.CV_8U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "images = [\n",
    "    [im_1, im_1_smooth_1, im_1_smooth_2, im_1_smooth_3],\n",
    "    [im_1 - im_1, np.abs(im_1_sub_1), np.abs(im_1_sub_2), np.abs(im_1_sub_3)],\n",
    "    [im_1, im_1_sharp_7, im_1_sharp_8, im_1_sharp_9],\n",
    "]\n",
    "titles = [\n",
    "    [\"Original\", \"im_1_smooth_1\", \"im_1_smooth_2\", \"im_1_smooth_3\"],\n",
    "    [\"Original\", \"im_1_sub_1\", \"im_1_sub_2\", \"im_1_sub_3\"],\n",
    "    [\"Original\", \"im_1_sharp_7\", \"im_1_sharp_8\", \"im_1_sharp_9\"],\n",
    "]\n",
    "fig, axs = plt.subplots(3, 4, figsize=(16, 12), layout=\"compressed\")\n",
    "fig.suptitle(\"Image Sharpening with High-Boost filtering technique\")\n",
    "for i in range(4):\n",
    "    axs[0, i].imshow(images[0][i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[0][i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[1][i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[1][i]} [Zoom]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "    axs[2, i].imshow(images[2][i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[2, i].set_title(f\"{titles[2][i]} [Zoom]\")\n",
    "    axs[2, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_3_'></a>[Edge Detection Filters](#toc0_)\n",
    "\n",
    "- Edge detection identifies boundaries between regions of different intensities in an image.\n",
    "\n",
    "üí™ **Advantages of Linear Filters:**\n",
    "\n",
    "- **Simplicity**: Linear filters are easy to implement and computationally efficient.\n",
    "- **Effectiveness**: They work well for detecting edges in images with moderate noise.\n",
    "- **Flexibility**: Different kernels (e.g., Sobel, Prewitt, Laplacian) can be used depending on the application.\n",
    "\n",
    "‚ö†Ô∏è **Limitations of Linear Filters:**\n",
    "\n",
    "- **Sensitivity to Noise**: Linear filters can amplify noise, leading to false edges.\n",
    "- **Thick Edges**: First-order filters (e.g., Sobel) often produce thick edges, which may require thinning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_3_1_'></a>[First-Order Derivative Filters](#toc0_)\n",
    "\n",
    "- First-order derivative filters approximate the gradient of the image, which measures the rate of change of intensity.\n",
    "- The gradient is a vector:\n",
    "\n",
    "$$\\nabla f = \\begin{bmatrix} G_x \\\\ G_y \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial f}{\\partial x} \\\\ \\frac{\\partial f}{\\partial y} \\end{bmatrix}$$\n",
    "\n",
    "- The magnitude of the gradient:\n",
    "\n",
    "$$|\\nabla f| = \\sqrt{\\left(G_x\\right)^2 + \\left(G_y\\right)^2} \\approx |G_x| + |G_y|$$\n",
    "\n",
    "- gradient direction (orthogonal to edge direction):\n",
    "\n",
    "$$\\theta = \\tan^{-1}\\left(\\frac{G_y}{G_x}\\right)$$\n",
    "\n",
    "ü™ú **Edge Detection Steps:**\n",
    "\n",
    "1. Compute Gradient Components\n",
    "1. Compute Gradient Magnitude\n",
    "1. Compute Edge Direction (Optional)\n",
    "1. Threshold the Gradient Magnitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward difference (ignoring last row and column)\n",
    "g_x_forward = np.zeros(im_1.shape, dtype=np.float32)\n",
    "g_y_forward = np.zeros(im_1.shape, dtype=np.float32)\n",
    "g_x_forward[:, :-1] = np.abs(cv2.subtract(im_1[:, 1:], im_1[:, :-1], dtype=cv2.CV_32F))\n",
    "g_y_forward[:-1, :] = np.abs(cv2.subtract(im_1[1:, :], im_1[:-1, :], dtype=cv2.CV_32F))\n",
    "\n",
    "# compute gradient magnitude\n",
    "grad_mag_forward = np.sqrt(g_x_forward**2 + g_y_forward**2)\n",
    "\n",
    "# normalize and convert to uint8\n",
    "grad_mag_forward = np.clip(grad_mag_forward, 0, 255).astype(np.uint8)\n",
    "\n",
    "# plot\n",
    "images = [im_1, g_x_forward, g_y_forward, grad_mag_forward]\n",
    "titles = [\"Original\", \"Gx\", \"Gy\", \"Magnitude\"]\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4), layout=\"compressed\")\n",
    "fig.suptitle(\"Compute First-Order Derivatives using Forward Difference Method\")\n",
    "for i in range(4):\n",
    "    axs[i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[i].set_title(titles[i])\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# central difference (ignoring first and last row/column)\n",
    "g_x_center = np.zeros(im_1.shape, dtype=np.float32)\n",
    "g_y_center = np.zeros(im_1.shape, dtype=np.float32)\n",
    "g_x_center[:, 1:-1] = np.abs(cv2.subtract(im_1[:, 2:], im_1[:, :-2], dtype=cv2.CV_32F) / 2.0)\n",
    "g_y_center[1:-1, :] = np.abs(cv2.subtract(im_1[2:, :], im_1[:-2, :], dtype=cv2.CV_32F) / 2.0)\n",
    "\n",
    "# compute gradient magnitude\n",
    "grad_mag_center = np.sqrt(g_x_center**2 + g_y_center**2)\n",
    "\n",
    "# normalize and convert to uint8\n",
    "grad_mag_center = np.clip(grad_mag_center, 0, 255).astype(np.uint8)\n",
    "\n",
    "# plot\n",
    "images = [im_1, g_x_center, g_y_center, grad_mag_center]\n",
    "titles = [\"Original\", \"Gx\", \"Gy\", \"Magnitude\"]\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4), layout=\"compressed\")\n",
    "fig.suptitle(\"Compute First-Order Derivatives using Central Difference Method\")\n",
    "for i in range(4):\n",
    "    axs[i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[i].set_title(titles[i])\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_3_1_1_'></a>[Roberts](#toc0_)\n",
    "\n",
    "- It uses two **2x2** kernels to approximate the gradient of an image.\n",
    "- These kernels are designed to highlight changes in intensity along the **diagonal directions** (45¬∞ and 135¬∞).\n",
    "\n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "G_x = \\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix}, \\qquad\n",
    "G_y = \\begin{bmatrix} -1 & 0 \\\\ 0 & 1 \\end{bmatrix}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- Roberts Cross Filters **[PhD thesis]** in *1963*: [Machine Perception of Three-Dimensional Solids](https://dspace.mit.edu/bitstream/handle/1721.1/11589/33959125-MIT.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberts cross kernels\n",
    "roberts_x = np.array([[0, -1], [1, 0]])\n",
    "roberts_y = np.array([[-1, 0], [0, 1]])\n",
    "\n",
    "# convolve with the Roberts kernels\n",
    "g_x_roberts = cv2.filter2D(im_1, cv2.CV_32F, roberts_x)\n",
    "g_y_roberts = cv2.filter2D(im_1, cv2.CV_32F, roberts_y)\n",
    "\n",
    "# compute gradient magnitude and angle\n",
    "grad_roberts_mag = np.sqrt(g_x_roberts**2 + g_y_roberts**2)\n",
    "grad_roberts_angle = np.arctan2(g_y_roberts, g_x_roberts)  # in radians\n",
    "\n",
    "# normalize and convert to uint8\n",
    "grad_roberts_mag = np.clip(grad_roberts_mag, 0, 255).astype(np.uint8)\n",
    "grad_roberts_angle = (grad_roberts_angle + np.pi) / (2 * np.pi) * 255\n",
    "\n",
    "# apply a threshold using Otsu's method\n",
    "# _, threshold_value = cv2.threshold(grad_roberts_mag, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "# grad_roberts_mag = np.where(grad_roberts_mag >= threshold_value, grad_roberts_mag, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "images = [im_1, np.abs(g_x_roberts), np.abs(g_y_roberts), grad_roberts_mag, grad_roberts_angle]\n",
    "titles = [\"Original\", \"Gx\", \"Gy\", \"Magnitude\", \"Direction (Angle)\"]\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20, 4), layout=\"compressed\")\n",
    "fig.suptitle(\"Edge Detection with Roberts Kernels\")\n",
    "for i in range(5):\n",
    "    axs[i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[i].set_title(titles[i])\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_3_1_2_'></a>[Prewitt](#toc0_)\n",
    "\n",
    "- It uses 3x3 kernels to approximate the gradient of an image.\n",
    "- It is particularly effective for detecting **horizontal** and **vertical** edges.\n",
    "\n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "G_x = \\begin{bmatrix} -1 & 0 & 1 \\\\ -1 & 0 & 1 \\\\ -1 & 0 & 1 \\end{bmatrix}, \\qquad\n",
    "G_y = \\begin{bmatrix} -1 & -1 & -1 \\\\ 0 & 0 & 0 \\\\ 1 & 1 & 1 \\end{bmatrix}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "- Variants of the Prewitt Filter (Diagonal):\n",
    "\n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "G_{-45^\\circ} = \\begin{bmatrix} -1 & -1 & 0 \\\\ -1 & 0 & 1 \\\\ 0 & 1 & 1 \\end{bmatrix}, \\qquad\n",
    "G_{+45^\\circ} = \\begin{bmatrix} 0 & 1 & 1 \\\\ -1 & 0 & 1 \\\\ -1 & -1 & 0 \\end{bmatrix}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- Prewitt Filters **[Book]** in *1970* : [Object Enhancement and Extraction](https://web.eecs.utk.edu/~hqi/ece472-572/reference/edge-Prewitt70.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prewitt kernels\n",
    "prewitt_x = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])\n",
    "prewitt_y = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]])\n",
    "\n",
    "# convolve with the prewitt kernels\n",
    "g_x_prewitt = cv2.filter2D(im_1, cv2.CV_32F, prewitt_x)\n",
    "g_y_prewitt = cv2.filter2D(im_1, cv2.CV_32F, prewitt_y)\n",
    "\n",
    "# compute gradient magnitude and angle\n",
    "grad_prewitt_mag = np.sqrt(g_x_prewitt**2 + g_y_prewitt**2)\n",
    "grad_prewitt_angle = np.arctan2(g_y_prewitt, g_x_prewitt)  # in radians\n",
    "\n",
    "# normalize and convert to uint8\n",
    "grad_prewitt_mag = np.clip(grad_prewitt_mag, 0, 255).astype(np.uint8)\n",
    "grad_prewitt_angle = (grad_prewitt_angle + np.pi) / (2 * np.pi) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "images = [im_1, np.abs(g_x_prewitt), np.abs(g_y_prewitt), grad_prewitt_mag, grad_prewitt_angle]\n",
    "titles = [\"Original\", \"Gx\", \"Gy\", \"Magnitude\", \"Direction (Angle)\"]\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20, 4), layout=\"compressed\")\n",
    "fig.suptitle(\"Edge Detection with Prewitt Kernels\")\n",
    "for i in range(5):\n",
    "    axs[i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[i].set_title(titles[i])\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_3_1_3_'></a>[Sobel](#toc0_)\n",
    "\n",
    "- It uses 3x3 kernels to approximate the gradient of an image.\n",
    "- It is particularly effective for detecting **horizontal** and **vertical** edges.\n",
    "\n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "G_x = \\begin{bmatrix} -1 & 0 & 1 \\\\ -2 & 0 & 2 \\\\ -1 & 0 & 1 \\end{bmatrix}, \\qquad\n",
    "G_y = \\begin{bmatrix} -1 & -2 & -1 \\\\ 0 & 0 & 0 \\\\ 1 & 2 & 1 \\end{bmatrix}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "- Variants of the Sobel Filter (Diagonal):\n",
    "\n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "G_{-45^\\circ} = \\begin{bmatrix} -2 & -1 & 0 \\\\ -1 & 0 & 1 \\\\ 0 & 1 & 2 \\end{bmatrix}, \\qquad\n",
    "G_{+45^\\circ} = \\begin{bmatrix} 0 & 1 & 2 \\\\ -1 & 0 & 1 \\\\ -2 & -1 & 0 \\end{bmatrix}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- Sobel Filters **[Paper]** in *1968* : [A 3√ó3 Isotropic Gradient Operator for Image Processing](https://www.researchgate.net/publication/285159837_A_33_isotropic_gradient_operator_for_image_processing)\n",
    "- `cv2.Sobel`: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gacea54f142e81b6758cb6f375ce782c8d](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gacea54f142e81b6758cb6f375ce782c8d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sobel kernels\n",
    "sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "sobel_d1 = np.array([[-2, -1, 0], [-1, 0, 1], [0, 2, 1]])\n",
    "sobel_d2 = np.array([[0, 1, 2], [-1, 0, 1], [-2, -1, 0]])\n",
    "\n",
    "# convolve with the sobel kernels\n",
    "g_x_sobel = np.abs(cv2.filter2D(im_1, cv2.CV_32F, sobel_x))\n",
    "g_y_sobel = np.abs(cv2.filter2D(im_1, cv2.CV_32F, sobel_y))\n",
    "g_d1_sobel = np.abs(cv2.filter2D(im_1, cv2.CV_32F, sobel_d1))\n",
    "g_d2_sobel = np.abs(cv2.filter2D(im_1, cv2.CV_32F, sobel_d2))\n",
    "\n",
    "# compute gradient magnitude\n",
    "grad_sobel_mag = np.sqrt(g_x_sobel**2 + g_y_sobel**2 + g_d1_sobel**2 + g_d2_sobel**2)\n",
    "\n",
    "# normalize and convert to uint8\n",
    "grad_sobel_mag = np.clip(grad_sobel_mag, 0, 255).astype(np.uint8)\n",
    "\n",
    "# apply a threshold using Otsu's method\n",
    "threshold_value, _ = cv2.threshold(grad_sobel_mag, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "grad_sobel_mag_norm = np.where(grad_sobel_mag >= threshold_value, grad_sobel_mag, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "images = [im_1, g_x_sobel, g_y_sobel, g_d1_sobel, g_d2_sobel, grad_sobel_mag, grad_sobel_mag_norm]\n",
    "titles = [\"Original\", \"Gx\", \"Gy\", \"Gd1\", \"Gd2\", \"Magnitude\", \"Normalized Magnitude\"]\n",
    "fig, axs = plt.subplots(1, 7, figsize=(28, 4), layout=\"compressed\")\n",
    "fig.suptitle(\"Edge Detection with Sobel Kernels\")\n",
    "for i in range(7):\n",
    "    axs[i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[i].set_title(titles[i])\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_3_1_4_'></a>[Scharr](#toc0_)\n",
    "\n",
    "- It is an improvement over the Sobel filter in terms of isotropy, providing a more rotation-consistent gradient response.\n",
    "- The Scharr filter is designed to deliver better results when detecting edges at diagonal or steep orientations and is particularly useful in applications requiring high-precision gradient estimation.\n",
    "\n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "G_x = \\begin{bmatrix} -3 & 0 & 3 \\\\ -10 & 0 & 10 \\\\ -3 & 0 & 3 \\end{bmatrix}, \\qquad\n",
    "G_y = \\begin{bmatrix} -3 & -10 & -3 \\\\ 0 & 0 & 0 \\\\ 3 & 10 & 3 \\end{bmatrix}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- Scharr FIlters **[PhD thesis]** in *2000*: [Optimale Operatoren in der digitalen Bildverarbeitung](https://www.researchgate.net/publication/33427401_Optimale_Operatoren_in_der_Digitalen_Bildverarbeitung)\n",
    "- `cv2.Scharr`: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaa13106761eedf14798f37aa2d60404c9](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaa13106761eedf14798f37aa2d60404c9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scharr kernels\n",
    "scharr_x = np.array([[-3, 0, 3], [-10, 0, 10], [-3, 0, 3]])\n",
    "scharr_y = np.array([[-3, -10, -3], [0, 0, 0], [3, 10, 3]])\n",
    "scharr_d1 = np.array([[-10, -3, 0], [-3, 0, 3], [0, 3, 10]])\n",
    "scharr_d2 = np.array([[0, 3, 10], [-3, 0, 3], [-10, -3, 0]])\n",
    "\n",
    "# convolve with the scharr kernels\n",
    "g_x_scharr = np.abs(cv2.filter2D(im_1, cv2.CV_32F, scharr_x))\n",
    "g_y_scharr = np.abs(cv2.filter2D(im_1, cv2.CV_32F, scharr_y))\n",
    "g_d1_scharr = np.abs(cv2.filter2D(im_1, cv2.CV_32F, scharr_d1))\n",
    "g_d2_scharr = np.abs(cv2.filter2D(im_1, cv2.CV_32F, scharr_d2))\n",
    "\n",
    "# compute gradient magnitude\n",
    "grad_scharr_mag = np.sqrt(g_x_scharr**2 + g_y_scharr**2 + g_d1_scharr**2 + g_d2_scharr**2)\n",
    "\n",
    "# normalize and convert to uint8\n",
    "grad_scharr_mag = np.clip(grad_scharr_mag, 0, 255).astype(np.uint8)\n",
    "\n",
    "# apply a threshold using Otsu's method\n",
    "threshold_value, _ = cv2.threshold(grad_scharr_mag, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "grad_scharr_mag_norm = np.where(grad_scharr_mag >= threshold_value, grad_scharr_mag, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "images = [im_1, g_x_scharr, g_y_scharr, g_d1_scharr, g_d2_scharr, grad_scharr_mag, grad_scharr_mag_norm]\n",
    "titles = [\"Original\", \"Gx\", \"Gy\", \"Gd1\", \"Gd2\", \"Magnitude\", \"Normalized Magnitude\"]\n",
    "fig, axs = plt.subplots(1, 7, figsize=(28, 4), layout=\"compressed\")\n",
    "fig.suptitle(\"Edge Detection with Scharr Kernels\")\n",
    "for i in range(7):\n",
    "    axs[i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[i].set_title(titles[i])\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_3_2_'></a>[Second-Order Derivative Filters](#toc0_)\n",
    "\n",
    "-  Unlike First-Order Derivative Filters (like Sobel, Prewitt, and Roberts), which measure gradient strength and direction.\n",
    "-  Second-Order Derivative filters enhance edge detection by highlighting areas where intensity changes most rapidly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_3_2_1_'></a>[Laplacian Operator (D4)](#toc0_)\n",
    "\n",
    "$$\\begin{bmatrix}0 & 1 & 0 \\\\ 1 & -4 & 1 \\\\ 0 & 1 & 0\\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_3_2_2_'></a>[Laplacian with Diagonals (D8)](#toc0_)\n",
    "\n",
    "$$\\begin{bmatrix}1 & 1 & 1 \\\\ 1 & -8 & 1 \\\\ 1 & 1 & 1\\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_3_2_3_'></a>[Laplacian of Gaussian (LoG)](#toc0_)\n",
    "\n",
    "- Since the Laplacian is highly sensitive to noise, we often smooth the image first using a Gaussian filter.\n",
    "      \n",
    "  $$LoG(x,y) = -\\frac{1}{\\pi \\sigma^4} \\left(1 - \\frac{x^2 + y^2}{2\\sigma^2}\\right) e^{-\\frac{x^2 + y^2}{2\\sigma^2}} = \\nabla^2 (G(x,y) * I(x,y))$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build kernels\n",
    "kernel_gaussian_5x5 = gaussian_kernel_2d(kernel_size=5, sigma=0.6).astype(np.float32)\n",
    "kernel_Laplacian_4c = np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1\n",
    "im_1_smooth_4 = cv2.filter2D(im_1, cv2.CV_32F, kernel_gaussian_5x5)\n",
    "im_1_laplacian_3 = cv2.filter2D(im_1_smooth_4, cv2.CV_32F, kernel_Laplacian_4c)\n",
    "im_1_sharp_13 = cv2.add(im_1, im_1_laplacian_3, dtype=cv2.CV_8U)\n",
    "\n",
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(18, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Image Sharpening using Laplacian of Gaussian (LoG)\")\n",
    "images = [im_1, im_1_smooth_4, np.abs(im_1_laplacian_3), im_1_sharp_13]\n",
    "titles = [\"im_1\", \"im_1_smooth_4\", \"np.abs(im_1_laplacian_3)\", \"im_1_sharp_13\"]\n",
    "for i in range(len(images)):\n",
    "    axs[0, i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[i]}[30:90, 90:150]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2\n",
    "kernel_combined = cv2.filter2D(kernel_gaussian_5x5, cv2.CV_32F, kernel_Laplacian_4c, borderType=cv2.BORDER_REPLICATE)\n",
    "im_1_laplacian_4 = cv2.filter2D(im_1, cv2.CV_32F, kernel_combined)\n",
    "im_1_sharp_14 = cv2.add(im_1, im_1_laplacian_4, dtype=cv2.CV_8U)\n",
    "\n",
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(14, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Image Sharpening using Laplacian of Gaussian (LoG)\")\n",
    "images = [im_1, np.abs(im_1_laplacian_4), im_1_sharp_14]\n",
    "titles = [\"im_1\", \"np.abs(im_1_laplacian_4)\", \"im_1_sharp_14\"]\n",
    "for i in range(len(images)):\n",
    "    axs[0, i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[i]}[30:90, 90:150]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_3_2_4_'></a>[Difference of Gaussian (DoG)](#toc0_)\n",
    "\n",
    "- The Difference of Gaussians (DoG) is an approximation of the LoG and is computed as:\n",
    "\n",
    "  $$DoG = G_{\\sigma_1} - G_{\\sigma_2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build kernels\n",
    "kernel_gaussian_1 = gaussian_kernel_2d(kernel_size=5, sigma=1.0).astype(np.float32)\n",
    "kernel_gaussian_2 = gaussian_kernel_2d(kernel_size=9, sigma=2.0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1\n",
    "im_1_blurred_1 = cv2.filter2D(im_1, cv2.CV_32F, kernel_gaussian_1, borderType=cv2.BORDER_REPLICATE)\n",
    "im_1_blurred_2 = cv2.filter2D(im_1, cv2.CV_32F, kernel_gaussian_2, borderType=cv2.BORDER_REPLICATE)\n",
    "dog_1 = cv2.subtract(im_1_blurred_1, im_1_blurred_2, dtype=cv2.CV_32F)\n",
    "im_1_sharp_15 = cv2.add(im_1, dog_1, dtype=cv2.CV_8U)\n",
    "\n",
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=5, figsize=(22, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Image Sharpening using Difference of Gaussian (DoG)\")\n",
    "images = [im_1, im_1_blurred_1, im_1_blurred_2, np.abs(dog_1), im_1_sharp_15]\n",
    "titles = [\"im_1\", \"im_1_blurred_1\", \"im_1_blurred_2\", \"np.abs(dog_1)\", \"im_1_sharp_15\"]\n",
    "for i in range(len(images)):\n",
    "    axs[0, i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[i]}[30:90, 90:150]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2\n",
    "kernel_combined = cv2.subtract(np.pad(kernel_gaussian_1, ((2,2),(2,2)), mode='constant'), kernel_gaussian_2, dtype=cv2.CV_32F)\n",
    "dog_2 = cv2.filter2D(im_1, cv2.CV_32F, kernel_combined, borderType=cv2.BORDER_REPLICATE)\n",
    "im_1_sharp_16 = cv2.add(im_1, dog_2, dtype=cv2.CV_8U)\n",
    "\n",
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(14, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Image Sharpening using Difference of Gaussian (DoG)\")\n",
    "images = [im_1, np.abs(dog_2), im_1_sharp_16]\n",
    "titles = [\"im_1\", \"np.abs(dog_2)\", \"im_1_sharp_16\"]\n",
    "for i in range(len(images)):\n",
    "    axs[0, i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[i]}[30:90, 90:150]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[Nonlinear Filters](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_1_'></a>[Order-Statistic Filters](#toc0_)\n",
    "\n",
    "- These filters are based on the **ranking** (ordering) of pixel values in a neighborhood.\n",
    "- They are widely used for tasks like **noise reduction** and **edge detection**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_1_1_'></a>[Median Filter](#toc0_)\n",
    "\n",
    "- Replaces each pixel with the **median** value of its neighborhood.\n",
    "- Highly effective for removing **salt-and-pepper** noise.\n",
    "- Preserves edges better than linear smoothing filters.\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `cv2.medianBlur`: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga564869aa33e58769b4469101aac458f9](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga564869aa33e58769b4469101aac458f9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_2_1_1_1_'></a>[Manual](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter_2d(image: NDArray, kernel_size: int) -> NDArray:\n",
    "    image_height, image_width = image.shape\n",
    "    pad_size = kernel_size // 2\n",
    "    padded_image = np.pad(image, pad_size, mode=\"constant\", constant_values=0)\n",
    "    output_image = np.zeros_like(image, dtype=np.uint8)\n",
    "\n",
    "    for i in range(image_height):\n",
    "        for j in range(image_width):\n",
    "            roi = padded_image[i : i + kernel_size, j : j + kernel_size]\n",
    "            output_image[i, j] = np.median(roi)\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_1_salt_pepper_median_1 = median_filter_2d(im_1_salt_pepper_noise, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "images = [im_1, im_1_salt_pepper_noise, im_1_salt_pepper_averaging_1, im_1_salt_pepper_median_1]\n",
    "titles = [\"Original\", \"Salt & Pepper Noise\", \"Averaging 3x3\", \"Median 3x3\"]\n",
    "fig, axs = plt.subplots(2, 4, figsize=(16, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Efficient Salt & Pepper Noise Removal using Median Filter (Non-Linear)\")\n",
    "for i in range(4):\n",
    "    axs[0, i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[i]} [Zoom]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_2_1_1_2_'></a>[Using OpenCV](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_1_salt_pepper_median_2 = cv2.medianBlur(im_1, ksize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "images = [im_1, im_1_salt_pepper_noise, im_1_salt_pepper_averaging_1, im_1_salt_pepper_median_2]\n",
    "titles = [\"Original\", \"Salt & Pepper Noise\", \"Averaging 3x3\", \"Median 3x3\"]\n",
    "fig, axs = plt.subplots(2, 4, figsize=(16, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Efficient Salt & Pepper Noise Removal using Median Filter (Non-Linear)\")\n",
    "for i in range(4):\n",
    "    axs[0, i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[i]} [Zoom]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_1_2_'></a>[Maximum and Minimum Filters](#toc0_)\n",
    "\n",
    "- Replaces each pixel with the **minimum** or **maximum** value of its neighborhood.\n",
    "- **Minimum** is useful for removing **white noise** (e.g., salt noise).\n",
    "- **Maximum** is useful for removing **black noise** (e.g., pepper noise).\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `cv2.erode` (Min filter): [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaeb1e0c1033e3f6b891a25d0511362aeb](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaeb1e0c1033e3f6b891a25d0511362aeb)\n",
    "- `cv2.dilate` (Max filter): [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga4ff0f3318642c4f469d0e11f242f3b6c](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga4ff0f3318642c4f469d0e11f242f3b6c)\n",
    "\n",
    "‚úçÔ∏è **Note**:  \n",
    "\n",
    "Although `cv2.erode` and `cv2.dilate` are commonly used for **morphological operations** such as erosion and dilation, they can also be used to perform **min** and **max** filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_2_1_2_1_'></a>[Using OpenCV](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_1_salt_pepper_min_1 = cv2.erode(im_1_salt_pepper_noise, kernel=np.ones((3, 3), np.uint8))\n",
    "\n",
    "# plot\n",
    "images = [im_1, im_1_salt_pepper_noise, im_1_salt_pepper_averaging_1, im_1_salt_pepper_min_1]\n",
    "titles = [\"Original\", \"Salt & Pepper Noise\", \"Averaging 3x3\", \"Min Filter 3x3\"]\n",
    "fig, axs = plt.subplots(2, 4, figsize=(16, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Removing Salt Noise with Erosion (Special Case)\")\n",
    "for i in range(4):\n",
    "    axs[0, i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[i]} [Zoom]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_1_salt_pepper_max_1 = cv2.dilate(im_1_salt_pepper_noise, kernel=np.ones((3, 3), np.uint8))\n",
    "\n",
    "# plot\n",
    "images = [im_1, im_1_salt_pepper_noise, im_1_salt_pepper_averaging_1, im_1_salt_pepper_max_1]\n",
    "titles = [\"Original\", \"Salt & Pepper Noise\", \"Averaging 3x3\", \"Min Filter 3x3\"]\n",
    "fig, axs = plt.subplots(2, 4, figsize=(16, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Removing Pepper Noise with Dilation (Special Case)\")\n",
    "for i in range(4):\n",
    "    axs[0, i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[i]} [Zoom]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_1_3_'></a>[Percentile Filters](#toc0_)\n",
    "\n",
    "- Replaces each pixel with a specific **percentile** value (e.g., 75th percentile) from the sorted neighborhood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_2_'></a>[Bilateral Filter](#toc0_)\n",
    "\n",
    "- The bilateral filter is a nonlinear filter that **smooths** an image while **preserving edges**.\n",
    "- It combines **spatial proximity** and **intensity similarity** to determine the weights for filtering.\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "- Filtered Value:\n",
    "\n",
    "  $$I_{\\text{filtered}}(x, y) = \\frac{1}{W} \\sum_{i,j \\in \\Omega} w_s(i, j) \\cdot w_r(i, j) \\cdot I(i, j)$$\n",
    "\n",
    "- Normalization Factor:\n",
    "\n",
    "  $$W = \\sum_{i,j \\in \\Omega} w_s(i, j) \\cdot w_r(i, j)$$\n",
    "\n",
    "- Range Weight:\n",
    "  - It is a Gaussian function of the intensity difference between $I(x, y)$ and $I(i, j)$.\n",
    "\n",
    "  $$w_r(i, j) = e^{-\\frac{(I(x, y) - I(i, j))^2}{2\\sigma_r^2}}$$\n",
    "\n",
    "- Spatial Weight:\n",
    "  - It is a Gaussian function of the Euclidean distance between $(x, y)$ and $(i, j)$.\n",
    "\n",
    "  $$w_s(i, j) = e^{-\\frac{(x-i)^2 + (y-j)^2}{2\\sigma_s^2}}$$\n",
    "\n",
    "**Example:**\n",
    "- Range Weight Scale : $\\sigma_r = 50$\n",
    "- Spatial Weight Scale : $\\sigma_s = 1$\n",
    "\n",
    "$$\n",
    "\\begin{array}{cccc}\n",
    "I = \\begin{bmatrix}10 & 20 & 10 \\\\ 20 & 255 & 20 \\\\ 10 & 20 & 10\\end{bmatrix}, &\n",
    "w_r \\approx \\begin{bmatrix} e^{-12.25} & e^{-5.78} & e^{-12.25} \\\\ e^{-5.78} & 1 & e^{-5.78} \\\\ e^{-12.25} & e^{-5.78} & e^{-12.25} \\end{bmatrix}, &\n",
    "w_s = \\begin{bmatrix} e^{-1} & e^{-0.5} & e^{-1} \\\\ e^{-0.5} & 1 & e^{-0.5} \\\\ e^{-1} & e^{-0.5} & e^{-1} \\end{bmatrix},\n",
    "W \\approx 1.0076 &\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `cv2.bilateralFilter`: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga9d7064d478c95d60003cf839430737ed](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga9d7064d478c95d60003cf839430737ed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_1_gauss_bilateral_1 = cv2.bilateralFilter(im_1_gaussian_noise, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "im_1_gauss_bilateral_2 = cv2.bilateralFilter(im_1_gaussian_noise, d=9, sigmaColor=100, sigmaSpace=100)\n",
    "im_1_gauss_bilateral_3 = cv2.bilateralFilter(im_1_gaussian_noise, d=9, sigmaColor=150, sigmaSpace=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "images = [im_1, im_1_gaussian_noise, im_1_gauss_bilateral_1, im_1_gauss_bilateral_2, im_1_gauss_bilateral_3]\n",
    "titles = [\"Original\", \"Gaussian Noise\", \"Bilateral Filter 1\", \"Bilateral Filter 2\", \"Bilateral Filter 3\"]\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Removing Noise while Preserving Edges using Bilateral Filter\")\n",
    "for i in range(5):\n",
    "    axs[0, i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[i]} [Zoom]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_3_'></a>[Marr-Hildreth Edge Detector](#toc0_)\n",
    "\n",
    "- is a classic method for detecting edges in images.\n",
    "- It is based on the **Laplacian of Gaussian (LoG)** filter, which combines Gaussian smoothing with the Laplacian operator **to detect edges at multiple scales**.\n",
    "- This algorithm relies on **zero-crossings** of the **LoG-filtered** image to **identify edges**.\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- Marr-Hildreth Edge Detector **[Paper]** in *1980* : [Theory of edge detection](https://www.hms.harvard.edu/bss/neuro/bornlab/qmbc/beta/day4/marr-hildreth-edge-prsl1980.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_4_'></a>[Canny Edge Detector](#toc0_)\n",
    "\n",
    "- It is a multi-step algorithm used to detect edges in images.\n",
    "- It is one of the most popular edge detection methods because it is:\n",
    "  - **Accurate**: Detects true edges while suppressing noise.\n",
    "  - **Robust**: Uses hysteresis thresholding to reduce false edges.\n",
    "  - **Efficient**: Combines multiple steps into a single pipeline.\n",
    "\n",
    "ü™ú **Steps of the Canny Edge Detector**:\n",
    "- **Noise Reduction**:\n",
    "  - Apply a Gaussian blur to smooth the image and reduce noise.\n",
    "  - This step ensures that the algorithm is less sensitive to small variations in intensity.\n",
    "- **Gradient Calculation**:\n",
    "  - Compute the intensity gradients (using Sobel filters) to find the magnitude and direction of edges.\n",
    "- **Non-Maximum Suppression**:\n",
    "  - Thin out the edges by keeping only the local maxima in the gradient magnitude image (for each pixel, check the two neighboring pixels along the gradient direction).\n",
    "- **Double Thresholding**:\n",
    "  - Use two thresholds (low and high) to classify edges as strong, weak, or non-edges.\n",
    "- **Edge Tracking by Hysteresis**:\n",
    "  - Finalize edges by connecting weak edges to strong edges, ensuring continuity.\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- Canny Edge Detector **[Paper]** in *1986* : [A Computational Approach to Edge Detection](https://ieeexplore.ieee.org/document/4767851)\n",
    "- `cv2.canny`: [docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga2a671611e104c093843d7b7fc46d24af](https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga2a671611e104c093843d7b7fc46d24af)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_edges = cv2.Canny(cv2.GaussianBlur(im_1, (3, 3), 0), 50, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "images = [im_1, grad_roberts_mag, grad_prewitt_mag, grad_sobel_mag, canny_edges]\n",
    "titles = [\"Original\", \"Roberts\", \"Prewitt\", \"Sobel\", \"Canny\"]\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Extract Edges using Canny Method\")\n",
    "for i in range(5):\n",
    "    axs[0, i].imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(titles[i])\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(images[i][30:90, 90:150], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1, i].set_title(f\"{titles[i]} [Zoom]\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "media-processing-workshop (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "origin_repo": "https://github.com/mr-pylin/media-processing-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
