{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
    "    <div style=\"text-align: left; flex: 4;\">\n",
    "        <strong>Author:</strong> Amirhossein Heydari ‚Äî \n",
    "        üìß <a href=\"mailto:amirhosseinheydari78@gmail.com\">amirhosseinheydari78@gmail.com</a> ‚Äî \n",
    "        üêô <a href=\"https://github.com/mr-pylin/media-processing-workshop\" target=\"_blank\" rel=\"noopener\">github.com/mr-pylin</a>\n",
    "    </div>\n",
    "    <div style=\"display: flex; justify-content: flex-end; flex: 1; gap: 8px; align-items: center; padding: 0;\">\n",
    "        <a href=\"https://opencv.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/libraries/opencv/logo/OpenCV_logo_no_text-1.svg\"\n",
    "                 alt=\"OpenCV Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "        <a href=\"https://pillow.readthedocs.io/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/libraries/pillow/logo/pillow-logo-248x250.png\"\n",
    "                 alt=\"PIL Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "        <a href=\"https://scikit-image.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/libraries/scikit-image/logo/logo.png\"\n",
    "                 alt=\"scikit-image Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "        <a href=\"https://scipy.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/libraries/scipy/logo/logo.svg\"\n",
    "                 alt=\"SciPy Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "    </div>\n",
    "</div>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Dependencies](#toc1_)    \n",
    "- [Prepare Images](#toc2_)    \n",
    "  - [Binary Images](#toc2_1_)    \n",
    "  - [Grayscale Images](#toc2_2_)    \n",
    "  - [RGB Images](#toc2_3_)    \n",
    "- [Morphological Processing](#toc3_)    \n",
    "  - [Structuring Elements](#toc3_1_)    \n",
    "    - [Square](#toc3_1_1_)    \n",
    "    - [Disk (Circular)](#toc3_1_2_)    \n",
    "    - [Diamond](#toc3_1_3_)    \n",
    "    - [Octagon](#toc3_1_4_)    \n",
    "    - [Line](#toc3_1_5_)    \n",
    "    - [Cross (Plus)](#toc3_1_6_)    \n",
    "    - [Rectangle](#toc3_1_7_)    \n",
    "  - [Morphological Operators](#toc3_2_)    \n",
    "    - [Erosion ($\\ominus$)](#toc3_2_1_)    \n",
    "      - [Binary Erosion](#toc3_2_1_1_)    \n",
    "        - [Using OpenCV](#toc3_2_1_1_1_)    \n",
    "        - [Using Scikit-Image](#toc3_2_1_1_2_)    \n",
    "        - [Using SciPy](#toc3_2_1_1_3_)    \n",
    "      - [Grayscale Erosion](#toc3_2_1_2_)    \n",
    "    - [Dilation ($\\oplus$)](#toc3_2_2_)    \n",
    "      - [Binary Dilation](#toc3_2_2_1_)    \n",
    "      - [Grayscale Dilation](#toc3_2_2_2_)    \n",
    "    - [Opening ($\\circ$)](#toc3_2_3_)    \n",
    "      - [Binary Opening](#toc3_2_3_1_)    \n",
    "      - [Grayscale Opening](#toc3_2_3_2_)    \n",
    "    - [Closing ($\\bullet$)](#toc3_2_4_)    \n",
    "      - [Binary Closing](#toc3_2_4_1_)    \n",
    "      - [Grayscale Closing](#toc3_2_4_2_)    \n",
    "    - [Gradient ($\\nabla$)](#toc3_2_5_)    \n",
    "      - [Binary Gradient](#toc3_2_5_1_)    \n",
    "      - [Grayscale Gradient](#toc3_2_5_2_)    \n",
    "    - [Top-Hat ($\\text{TH}$)](#toc3_2_6_)    \n",
    "      - [Binary Top-Hat](#toc3_2_6_1_)    \n",
    "      - [Grayscale Top-Hat](#toc3_2_6_2_)    \n",
    "    - [Black-Hat ($\\text{BH}$)](#toc3_2_7_)    \n",
    "      - [Binary Black-Hat](#toc3_2_7_1_)    \n",
    "      - [Grayscale Black-Hat](#toc3_2_7_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Dependencies](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import skimage as ski\n",
    "from numpy.typing import NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable automatic figure display (plt.show() required)  \n",
    "# this ensures consistency with .py scripts and gives full control over when plots appear\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a reproducible random number generator\n",
    "rng = np.random.default_rng(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Prepare Images](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Binary Images](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square with hole (centered)\n",
    "im_bin_1 = np.zeros((32, 32), dtype=np.uint8)\n",
    "im_bin_1[8:24, 8:24] = 1\n",
    "im_bin_1[12:20, 12:20] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two close objects\n",
    "im_bin_2 = np.zeros((32, 32), dtype=np.uint8)\n",
    "im_bin_2[10:18, 6:12] = 1\n",
    "im_bin_2[10:18, 14:20] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagonal line structure\n",
    "im_bin_3 = np.zeros((32, 32), dtype=np.uint8)\n",
    "for i in range(5, 27):\n",
    "    im_bin_3[i, i] = 1\n",
    "    im_bin_3[i, i + 1] = 1\n",
    "    im_bin_3[i, i - 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy blob\n",
    "im_bin_4 = np.zeros((32, 32), dtype=np.uint8)\n",
    "im_bin_4[10:22, 10:22] = 1\n",
    "im_bin_4 = np.bitwise_or(im_bin_4, rng.integers(0, 2, size=(32, 32)) & (rng.random((32, 32)) < 0.05))\n",
    "im_bin_4 = im_bin_4.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# circle with pepper noise\n",
    "im_bin_5 = np.zeros((32, 32), dtype=np.uint8)\n",
    "y, x = np.ogrid[-16:16, -16:16]\n",
    "circle_mask = x**2 + y**2 <= 64  # radius=8\n",
    "im_bin_5[circle_mask] = 1\n",
    "pepper_mask = rng.random((32, 32)) < 0.05\n",
    "im_bin_5[pepper_mask & circle_mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  irregular shape with protrusions/indentations\n",
    "im_bin_6 = np.zeros((32, 32), dtype=np.uint8)\n",
    "im_bin_6[5:25, 5:20] = 1\n",
    "\n",
    "# protrusions (thin structures)\n",
    "im_bin_6[3:5, 10:15] = 1\n",
    "im_bin_6[25:27, 8:12] = 1\n",
    "\n",
    "# indentations (small holes)\n",
    "im_bin_6[12:18, 15:18] = 0\n",
    "im_bin_6[20:22, 7:9] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=1, ncols=6, figsize=(24, 4), layout=\"compressed\")\n",
    "axs[0].imshow(im_bin_1, vmin=0, vmax=1, cmap=\"gray\")\n",
    "axs[0].set_title(\"im_bin_1 (binary)\")\n",
    "axs[1].imshow(im_bin_2, vmin=0, vmax=1, cmap=\"gray\")\n",
    "axs[1].set_title(\"im_bin_2 (binary)\")\n",
    "axs[2].imshow(im_bin_3, vmin=0, vmax=1, cmap=\"gray\")\n",
    "axs[2].set_title(\"im_bin_3 (binary)\")\n",
    "axs[3].imshow(im_bin_4, vmin=0, vmax=1, cmap=\"gray\")\n",
    "axs[3].set_title(\"im_bin_4 (binary)\")\n",
    "axs[4].imshow(im_bin_5, vmin=0, vmax=1, cmap=\"gray\")\n",
    "axs[4].set_title(\"im_bin_5 (binary)\")\n",
    "axs[5].imshow(im_bin_6, vmin=0, vmax=1, cmap=\"gray\")\n",
    "axs[5].set_title(\"im_bin_6 (binary)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Grayscale Images](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient ramp with salt-pepper noise\n",
    "im_gray_1 = np.zeros((32, 32), dtype=np.float32)\n",
    "im_gray_1 += np.linspace(0, 1, 32).reshape(1, -1)  # Vertical ramp\n",
    "\n",
    "# add salt & pepper noise\n",
    "salt_mask = rng.random((32, 32)) < 0.05\n",
    "pepper_mask = rng.random((32, 32)) < 0.05\n",
    "im_gray_1[salt_mask] = 1.0\n",
    "im_gray_1[pepper_mask] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian hills with valley\n",
    "y, x = np.mgrid[-16:16, -16:16]\n",
    "im_gray_2 = np.exp(-(x**2 + y**2) / 50)  # base hill\n",
    "im_gray_2 += 0.7 * np.exp(-((x - 10) ** 2 + (y + 5) ** 2) / 30)  # right hill\n",
    "im_gray_2 -= 0.4 * np.exp(-((x + 5) ** 2 + y**2) / 20)  # valley\n",
    "im_gray_2 = (im_gray_2 - im_gray_2.min()) / (im_gray_2.max() - im_gray_2.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step edge with texture\n",
    "im_gray_3 = np.zeros((32, 32), dtype=np.float32)\n",
    "im_gray_3[:, 16:] = 0.8  # Step edge\n",
    "\n",
    "# add texture (high-frequency pattern)\n",
    "texture = rng.random((32, 32)) * 0.3\n",
    "texture[::2, ::2] += 0.2  # Grid-like pattern\n",
    "im_gray_3 = np.clip(im_gray_3 + texture, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sinusoidal waves\n",
    "x = np.arange(32)\n",
    "\n",
    "# vertical waves (column vector)\n",
    "vertical = 0.3 * np.sin(2 * np.pi * x / 8)\n",
    "\n",
    "# horizontal waves (row vector)\n",
    "horizontal = 0.2 * np.cos(2 * np.pi * x / 4)\n",
    "\n",
    "# add with proper broadcasting\n",
    "im_gray_4 = 0.5 + vertical[:, np.newaxis] + horizontal[np.newaxis, :]\n",
    "im_gray_4 = (im_gray_4 - im_gray_4.min()) / (im_gray_4.max() - im_gray_4.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# circular features with noise\n",
    "y, x = np.ogrid[-16:16, -16:16]\n",
    "im_gray_5 = np.zeros((32, 32))\n",
    "im_gray_5[x**2 + y**2 < 64] = 0.9  # bright disk (r=8)\n",
    "im_gray_5[(x - 8) ** 2 + (y + 8) ** 2 < 25] = 0.2  # dark disk (r=5)\n",
    "\n",
    "# add gaussian noise\n",
    "im_gray_5 += rng.normal(0, 0.1, (32, 32))\n",
    "im_gray_5 = np.clip(im_gray_5, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge line with gradual slope\n",
    "im_gray_6 = np.zeros((32, 32))\n",
    "for r in range(32):\n",
    "    im_gray_6[r, :] = 0.8 * np.exp(-((r - 16) ** 2) / 20)  # ridge center\n",
    "im_gray_6 += np.linspace(0, 0.3, 32).reshape(1, -1)  # Left-right gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=1, ncols=6, figsize=(24, 4), layout=\"compressed\")\n",
    "axs[0].imshow(im_gray_1, vmin=0, vmax=1, cmap=\"gray\")\n",
    "axs[0].set_title(\"im_gray_1 (grayscale)\")\n",
    "axs[1].imshow(im_gray_2, vmin=0, vmax=1, cmap=\"gray\")\n",
    "axs[1].set_title(\"im_gray_2 (grayscale)\")\n",
    "axs[2].imshow(im_gray_3, vmin=0, vmax=1, cmap=\"gray\")\n",
    "axs[2].set_title(\"im_gray_3 (grayscale)\")\n",
    "axs[3].imshow(im_gray_4, vmin=0, vmax=1, cmap=\"gray\")\n",
    "axs[3].set_title(\"im_gray_4 (grayscale)\")\n",
    "axs[4].imshow(im_gray_5, vmin=0, vmax=1, cmap=\"gray\")\n",
    "axs[4].set_title(\"im_gray_5 (grayscale)\")\n",
    "axs[5].imshow(im_gray_6, vmin=0, vmax=1, cmap=\"gray\")\n",
    "axs[5].set_title(\"im_gray_6 (grayscale)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[RGB Images](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB gradient with salt-pepper noise\n",
    "h, w = 32, 32\n",
    "im_rgb_1 = np.zeros((h, w, 3), dtype=np.float32)\n",
    "\n",
    "# R: vertical ramp + salt noise\n",
    "im_rgb_1[..., 0] = np.linspace(0, 1, w).reshape(1, -1)\n",
    "im_rgb_1[..., 0] += (rng.random((h, w)) < 0.05) * 0.8\n",
    "\n",
    "# G: horizontal ramp + pepper noise\n",
    "im_rgb_1[..., 1] = np.linspace(0, 1, h).reshape(-1, 1)\n",
    "im_rgb_1[..., 1] -= (rng.random((h, w)) < 0.05) * 0.6\n",
    "\n",
    "# B: diagonal gradient\n",
    "im_rgb_1[..., 2] = np.linspace(0, 1, h * w).reshape(h, w)\n",
    "\n",
    "im_rgb_1 = np.clip(im_rgb_1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlapping color shapes\n",
    "im_rgb_2 = np.zeros((32, 32, 3), dtype=np.float32)\n",
    "y, x = np.ogrid[-16:16, -16:16]\n",
    "\n",
    "# R: red square\n",
    "im_rgb_2[8:24, 4:20, 0] = 0.9\n",
    "\n",
    "# G: green circle (overlaps square)\n",
    "circle_mask = x**2 + y**2 < 64\n",
    "im_rgb_2[..., 1][circle_mask] = 0.7\n",
    "\n",
    "# B: blue triangle (overlaps both)\n",
    "for r in range(32):\n",
    "    im_rgb_2[r, max(0, 12 - r) : min(32, 20 + r), 2] = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-channel wave patterns\n",
    "x = np.arange(32)\n",
    "im_rgb_3 = np.zeros((32, 32, 3))\n",
    "\n",
    "# R: vertical waves\n",
    "im_rgb_3[..., 0] = 0.4 + 0.3 * np.sin(2 * np.pi * x / 8)[:, None]\n",
    "\n",
    "# G: horizontal waves\n",
    "im_rgb_3[..., 1] = 0.5 + 0.2 * np.cos(2 * np.pi * x / 6)[None, :]\n",
    "\n",
    "# B: diagonal waves\n",
    "im_rgb_3[..., 2] = 0.3 + 0.4 * np.sin(2 * np.pi * (x[:, None] + x[None, :]) / 10)\n",
    "\n",
    "im_rgb_3 = np.clip(im_rgb_3, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy color blobs with holes\n",
    "im_rgb_4 = np.zeros((32, 32, 3))\n",
    "centers = [(10, 10), (10, 22), (22, 16)]\n",
    "\n",
    "# create blobs per channel\n",
    "for c in range(3):\n",
    "    yc, xc = centers[c]\n",
    "    for y in range(32):\n",
    "        for x in range(32):\n",
    "            dist = np.sqrt((x - xc) ** 2 + (y - yc) ** 2)\n",
    "            im_rgb_4[y, x, c] = max(0, 0.8 - 0.05 * dist)\n",
    "\n",
    "    # add channel-specific holes\n",
    "    hole_size = 5 + c * 2\n",
    "    im_rgb_4[yc - 3 : yc + 3, xc - 3 : xc + 3, c] = 0\n",
    "\n",
    "    # add different noise per channel\n",
    "    noise = rng.random((32, 32)) * 0.3\n",
    "    if c == 0:  # salt only on red\n",
    "        noise[noise > 0.8] = 0.9\n",
    "    im_rgb_4[..., c] = np.clip(im_rgb_4[..., c] + noise, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(16, 4), layout=\"compressed\")\n",
    "axs[0].imshow(im_rgb_1, vmin=0, vmax=1)\n",
    "axs[0].set_title(\"im_rgb_1 (rgb)\")\n",
    "axs[1].imshow(im_rgb_2, vmin=0, vmax=1)\n",
    "axs[1].set_title(\"im_rgb_2 (rgb)\")\n",
    "axs[2].imshow(im_rgb_3, vmin=0, vmax=1)\n",
    "axs[2].set_title(\"im_rgb_3 (rgb)\")\n",
    "axs[3].imshow(im_rgb_4, vmin=0, vmax=1)\n",
    "axs[3].set_title(\"im_rgb_4 (rgb)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE NEED vector morphology to consider\n",
    "WHAT IS anisotropic MORPHOLOGY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Morphological Processing](#toc0_)\n",
    "\n",
    "- Morphological image processing refers to a set of operations that process images based on shapes.\n",
    "- These techniques are typically applied to binary images and rely on structuring elements to probe and transform input images.\n",
    "\n",
    "üìù **Docs**:\n",
    "- Morphological Transformations: [docs.opencv.org/master/d4/d76/tutorial_js_morphological_ops.html](https://docs.opencv.org/master/d4/d76/tutorial_js_morphological_ops.html)\n",
    "- Image Filtering: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaeb1e0c1033e3f6b891a25d0511362aeb](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaeb1e0c1033e3f6b891a25d0511362aeb)\n",
    "- `cv2.erode`: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaeb1e0c1033e3f6b891a25d0511362aeb](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaeb1e0c1033e3f6b891a25d0511362aeb)\n",
    "- `cv2.dilate`: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga4ff0f3318642c4f469d0e11f242f3b6c](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga4ff0f3318642c4f469d0e11f242f3b6c)\n",
    "- `cv2.morphologyEx`: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga67493776e3ad1a3df63883829375201f](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga67493776e3ad1a3df63883829375201f)\n",
    "- `cv2.getStructuringElement`: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gac342a1bb6eabf6f55c803b09268e36dc](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gac342a1bb6eabf6f55c803b09268e36dc)\n",
    "- `cv2.MorphTypes`: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga7be549266bad7b2e6a04db49827f9f32](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga7be549266bad7b2e6a04db49827f9f32)\n",
    "- `skimage.morphology`: [scikit-image.org/docs/stable/api/skimage.morphology.html](https://scikit-image.org/docs/stable/api/skimage.morphology.html)\n",
    "- `scipy.ndimage`: [docs.scipy.org/doc/scipy/reference/ndimage.html#morphology](https://docs.scipy.org/doc/scipy/reference/ndimage.html#morphology)\n",
    "- Multidimensional Image Processing: [docs.scipy.org/doc/scipy/tutorial/ndimage.html#morphology](https://docs.scipy.org/doc/scipy/tutorial/ndimage.html#morphology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[Structuring Elements](#toc0_)\n",
    "\n",
    "**Common Structuring Elements:**\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccccccc}\n",
    "\\begin{bmatrix}1 & 1 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1\\end{bmatrix}, &\n",
    "\\begin{bmatrix}0 & 1 & 0 \\\\ 1 & 1 & 1 \\\\ 0 & 1 & 0\\end{bmatrix}, &\n",
    "\\begin{bmatrix}0 & 0 & 0 \\\\ 1 & 1 & 1 \\\\ 0 & 0 & 0\\end{bmatrix}, &\n",
    "\\begin{bmatrix}0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 0\\end{bmatrix}, &\n",
    "\\begin{bmatrix}0 & 0 & 1 & 0 & 0 \\\\ 0 & 1 & 1 & 1 & 0 \\\\ 1 & 1 & 1 & 1 & 1 \\\\ 0 & 1 & 1 & 1 & 0 \\\\ 0 & 0 & 1 & 0 & 0\\end{bmatrix}, &\n",
    "\\begin{bmatrix}0 & 0 & 1 & 0 & 0 \\\\ 0 & 1 & 1 & 1 & 0 \\\\ 1 & 1 & 1 & 1 & 1 \\\\ 0 & 1 & 1 & 1 & 0 \\\\ 0 & 0 & 1 & 0 & 0\\end{bmatrix}, &\n",
    "\\begin{bmatrix}0 & 1 & 1 & 1 & 0 \\\\ 1 & 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 & 1 \\\\ 0 & 1 & 1 & 1 & 0\\end{bmatrix} \\\\\n",
    "\\text{(a)} & \\text{(b)} & \\text{(c)} & \\text{(d)} & \\text{(e)} & \\text{(f)} & \\text{(g)}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "- **(a) Square (Box)**: General-purpose operations, such as smoothing, noise removal, or filling small holes.\n",
    "- **(b) Cross**: Operations that require preserving connectivity or working with thin structures.\n",
    "- **(c) Line 1**:  Operations that involve directional features or linear structures.\n",
    "- **(d) Line 2 (Diagonal)**: Operations that involve directional features or linear structures.\n",
    "- **(e) Diamond**: Operations that require isotropic behavior but with a softer shape than a square.\n",
    "- **(f) Disk (radius = 2)**: Operations that require circular symmetry or rounded shapes.\n",
    "- **(g) Octagon (radius = 2)**: Operations that require a balance between square and disk shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_1_'></a>[Square](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_square2 = np.ones((2, 2), dtype=np.uint8)\n",
    "se_square3 = np.ones((3, 3), dtype=np.uint8)\n",
    "se_square5 = np.ones((5, 5), dtype=np.uint8)\n",
    "\n",
    "# log\n",
    "print(f\"se_square2:\\n{se_square2}\\n\")\n",
    "print(f\"se_square3:\\n{se_square3}\\n\")\n",
    "print(f\"se_square5:\\n{se_square5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_square3_ski = ski.morphology.footprint_rectangle((3, 3))\n",
    "se_square5_ski = ski.morphology.footprint_rectangle((5, 5))\n",
    "\n",
    "# log\n",
    "print(f\"se_square3_ski:\\n{se_square3_ski}\\n\")\n",
    "print(f\"se_square5_ski:\\n{se_square5_ski}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_2_'></a>[Disk (Circular)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_disk1 = ski.morphology.disk(1)\n",
    "se_disk3 = ski.morphology.disk(3)\n",
    "se_disk4 = ski.morphology.disk(4)\n",
    "se_disk5 = ski.morphology.disk(5)\n",
    "\n",
    "# log\n",
    "print(f\"se_disk1:\\n{se_disk1}\\n\")\n",
    "print(f\"se_disk3:\\n{se_disk3}\\n\")\n",
    "print(f\"se_disk4:\\n{se_disk4}\\n\")\n",
    "print(f\"se_disk5:\\n{se_disk5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_3_'></a>[Diamond](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_diamond1 = ski.morphology.diamond(1)\n",
    "se_diamond2 = ski.morphology.diamond(2)\n",
    "\n",
    "# log\n",
    "print(f\"se_diamond1:\\n{se_diamond1}\\n\")\n",
    "print(f\"se_diamond2:\\n{se_diamond2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_4_'></a>[Octagon](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_octagon3_3 = ski.morphology.octagon(3, 3)\n",
    "se_octagon4_2 = ski.morphology.octagon(4, 2)\n",
    "\n",
    "# log\n",
    "print(f\"se_octagon3_3:\\n{se_octagon3_3}\\n\")\n",
    "print(f\"se_octagon4_2:\\n{se_octagon4_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_5_'></a>[Line](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_line_h = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 1))\n",
    "se_line_v = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 7))\n",
    "\n",
    "# log\n",
    "print(f\"se_line_h:\\n{se_line_h}\\n\")\n",
    "print(f\"se_line_v:\\n{se_line_v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_line_45 = np.zeros((5, 5), dtype=np.uint8)\n",
    "cv2.line(se_line_45, (0, 4), (4, 0), 1, thickness=1)\n",
    "\n",
    "se_line_135 = np.zeros((7, 7), dtype=np.uint8)\n",
    "cv2.line(se_line_135, (0, 0), (6, 6), 1, thickness=1)\n",
    "\n",
    "# log\n",
    "print(f\"se_line_45:\\n{se_line_45}\\n\")\n",
    "print(f\"se_line_135:\\n{se_line_135}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_6_'></a>[Cross (Plus)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_cross3 = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]], dtype=np.uint8)\n",
    "\n",
    "# log\n",
    "print(f\"se_cross3:\\n{se_cross3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_cross3_ski = ski.morphology.diamond(1)\n",
    "\n",
    "# log\n",
    "print(f\"se_cross3_ski:\\n{se_cross3_ski}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_7_'></a>[Rectangle](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_rect_3x7 = ski.morphology.footprint_rectangle((3, 7))\n",
    "se_rect_7x3 = ski.morphology.footprint_rectangle((7, 3))\n",
    "\n",
    "# log\n",
    "print(f\"se_rect_3x7:\\n{se_rect_3x7}\\n\")\n",
    "print(f\"se_rect_7x3:\\n{se_rect_7x3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[Morphological Operators](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_1_'></a>[Erosion ($\\ominus$)](#toc0_)\n",
    "\n",
    "**Erosion** is a fundamental morphological operation that shrinks bright (foreground) regions in an image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erosion(image: NDArray, se: NDArray) -> NDArray:\n",
    "\n",
    "    H, W = image.shape\n",
    "    h, w = se.shape\n",
    "    pad_h = h // 2\n",
    "    pad_w = w // 2\n",
    "\n",
    "    # pad image with zeros on all sides\n",
    "    padded = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), mode=\"constant\", constant_values=0)\n",
    "\n",
    "    # precompute coordinates of SE‚Äôs 1‚Äêentries\n",
    "    se_coords = np.argwhere(se == 1)\n",
    "    offsets_i = se_coords[:, 0]\n",
    "    offsets_j = se_coords[:, 1]\n",
    "\n",
    "    eroded = np.empty((H, W), dtype=image.dtype)\n",
    "\n",
    "    # for each pixel in the original image, compute the min over the neighborhood\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            # window top-left in padded is (i, j), bottom-right (i+h‚àí1, j+w‚àí1)\n",
    "            # but we only sample positions where se == 1:\n",
    "            vals = padded[i + offsets_i, j + offsets_j]\n",
    "            eroded[i, j] = vals.min()\n",
    "\n",
    "    return eroded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_1_1_'></a>[Binary Erosion](#toc0_)\n",
    "- Shrinks foreground objects.\n",
    "- Removes small white noise and disconnects connected components.\n",
    "\n",
    "$$\n",
    "I \\ominus S = \\{ x \\mid S_x \\subseteq I \\}\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $I$: Input binary image  \n",
    "- $S$: Structuring element  \n",
    "- $S_x$: Structuring element translated to position $x$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_2_1_1_1_'></a>[Using OpenCV](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erode_bin_1 = cv2.erode(im_bin_1, se_line_45)\n",
    "erode_bin_2 = cv2.erode(im_bin_3, se_line_135)\n",
    "erode_bin_3 = cv2.erode(im_bin_5, se_square3)\n",
    "erode_bin_4 = cv2.erode(im_bin_6, se_diamond1)\n",
    "\n",
    "imgs = [im_bin_1, im_bin_3, im_bin_5, im_bin_6]\n",
    "erodes = [erode_bin_1, erode_bin_2, erode_bin_3, erode_bin_4]\n",
    "titles = [\"im_bin_1 & se_line_45\", \"im_bin_3 & se_line_135\", \"im_bin_5 & se_square3\", \"im_bin_6 & se_diamond1\"]\n",
    "\n",
    "# plot\n",
    "fig, axs = plt.subplots(3, len(erodes), figsize=(16, 12), layout=\"compressed\")\n",
    "for col, (img, erode, title) in enumerate(zip(imgs, erodes, titles)):\n",
    "    deleted_idx = (img == 1) & (erode == 0)\n",
    "    erode_rgb = np.stack([erode * 255] * 3, axis=-1)\n",
    "    erode_rgb[deleted_idx] = [255, 0, 0]\n",
    "    axs[0, col].imshow(img, cmap=\"gray\")\n",
    "    axs[0, col].set_title(\"Original\")\n",
    "    axs[1, col].imshow(erode_rgb)\n",
    "    axs[1, col].set_title(f\"Erosion: {title}\")\n",
    "    axs[2, col].imshow(erode, cmap=\"gray\")\n",
    "    axs[2, col].set_title(f\"Final image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_2_1_1_2_'></a>[Using Scikit-Image](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erode_bin_1 = ski.morphology.erosion(im_bin_1, footprint=se_line_45)\n",
    "erode_bin_2 = ski.morphology.erosion(im_bin_3, footprint=se_line_135)\n",
    "erode_bin_3 = ski.morphology.erosion(im_bin_5, footprint=se_square3)\n",
    "erode_bin_4 = ski.morphology.erosion(im_bin_6, footprint=se_diamond1)\n",
    "\n",
    "imgs = [im_bin_1, im_bin_3, im_bin_5, im_bin_6]\n",
    "erodes = [erode_bin_1, erode_bin_2, erode_bin_3, erode_bin_4]\n",
    "titles = [\"im_bin_1 & se_line_45\", \"im_bin_3 & se_line_135\", \"im_bin_5 & se_square3\", \"im_bin_6 & se_diamond1\"]\n",
    "\n",
    "# plot\n",
    "fig, axs = plt.subplots(3, len(erodes), figsize=(16, 12), layout=\"compressed\")\n",
    "for col, (img, erode, title) in enumerate(zip(imgs, erodes, titles)):\n",
    "    deleted_idx = (img == 1) & (erode == 0)\n",
    "    erode_rgb = np.stack([erode * 255] * 3, axis=-1)\n",
    "    erode_rgb[deleted_idx] = [255, 0, 0]\n",
    "    axs[0, col].imshow(img, cmap=\"gray\")\n",
    "    axs[0, col].set_title(\"Original\")\n",
    "    axs[1, col].imshow(erode_rgb)\n",
    "    axs[1, col].set_title(f\"Erosion: {title}\")\n",
    "    axs[2, col].imshow(erode, cmap=\"gray\")\n",
    "    axs[2, col].set_title(f\"Final image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_2_1_1_3_'></a>[Using SciPy](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erode_bin_1 = sp.ndimage.binary_erosion(im_bin_1, structure=se_line_45)\n",
    "erode_bin_2 = sp.ndimage.binary_erosion(im_bin_3, structure=se_line_135)\n",
    "erode_bin_3 = sp.ndimage.binary_erosion(im_bin_5, structure=se_square3)\n",
    "erode_bin_4 = sp.ndimage.binary_erosion(im_bin_6, structure=se_diamond1)\n",
    "\n",
    "imgs = [im_bin_1, im_bin_3, im_bin_5, im_bin_6]\n",
    "erodes = [erode_bin_1, erode_bin_2, erode_bin_3, erode_bin_4]\n",
    "titles = [\"im_bin_1 & se_line_45\", \"im_bin_3 & se_line_135\", \"im_bin_5 & se_square3\", \"im_bin_6 & se_diamond1\"]\n",
    "\n",
    "# plot\n",
    "fig, axs = plt.subplots(3, len(erodes), figsize=(16, 12), layout=\"compressed\")\n",
    "for col, (img, erode, title) in enumerate(zip(imgs, erodes, titles)):\n",
    "    deleted_idx = (img == 1) & (erode == 0)\n",
    "    erode_rgb = np.stack([erode * 255] * 3, axis=-1)\n",
    "    erode_rgb[deleted_idx] = [255, 0, 0]\n",
    "    axs[0, col].imshow(img, cmap=\"gray\")\n",
    "    axs[0, col].set_title(\"Original\")\n",
    "    axs[1, col].imshow(erode_rgb)\n",
    "    axs[1, col].set_title(f\"Erosion: {title}\")\n",
    "    axs[2, col].imshow(erode, cmap=\"gray\")\n",
    "    axs[2, col].set_title(f\"Final image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_1_2_'></a>[Grayscale Erosion](#toc0_)\n",
    "- Darkens bright regions by taking the local minimum.\n",
    "- Suppresses small bright spots and thins object boundaries.\n",
    "\n",
    "$$\n",
    "(I \\ominus S)(x) = \\min_{s \\in S} \\left[ I(x + s) - S(s) \\right]\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $I$: Input grayscale image  \n",
    "- $S$: Structuring element (can be flat or non-flat)  \n",
    "- $s$: Offset inside the structuring element\n",
    "\n",
    "> **Note:** For RGB images, erosion is typically applied **channel-wise** by treating each color channel (R, G, B) as a separate grayscale image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erode_gray_1 = cv2.erode(im_gray_1, se_disk1)\n",
    "erode_gray_2 = cv2.erode(im_gray_2, se_disk3)\n",
    "erode_gray_3 = cv2.erode(im_gray_3, se_square3)\n",
    "erode_gray_4 = cv2.erode(im_gray_4, se_square5)\n",
    "\n",
    "imgs_gray = [im_gray_1, im_gray_2, im_gray_3, im_gray_4]\n",
    "erodes_gray = [erode_gray_1, erode_gray_2, erode_gray_3, erode_gray_4]\n",
    "titles = [\"im_gray_1 & se_disk1\", \"im_gray_2 & se_disk3\", \"im_gray_3 & se_square3\", \"im_gray_4 & se_square5\"]\n",
    "\n",
    "fig, axs = plt.subplots(3, len(erodes_gray), figsize=(16, 12), layout=\"compressed\")\n",
    "for col, (img, erode, title) in enumerate(zip(imgs_gray, erodes_gray, titles)):\n",
    "    diff_img = np.abs(img.astype(np.float32) - erode)\n",
    "\n",
    "    axs[0, col].imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axs[0, col].set_title(\"Original Grayscale\")\n",
    "    axs[1, col].imshow(erode, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axs[1, col].set_title(f\"Erosion: {title}\")\n",
    "    axs[2, col].imshow(diff_img, cmap=\"hot\", vmin=0, vmax=1)\n",
    "    axs[2, col].set_title(\"Absolute difference\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_2_'></a>[Dilation ($\\oplus$)](#toc0_)\n",
    "\n",
    "**Dilation** is a fundamental morphological operation that expands bright (foreground) regions in an image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilation(image: NDArray, se: NDArray) -> NDArray:\n",
    "\n",
    "    H, W = image.shape\n",
    "    h, w = se.shape\n",
    "    pad_h = h // 2\n",
    "    pad_w = w // 2\n",
    "\n",
    "    # pad image with zeros on all sides\n",
    "    padded = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), mode=\"constant\", constant_values=0)\n",
    "\n",
    "    # precompute coordinates of SE‚Äôs 1‚Äêentries\n",
    "    se_coords = np.argwhere(se == 1)\n",
    "    offsets_i = se_coords[:, 0]\n",
    "    offsets_j = se_coords[:, 1]\n",
    "\n",
    "    dilated = np.empty((H, W), dtype=image.dtype)\n",
    "\n",
    "    # for each pixel in the original image, compute the max over the neighborhood\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            vals = padded[i + offsets_i, j + offsets_j]\n",
    "            dilated[i, j] = vals.max()\n",
    "\n",
    "    return dilated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_2_1_'></a>[Binary Dilation](#toc0_)\n",
    "- Expands foreground objects.\n",
    "- Fills small holes and connects nearby objects.\n",
    "\n",
    "$$\n",
    "I \\oplus S = \\{ x \\mid (SÃÇ)_x \\cap I \\neq \\emptyset \\}\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $I$: Input binary image  \n",
    "- $S$: Structuring element  \n",
    "- $SÃÇ$: Reflection of structuring element $S$  \n",
    "- $(SÃÇ)_x$: Reflected structuring element translated to position $x$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilate_bin_1 = cv2.dilate(im_bin_2, se_square3)\n",
    "dilate_bin_2 = cv2.dilate(im_bin_3, se_line_45)\n",
    "dilate_bin_3 = cv2.dilate(im_bin_5, se_disk1)\n",
    "dilate_bin_4 = cv2.dilate(im_bin_6, se_diamond1)\n",
    "\n",
    "imgs = [im_bin_2, im_bin_3, im_bin_5, im_bin_6]\n",
    "dilates = [dilate_bin_1, dilate_bin_2, dilate_bin_3, dilate_bin_4]\n",
    "titles = [\"im_bin_2 & se_square3\", \"im_bin_3 & se_line_45\", \"im_bin_5 & se_disk1\", \"im_bin_6 & se_diamond1\"]\n",
    "\n",
    "fig, axs = plt.subplots(3, len(dilates), figsize=(16, 12), layout=\"compressed\")\n",
    "for col, (img, dilate, title) in enumerate(zip(imgs, dilates, titles)):\n",
    "    added_idx = (img == 0) & (dilate == 1)\n",
    "    dilate_rgb = np.stack([dilate * 255] * 3, axis=-1)\n",
    "    dilate_rgb[added_idx] = [0, 255, 0]\n",
    "\n",
    "    axs[0, col].imshow(img, cmap=\"gray\")\n",
    "    axs[0, col].set_title(\"Original\")\n",
    "    axs[1, col].imshow(dilate_rgb)\n",
    "    axs[1, col].set_title(f\"Dilation: {title}\")\n",
    "    axs[2, col].imshow(dilate, cmap=\"gray\")\n",
    "    axs[2, col].set_title(\"Final image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_2_2_'></a>[Grayscale Dilation](#toc0_)\n",
    "- Brightens regions by taking the local maximum.\n",
    "- Fills small dark spots and thickens object boundaries.\n",
    "\n",
    "$$\n",
    "(I \\oplus S)(x) = \\max_{s \\in S} \\left[ I(x - s) + S(s) \\right]\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $I$: Input grayscale image  \n",
    "- $S$: Structuring element (can be flat or non-flat)  \n",
    "- $s$: Offset inside the structuring element\n",
    "\n",
    "> **Note:** For RGB images, dilation is typically applied **channel-wise** by treating each color channel (R, G, B) as a separate grayscale image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilate_gray_1 = cv2.dilate(im_gray_1, se_disk1)\n",
    "dilate_gray_2 = cv2.dilate(im_gray_2, se_disk3)\n",
    "dilate_gray_3 = cv2.dilate(im_gray_3, se_square3)\n",
    "dilate_gray_4 = cv2.dilate(im_gray_4, se_square5)\n",
    "\n",
    "imgs_gray = [im_gray_1, im_gray_2, im_gray_3, im_gray_4]\n",
    "dilates_gray = [dilate_gray_1, dilate_gray_2, dilate_gray_3, dilate_gray_4]\n",
    "titles = [\"im_gray_1 & se_disk1\", \"im_gray_2 & se_disk3\", \"im_gray_3 & se_square3\", \"im_gray_4 & se_square5\"]\n",
    "\n",
    "fig, axs = plt.subplots(3, len(dilates_gray), figsize=(16, 12), layout=\"compressed\")\n",
    "for col, (img, dilate, title) in enumerate(zip(imgs_gray, dilates_gray, titles)):\n",
    "    diff_img = np.abs(dilate - img.astype(np.float32))\n",
    "\n",
    "    axs[0, col].imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axs[0, col].set_title(\"Original Grayscale\")\n",
    "    axs[1, col].imshow(dilate, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axs[1, col].set_title(f\"Dilation: {title}\")\n",
    "    axs[2, col].imshow(diff_img, cmap=\"hot\", vmin=0, vmax=1)\n",
    "    axs[2, col].set_title(\"Absolute difference\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_3_'></a>[Opening ($\\circ$)](#toc0_)\n",
    "\n",
    "**Opening** is a morphological operation that smooths object contours, removes small objects, and separates objects that are close together by performing erosion followed by dilation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opening(image: NDArray, se: NDArray) -> NDArray:\n",
    "    eroded = erosion(image, se)\n",
    "    opened = dilation(eroded, se)\n",
    "    return opened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_3_1_'></a>[Binary Opening](#toc0_)\n",
    "- Removes small foreground objects (noise).\n",
    "- Smooths object boundaries without significantly changing their area.\n",
    "\n",
    "$$\n",
    "I \\circ S = (I \\ominus S) \\oplus S\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $I$: Input binary image  \n",
    "- $S$: Structuring element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_bin_1 = cv2.morphologyEx(im_bin_4, cv2.MORPH_OPEN, se_square3)\n",
    "open_bin_2 = cv2.morphologyEx(im_bin_6, cv2.MORPH_OPEN, se_diamond1)\n",
    "open_bin_3 = cv2.morphologyEx(im_bin_3, cv2.MORPH_OPEN, se_line_45)\n",
    "open_bin_4 = cv2.morphologyEx(im_bin_2, cv2.MORPH_OPEN, se_disk1)\n",
    "\n",
    "imgs = [im_bin_4, im_bin_6, im_bin_3, im_bin_2]\n",
    "opens = [open_bin_1, open_bin_2, open_bin_3, open_bin_4]\n",
    "titles = [\"im_bin_4 & se_square3\", \"im_bin_6 & se_diamond1\", \"im_bin_3 & se_line_45\", \"im_bin_2 & se_disk1\"]\n",
    "\n",
    "fig, axs = plt.subplots(3, len(opens), figsize=(16, 12), layout=\"compressed\")\n",
    "for col, (img, open_img, title) in enumerate(zip(imgs, opens, titles)):\n",
    "    deleted_idx = (img == 1) & (open_img == 0)\n",
    "    open_rgb = np.stack([open_img * 255] * 3, axis=-1)\n",
    "    open_rgb[deleted_idx] = [255, 0, 0]\n",
    "\n",
    "    axs[0, col].imshow(img, cmap=\"gray\")\n",
    "    axs[0, col].set_title(\"Original\")\n",
    "    axs[1, col].imshow(open_rgb)\n",
    "    axs[1, col].set_title(f\"Opening: {title}\")\n",
    "    axs[2, col].imshow(open_img, cmap=\"gray\")\n",
    "    axs[2, col].set_title(\"Final image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_3_2_'></a>[Grayscale Opening](#toc0_)\n",
    "- Removes small bright spots and smooths contours.\n",
    "- Preserves overall shape but eliminates small details.\n",
    "\n",
    "$$\n",
    "(I \\circ S)(x) = \\left( (I \\ominus S) \\oplus S \\right)(x)\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $I$: Input grayscale image  \n",
    "- $S$: Structuring element\n",
    "\n",
    "> **Note:** For RGB images, opening is typically applied **channel-wise** by treating each color channel (R, G, B) as a separate grayscale image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_gray_1 = cv2.morphologyEx(im_gray_1, cv2.MORPH_OPEN, se_disk1)\n",
    "open_gray_2 = cv2.morphologyEx(im_gray_3, cv2.MORPH_OPEN, se_square3)\n",
    "open_gray_3 = cv2.morphologyEx(im_gray_4, cv2.MORPH_OPEN, se_square5)\n",
    "open_gray_4 = cv2.morphologyEx(im_gray_5, cv2.MORPH_OPEN, se_disk1)\n",
    "\n",
    "imgs_gray = [im_gray_1, im_gray_3, im_gray_4, im_gray_5]\n",
    "opens_gray = [open_gray_1, open_gray_2, open_gray_3, open_gray_4]\n",
    "titles = [\"im_gray_1 & se_disk1\", \"im_gray_3 & se_square3\", \"im_gray_4 & se_square5\", \"im_gray_5 & se_disk1\"]\n",
    "\n",
    "fig, axs = plt.subplots(3, len(opens_gray), figsize=(16, 12), layout=\"compressed\")\n",
    "for col, (img, opened, title) in enumerate(zip(imgs_gray, opens_gray, titles)):\n",
    "    diff_img = np.abs(img.astype(np.float32) - opened)\n",
    "\n",
    "    axs[0, col].imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axs[0, col].set_title(\"Original Grayscale\")\n",
    "    axs[1, col].imshow(opened, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axs[1, col].set_title(f\"Opening: {title}\")\n",
    "    axs[2, col].imshow(diff_img, cmap=\"hot\", vmin=0, vmax=1)\n",
    "    axs[2, col].set_title(\"Absolute difference\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_4_'></a>[Closing ($\\bullet$)](#toc0_)\n",
    "\n",
    "**Closing** is a morphological operation that smooths object contours, fills small holes, and connects nearby objects by performing dilation followed by erosion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closing(image: NDArray, se: NDArray) -> NDArray:\n",
    "    dilated = dilation(image, se)\n",
    "    closed = erosion(dilated, se)\n",
    "    return closed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_4_1_'></a>[Binary Closing](#toc0_)\n",
    "- Fills small holes and gaps inside foreground objects.\n",
    "- Connects nearby objects without significantly changing their area.\n",
    "\n",
    "$$\n",
    "I \\bullet S = (I \\oplus S) \\ominus S\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $I$: Input binary image  \n",
    "- $S$: Structuring element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_bin_1 = cv2.morphologyEx(im_bin_5, cv2.MORPH_CLOSE, se_disk1)\n",
    "close_bin_2 = cv2.morphologyEx(im_bin_2, cv2.MORPH_CLOSE, se_square3)\n",
    "close_bin_3 = cv2.morphologyEx(im_bin_1, cv2.MORPH_CLOSE, se_disk3)\n",
    "close_bin_4 = cv2.morphologyEx(im_bin_6, cv2.MORPH_CLOSE, se_diamond1)\n",
    "\n",
    "imgs = [im_bin_5, im_bin_2, im_bin_1, im_bin_6]\n",
    "closes = [close_bin_1, close_bin_2, close_bin_3, close_bin_4]\n",
    "titles = [\"im_bin_5 & se_line_45\", \"im_bin_2 & se_line_135\", \"im_bin_1 & se_square3\", \"im_bin_6 & se_diamond1\"]\n",
    "\n",
    "fig, axs = plt.subplots(3, len(closes), figsize=(16, 12), layout=\"compressed\")\n",
    "for col, (img, close_img, title) in enumerate(zip(imgs, closes, titles)):\n",
    "    added_idx = (img == 0) & (close_img == 1)\n",
    "    close_rgb = np.stack([close_img * 255] * 3, axis=-1)\n",
    "    close_rgb[added_idx] = [0, 255, 0]\n",
    "\n",
    "    axs[0, col].imshow(img, cmap=\"gray\")\n",
    "    axs[0, col].set_title(\"Original\")\n",
    "    axs[1, col].imshow(close_rgb)\n",
    "    axs[1, col].set_title(f\"Closing: {title}\")\n",
    "    axs[2, col].imshow(close_img, cmap=\"gray\")\n",
    "    axs[2, col].set_title(\"Final image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_4_2_'></a>[Grayscale Closing](#toc0_)\n",
    "- Fills small dark spots and smooths contours.\n",
    "- Preserves overall shape but fills small gaps.\n",
    "\n",
    "$$\n",
    "(I \\bullet S)(x) = \\left( (I \\oplus S) \\ominus S \\right)(x)\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $I$: Input grayscale image  \n",
    "- $S$: Structuring element\n",
    "\n",
    "> **Note:** For RGB images, closing is typically applied **channel-wise** by treating each color channel (R, G, B) as a separate grayscale image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_gray_1 = cv2.morphologyEx(im_gray_1, cv2.MORPH_CLOSE, se_disk1)\n",
    "close_gray_2 = cv2.morphologyEx(im_gray_2, cv2.MORPH_CLOSE, se_disk3)\n",
    "close_gray_3 = cv2.morphologyEx(im_gray_3, cv2.MORPH_CLOSE, se_square3)\n",
    "close_gray_4 = cv2.morphologyEx(im_gray_4, cv2.MORPH_CLOSE, se_square5)\n",
    "\n",
    "imgs_gray = [im_gray_1, im_gray_2, im_gray_3, im_gray_4]\n",
    "closes_gray = [close_gray_1, close_gray_2, close_gray_3, close_gray_4]\n",
    "titles = [\"im_gray_1 & se_disk1\", \"im_gray_2 & se_disk3\", \"im_gray_3 & se_square3\", \"im_gray_4 & se_square5\"]\n",
    "\n",
    "fig, axs = plt.subplots(3, len(closes_gray), figsize=(16, 12), layout=\"compressed\")\n",
    "for col, (img, closed, title) in enumerate(zip(imgs_gray, closes_gray, titles)):\n",
    "    diff_img = np.abs(img.astype(np.float32) - closed)\n",
    "\n",
    "    axs[0, col].imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axs[0, col].set_title(\"Original Grayscale\")\n",
    "    axs[1, col].imshow(closed, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axs[1, col].set_title(f\"Closing: {title}\")\n",
    "    axs[2, col].imshow(diff_img, cmap=\"hot\", vmin=0, vmax=1)\n",
    "    axs[2, col].set_title(\"Absolute difference\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_5_'></a>[Gradient ($\\nabla$)](#toc0_)\n",
    "\n",
    "**Morphological Gradient** is an operator that extracts object boundaries by computing the difference between dilation and erosion of the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(image: NDArray, se: NDArray) -> NDArray:\n",
    "    dil = dilation(image, se)\n",
    "    ero = erosion(image, se)\n",
    "    grad = dil - ero\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_5_1_'></a>[Binary Gradient](#toc0_)\n",
    "- Highlights the edges of objects in a binary image.\n",
    "- Useful for boundary detection and shape analysis.\n",
    "\n",
    "$$\n",
    "\\nabla I = (I \\oplus S) - (I \\ominus S)\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $I$: Input binary image  \n",
    "- $S$: Structuring element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_bin_1 = cv2.morphologyEx(im_bin_1, cv2.MORPH_GRADIENT, se_square3)\n",
    "grad_bin_2 = cv2.morphologyEx(im_bin_3, cv2.MORPH_GRADIENT, se_disk1)\n",
    "grad_bin_3 = cv2.morphologyEx(im_bin_5, cv2.MORPH_GRADIENT, se_square2)\n",
    "grad_bin_4 = cv2.morphologyEx(im_bin_6, cv2.MORPH_GRADIENT, se_square2)\n",
    "\n",
    "imgs = [im_bin_1, im_bin_3, im_bin_5, im_bin_6]\n",
    "grads = [grad_bin_1, grad_bin_2, grad_bin_3, grad_bin_4]\n",
    "titles = [\"im_bin_1 & se_square3\", \"im_bin_3 & se_disk1\", \"im_bin_5 & se_square2\", \"im_bin_6 & se_diamond1\"]\n",
    "\n",
    "fig, axs = plt.subplots(2, len(grads), figsize=(16, 8), layout=\"compressed\")\n",
    "for col, (img, grad_img, title) in enumerate(zip(imgs, grads, titles)):\n",
    "    axs[0, col].imshow(img, cmap=\"gray\")\n",
    "    axs[0, col].set_title(\"Original\")\n",
    "    axs[1, col].imshow(grad_img, cmap=\"gray\")\n",
    "    axs[1, col].set_title(\"Edges highlighted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_5_2_'></a>[Grayscale Gradient](#toc0_)\n",
    "- Emphasizes transitions or edges in grayscale images.\n",
    "- Helps in edge detection while preserving shape.\n",
    "\n",
    "$$\n",
    "(\\nabla I)(x) = \\left( (I \\oplus S) - (I \\ominus S) \\right)(x)\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $I$: Input grayscale image  \n",
    "- $S$: Structuring element\n",
    "\n",
    "> **Note:** For RGB images, the gradient is usually applied **channel-wise** by processing each channel separately (R, G, B).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_gray_1 = cv2.morphologyEx(im_gray_1, cv2.MORPH_GRADIENT, se_square3)\n",
    "gradient_gray_2 = cv2.morphologyEx(im_gray_2, cv2.MORPH_GRADIENT, se_disk3)\n",
    "gradient_gray_3 = cv2.morphologyEx(im_gray_3, cv2.MORPH_GRADIENT, se_square3)\n",
    "gradient_gray_4 = cv2.morphologyEx(im_gray_4, cv2.MORPH_GRADIENT, se_square5)\n",
    "\n",
    "imgs_gray = [im_gray_1, im_gray_2, im_gray_3, im_gray_4]\n",
    "gradients_gray = [gradient_gray_1, gradient_gray_2, gradient_gray_3, gradient_gray_4]\n",
    "titles = [\"im_gray_1 & se_square3\", \"im_gray_2 & se_disk3\", \"im_gray_3 & se_square3\", \"im_gray_4 & se_square5\"]\n",
    "\n",
    "fig, axs = plt.subplots(3, len(gradients_gray), figsize=(16, 12), layout=\"compressed\")\n",
    "for col, (img, gradient, title) in enumerate(zip(imgs_gray, gradients_gray, titles)):\n",
    "    diff_img = np.abs(img.astype(np.float32) - gradient)\n",
    "\n",
    "    axs[0, col].imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axs[0, col].set_title(\"Original Grayscale\")\n",
    "    axs[1, col].imshow(gradient, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axs[1, col].set_title(f\"Gradient: {title}\")\n",
    "    axs[2, col].imshow(diff_img, cmap=\"hot\", vmin=0, vmax=1)\n",
    "    axs[2, col].set_title(\"Absolute difference\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_6_'></a>[Top-Hat ($\\text{TH}$)](#toc0_)\n",
    "\n",
    "**Top-Hat** transformation extracts small bright features that are smaller than the structuring element by subtracting the opened image from the original.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_hat(image: NDArray, se: NDArray) -> NDArray:\n",
    "    opened = opening(image, se)\n",
    "    th = image - opened\n",
    "    return th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_6_1_'></a>[Binary Top-Hat](#toc0_)\n",
    "- Extracts small bright objects or details.\n",
    "- Useful for enhancing bright spots on a dark background.\n",
    "\n",
    "$$\n",
    "\\text{TH}(I) = I - (I \\circ S)\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $I$: Input binary image  \n",
    "- $S$: Structuring element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tophat_bin_1 = cv2.morphologyEx(im_bin_4, cv2.MORPH_TOPHAT, se_square3)\n",
    "tophat_bin_2 = cv2.morphologyEx(im_bin_6, cv2.MORPH_TOPHAT, se_diamond1)\n",
    "tophat_bin_3 = cv2.morphologyEx(im_bin_3, cv2.MORPH_TOPHAT, se_square3)\n",
    "tophat_bin_4 = cv2.morphologyEx(im_bin_2, cv2.MORPH_TOPHAT, se_disk4)\n",
    "\n",
    "imgs = [im_bin_4, im_bin_6, im_bin_3, im_bin_2]\n",
    "tophats = [tophat_bin_1, tophat_bin_2, tophat_bin_3, tophat_bin_4]\n",
    "titles = [\"im_bin_4 & se_square3\", \"im_bin_6 & se_diamond1\", \"im_bin_3 & se_square3\", \"im_bin_2 & se_disk4\"]\n",
    "\n",
    "fig, axs = plt.subplots(2, len(tophats), figsize=(16, 8), layout=\"compressed\")\n",
    "for col, (img, tophat_img, title) in enumerate(zip(imgs, tophats, titles)):\n",
    "    highlight_idx = tophat_img > 0\n",
    "    tophat_rgb = np.zeros((*tophat_img.shape, 3), dtype=np.uint8)\n",
    "    tophat_rgb[highlight_idx] = [255, 0, 0]\n",
    "\n",
    "    axs[0, col].imshow(img, cmap=\"gray\")\n",
    "    axs[0, col].set_title(\"Original\")\n",
    "    axs[1, col].imshow(tophat_rgb)\n",
    "    axs[1, col].set_title(f\"Top-Hat: {title}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_6_2_'></a>[Grayscale Top-Hat](#toc0_)\n",
    "- Highlights small bright regions in grayscale images.\n",
    "- Helps in background correction and feature extraction.\n",
    "\n",
    "$$\n",
    "(\\text{TH}(I))(x) = I(x) - \\left( (I \\circ S) \\right)(x)\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $I$: Input grayscale image  \n",
    "- $S$: Structuring element\n",
    "\n",
    "> **Note:** For RGB images, top-hat is typically applied **channel-wise** by processing each color channel separately (R, G, B).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply grayscale Top-Hat (original - opening)\n",
    "tophat_gray_1 = cv2.morphologyEx(im_gray_1, cv2.MORPH_TOPHAT, se_disk1)\n",
    "tophat_gray_2 = cv2.morphologyEx(im_gray_3, cv2.MORPH_TOPHAT, se_square3)\n",
    "tophat_gray_3 = cv2.morphologyEx(im_gray_5, cv2.MORPH_TOPHAT, se_disk5)\n",
    "tophat_gray_4 = cv2.morphologyEx(im_gray_2, cv2.MORPH_TOPHAT, se_disk3)\n",
    "\n",
    "imgs_gray = [im_gray_1, im_gray_3, im_gray_5, im_gray_2]\n",
    "tophats_gray = [tophat_gray_1, tophat_gray_2, tophat_gray_3, tophat_gray_4]\n",
    "titles = [\"im_gray_1 & se_disk1\", \"im_gray_3 & se_square3\", \"im_gray_5 & se_disk5\", \"im_gray_2 & se_disk3\"]\n",
    "\n",
    "fig, axs = plt.subplots(3, len(tophats_gray), figsize=(16, 12), layout=\"compressed\")\n",
    "for col, (img, tophat, title) in enumerate(zip(imgs_gray, tophats_gray, titles)):\n",
    "    diff_img = np.abs(img.astype(np.float32) - tophat)\n",
    "\n",
    "    axs[0, col].imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axs[0, col].set_title(\"Original Grayscale\")\n",
    "    axs[1, col].imshow(tophat, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axs[1, col].set_title(f\"Top-Hat: {title}\")\n",
    "    axs[2, col].imshow(diff_img, cmap=\"hot\", vmin=0, vmax=1)\n",
    "    axs[2, col].set_title(\"Absolute difference\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_7_'></a>[Black-Hat ($\\text{BH}$)](#toc0_)\n",
    "\n",
    "**Black-Hat** transformation extracts small dark features that are smaller than the structuring element by subtracting the original image from its closing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_hat(image: NDArray, se: NDArray) -> NDArray:\n",
    "    closed = closing(image, se)\n",
    "    bh = closed - image\n",
    "    return bh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_7_1_'></a>[Binary Black-Hat](#toc0_)\n",
    "- Extracts small dark spots or holes.\n",
    "- Useful for detecting dark features on a bright background.\n",
    "\n",
    "$$\n",
    "\\text{BH}(I) = (I \\bullet S) - I\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $I$: Input binary image  \n",
    "- $S$: Structuring element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackhat_bin_1 = cv2.morphologyEx(im_bin_5, cv2.MORPH_BLACKHAT, se_disk1)\n",
    "blackhat_bin_2 = cv2.morphologyEx(im_bin_1, cv2.MORPH_BLACKHAT, se_disk3)\n",
    "blackhat_bin_3 = cv2.morphologyEx(im_bin_6, cv2.MORPH_BLACKHAT, se_diamond1)\n",
    "blackhat_bin_4 = cv2.morphologyEx(im_bin_2, cv2.MORPH_BLACKHAT, se_square3)\n",
    "\n",
    "imgs = [im_bin_5, im_bin_1, im_bin_6, im_bin_2]\n",
    "blackhats = [blackhat_bin_1, blackhat_bin_2, blackhat_bin_3, blackhat_bin_4]\n",
    "titles = [\"im_bin_5 & se_disk1\", \"im_bin_1 & se_disk3\", \"im_bin_6 & se_diamond1\", \"im_bin_2 & se_square3\"]\n",
    "\n",
    "fig, axs = plt.subplots(2, len(blackhats), figsize=(16, 8), layout=\"compressed\")\n",
    "for col, (img, blackhat_img, title) in enumerate(zip(imgs, blackhats, titles)):\n",
    "    highlight_idx = blackhat_img > 0\n",
    "    blackhat_rgb = np.zeros((*blackhat_img.shape, 3), dtype=np.uint8)\n",
    "    blackhat_rgb[highlight_idx] = [0, 255, 0]\n",
    "\n",
    "    axs[0, col].imshow(img, cmap=\"gray\")\n",
    "    axs[0, col].set_title(\"Original\")\n",
    "    axs[1, col].imshow(blackhat_rgb)\n",
    "    axs[1, col].set_title(f\"Black-Hat: {title}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_7_2_'></a>[Grayscale Black-Hat](#toc0_)\n",
    "- Highlights small dark regions in grayscale images.\n",
    "- Helps in detecting dark details and correcting uneven illumination.\n",
    "\n",
    "$$\n",
    "(\\text{BH}(I))(x) = \\left( (I \\bullet S) \\right)(x) - I(x)\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $I$: Input grayscale image  \n",
    "- $S$: Structuring element\n",
    "\n",
    "> **Note:** For RGB images, black-hat is usually applied **channel-wise** by processing each channel separately (R, G, B).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply grayscale Black-Hat (closing - original)\n",
    "blackhat_gray_1 = cv2.morphologyEx(im_gray_1, cv2.MORPH_BLACKHAT, se_disk1)\n",
    "blackhat_gray_2 = cv2.morphologyEx(im_gray_2, cv2.MORPH_BLACKHAT, se_disk3)\n",
    "blackhat_gray_3 = cv2.morphologyEx(im_gray_3, cv2.MORPH_BLACKHAT, se_square3)\n",
    "blackhat_gray_4 = cv2.morphologyEx(im_gray_5, cv2.MORPH_BLACKHAT, se_disk5)\n",
    "\n",
    "imgs_gray = [im_gray_1, im_gray_2, im_gray_3, im_gray_5]\n",
    "blackhats_gray = [blackhat_gray_1, blackhat_gray_2, blackhat_gray_3, blackhat_gray_4]\n",
    "titles = [\"im_gray_1 & se_disk1\", \"im_gray_2 & se_disk3\", \"im_gray_3 & se_square3\", \"im_gray_5 & se_disk5\"]\n",
    "\n",
    "fig, axs = plt.subplots(3, len(blackhats_gray), figsize=(16, 12), layout=\"compressed\")\n",
    "for col, (img, blackhat, title) in enumerate(zip(imgs_gray, blackhats_gray, titles)):\n",
    "    diff_img = np.abs(img.astype(np.float32) - blackhat)\n",
    "\n",
    "    axs[0, col].imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axs[0, col].set_title(\"Original Grayscale\")\n",
    "    axs[1, col].imshow(blackhat, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axs[1, col].set_title(f\"Black-Hat: {title}\")\n",
    "    axs[2, col].imshow(diff_img, cmap=\"hot\", vmin=0, vmax=1)\n",
    "    axs[2, col].set_title(\"Absolute difference\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "media-processing-workshop (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "origin_repo": "https://github.com/mr-pylin/media-processing-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
