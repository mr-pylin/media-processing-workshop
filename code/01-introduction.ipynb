{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
    "    <div style=\"text-align: left; flex: 4;\">\n",
    "        <strong>Author:</strong> Amirhossein Heydari ‚Äî \n",
    "        üìß <a href=\"mailto:amirhosseinheydari78@gmail.com\">amirhosseinheydari78@gmail.com</a> ‚Äî \n",
    "        üêô <a href=\"https://github.com/mr-pylin/media-processing-workshop\" target=\"_blank\" rel=\"noopener\">github.com/mr-pylin</a>\n",
    "    </div>\n",
    "    <div style=\"display: flex; justify-content: flex-end; flex: 1; gap: 8px; align-items: center; padding: 0;\">\n",
    "        <a href=\"https://opencv.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/libraries/opencv/logo/OpenCV_logo_no_text-1.svg\"\n",
    "                 alt=\"OpenCV Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "        <a href=\"https://pillow.readthedocs.io/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/libraries/pillow/logo/pillow-logo-248x250.png\"\n",
    "                 alt=\"PIL Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "        <a href=\"https://scikit-image.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/libraries/scikit-image/logo/logo.png\"\n",
    "                 alt=\"scikit-image Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "        <a href=\"https://scipy.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/libraries/scipy/logo/logo.svg\"\n",
    "                 alt=\"SciPy Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "    </div>\n",
    "</div>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Introduction](#toc1_)    \n",
    "  - [üì∑ Analog Image](#toc1_1_)    \n",
    "    - [üü¢ What makes an image analog](#toc1_1_1_)    \n",
    "    - [üåà Continuous light, color, and intensity in the real world](#toc1_1_2_)    \n",
    "    - [üìù Examples of analog imaging systems](#toc1_1_3_)    \n",
    "  - [üéõÔ∏è Analog to Digital - Capturing Using Sensors](#toc1_2_)    \n",
    "    - [üí° How cameras sense light](#toc1_2_1_)    \n",
    "    - [üü¢ Pixels, sampling, and quantization (intuitive view)](#toc1_2_2_)    \n",
    "    - [üé¶ Sensor architectures (CCD, CMOS, Foveon)](#toc1_2_3_)    \n",
    "    - [üé® Color filter arrays and demosaicing](#toc1_2_4_)    \n",
    "  - [üñºÔ∏è Digital Image](#toc1_3_)    \n",
    "    - [üìè Pixel representation and resolution](#toc1_3_1_)    \n",
    "    - [üé® Bit depth and color channels](#toc1_3_2_)    \n",
    "    - [üñäÔ∏è Raster vs. vector images](#toc1_3_3_)    \n",
    "    - [üíæ Common file formats (JPEG, PNG, TIFF, SVG‚Ä¶)](#toc1_3_4_)    \n",
    "    - [üåà Color spaces in simple terms (RGB, HSV, YCbCr, CMYK)](#toc1_3_5_)    \n",
    "  - [üñ•Ô∏è Visualization a Digital Image](#toc1_4_)    \n",
    "    - [üí° How digital images appear on screens](#toc1_4_1_)    \n",
    "    - [‚ö° Display pipeline (basic idea)](#toc1_4_2_)    \n",
    "    - [üì∫ Overview of display technologies (LCD, LED, OLED, E-Ink)](#toc1_4_3_)    \n",
    "    - [üé® Factors affecting perceived image quality (contrast, brightness, gamut)](#toc1_4_4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Introduction](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[üì∑ Analog Image](#toc0_)\n",
    "\n",
    "- An **analog image** is a continuous visual signal ‚Äî intensity and color vary smoothly across space without discrete pixels or numeric encoding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[üü¢ What makes an image analog](#toc0_)\n",
    "\n",
    "- No fixed sampling grid: values exist for every point in space.\n",
    "- Continuous variation of radiance, color, and intensity.\n",
    "- Examples: photographic film, direct optical patterns, real-world scene radiance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_2_'></a>[üåà Continuous light, color, and intensity in the real world](#toc0_)\n",
    "\n",
    "- Scene radiance is a function of position and wavelength (intuitively: ‚Äúhow much light each tiny point emits/reflected‚Äù).\n",
    "- Human perception samples this continuous field through the eye; cameras sample it with sensors.\n",
    "- Important intuitive consequences: aliasing only appears after sampling; infinitely fine detail is a theoretical property of analog signals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_3_'></a>[üìù Examples of analog imaging systems](#toc0_)\n",
    "\n",
    "- **Film photography:** silver-halide crystals produce continuous-tone images (perceived as continuous).  \n",
    "- **Optical projection:** lenses projecting light patterns (movie projector, slide projector).  \n",
    "- **Human vision / retina:** biological sensing of continuous light (sampled by neural processes).  \n",
    "- **Specialized analog sensors:** older analog video cameras, oscilloscope traces, etc.\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; gap: 20px; padding-top: 10px;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"../assets/images/wikipedia/Undeveloped_35_mm_film.jpg\" alt=\"Photographic film\" \n",
    "             style=\"height: 250px; width: auto; border-radius: 16px;\">\n",
    "        <p><em>Figure 1: Undeveloped 24-exposure roll of Kodak Ultramax 400</em> \n",
    "           (<a href=\"https://en.wikipedia.org/wiki/Photographic_film\" target=\"_blank\">source</a>)</p>\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"../assets/images/wikipedia/Photographic_Film_135.svg\" alt=\"Color film Layers\" \n",
    "             style=\"height: 250px; width: auto; background-color: #DBDBDB; border-radius: 16px;\">\n",
    "        <p><em>Figure 2: Layers of 35 mm color film</em> \n",
    "           (<a href=\"https://en.wikipedia.org/wiki/Photographic_film\" target=\"_blank\">source</a>)</p>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[üéõÔ∏è Analog to Digital - Capturing Using Sensors](#toc0_)\n",
    "\n",
    "- Converting a real-world scene into a **digital image** requires sensing light and converting it into discrete numerical samples (pixels).\n",
    "- This section gives an intuitive view of how cameras and sensors work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_1_'></a>[üí° How cameras sense light](#toc0_)\n",
    "\n",
    "- Sensors detect incoming photons and convert them into electrical signals.  \n",
    "- Each sensor element (pixel) accumulates charge proportional to light intensity.  \n",
    "- Analogy: the sensor ‚Äúcounts‚Äù light at each small spot to produce a numerical value.\n",
    "\n",
    "<div style=\"text-align: center; padding-top: 10px;\">\n",
    "    <img src=\"../assets/images/third_party/array-diagram1.png\" alt=\"Bayer array\" \n",
    "         style=\"min-width: 128px; max-width: 50%; height: auto; background-color: #DBDBDB; \n",
    "                border-radius: 16px; padding: 10px; margin: 5px;\">\n",
    "    <p><em>Figure 3: Top-view of Bayer array (on left) and side-view of color photosites (on right)</em> \n",
    "       (<a href=\"https://www.red.com/red-101/bayer-sensor-strategy\" target=\"_blank\">source</a>)</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_2_'></a>[üü¢ Pixels, sampling, and quantization (intuitive view)](#toc0_)\n",
    "\n",
    "- **Sampling:** dividing a continuous image into discrete pixels.  \n",
    "- **Quantization:** mapping continuous intensity values to discrete numbers (e.g., 0‚Äì255 for 8-bit).  \n",
    "- **Key point:** information is inevitably lost compared to the original analog signal.\n",
    "\n",
    "<div style=\"text-align: center; padding-top: 10px;\">\n",
    "    <img src=\"../assets/images/dip_3rd/misc/sampling-and-quantization.png\" alt=\"Sampling and Quantization\" \n",
    "         style=\"min-width: 128px; max-width: 80%; height: auto; border-radius: 16px;\">\n",
    "    <p><em>Figure 4: Image sampling and quantization process</em></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_3_'></a>[üé¶ Sensor architectures (CCD, CMOS, Foveon)](#toc0_)\n",
    "\n",
    "- **[CCD](https://de.wikipedia.org/wiki/CCD-Sensor) (Charge-Coupled Device):** high image quality, low noise, slower, more power.  \n",
    "- **[CMOS](https://de.wikipedia.org/wiki/Active_Pixel_Sensor) (Complementary Metal-Oxide-Semiconductor):** per-pixel amplifier, faster, lower power, widely used.  \n",
    "- **[Foveon X3](https://en.wikipedia.org/wiki/Foveon_X3_sensor):** captures full RGB at every pixel (no Bayer filter), higher color accuracy.\n",
    "\n",
    "<div style=\"text-align: center; padding-top: 10px;\">\n",
    "    <img src=\"../assets/images/third_party/sensors.jpg\" alt=\"Sensors\" \n",
    "         style=\"min-width: 128px; max-width: 60%; height: auto; border-radius: 16px;\">\n",
    "    <p><em>Figure 5: Direct Image vs. Color filter array sensors</em> (<a href=\"https://www.extremetech.com/electronics/84250-sigmas-foveon-sensor-what-it-is-and-how-it-makes-megapixels-obsolete\" target=\"_blank\">source</a>)</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_4_'></a>[üé® Color filter arrays and demosaicing](#toc0_)\n",
    "\n",
    "- Most sensors are monochrome; color is obtained via filters.  \n",
    "- **[Bayer Filter](https://en.wikipedia.org/wiki/Bayer_filter) (RGGB):** most common; green sampled twice for human vision sensitivity.  \n",
    "- **[RGBE](https://en.wikipedia.org/wiki/RGBE_filter) / [CYGM](https://en.wikipedia.org/wiki/CYGM_filter) Filters:** alternative patterns for improved sensitivity or color accuracy.  \n",
    "- **Demosaicing:** reconstructs full RGB image from filtered sensor data.\n",
    "\n",
    "<div style=\"text-align: center; padding-top: 10px;\">\n",
    "    <img src=\"../assets/images/third_party/bayer_pattern_on_sensor_profile.svg\" alt=\"bayer_pattern_on_sensor_profile.svg\" \n",
    "         style=\"min-width: 128px; max-width: 40%; height: auto; background-color: #DBDBDB; border-radius: 16px;\">\n",
    "    <p><em>Figure 6: Bayer Filter</em> (<a href=\"https://en.wikipedia.org/wiki/Bayer_filter\" target=\"_blank\">source</a>)</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; gap: 20px; padding-top: 10px;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"../assets/images/third_party/bayer_pattern.svg\" alt=\"bayer_pattern.svg\" \n",
    "             style=\"height: 40%; width: auto; border-radius: 16px;\">\n",
    "        <p><em>Figure 7: Bayer Pattern</em> \n",
    "           (<a href=\"https://en.wikipedia.org/wiki/RGBE_filter\" target=\"_blank\">source</a>)</p>\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"../assets/images/third_party/rgbe_filter.svg\" alt=\"rgbe_filter.svg\" \n",
    "             style=\"height: 40%; width: auto; background-color: #DBDBDB; border-radius: 16px;\">\n",
    "        <p><em>Figure 8: RGBE Pattern</em> \n",
    "           (<a href=\"https://en.wikipedia.org/wiki/RGBE_filter\" target=\"_blank\">source</a>)</p>\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"../assets/images/third_party/cygm_pattern.svg\" alt=\"cygm_pattern.svg\" \n",
    "             style=\"height: 40%; width: auto; border-radius: 16px;\">\n",
    "        <p><em>Figure 9: CYGM Pattern</em> \n",
    "           (<a href=\"https://en.wikipedia.org/wiki/CYGM_filter\" target=\"_blank\">source</a>)</p>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[üñºÔ∏è Digital Image](#toc0_)\n",
    "\n",
    "- A **digital image** is a matrix of pixel values where each pixel stores intensity or color information.\n",
    "- Unlike analog images, digital images are **discrete**, making them easy to store, process, and transmit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_1_'></a>[üìè Pixel representation and resolution](#toc0_)\n",
    "\n",
    "- Image is divided into a **grid of pixels**.  \n",
    "- **Resolution:** width √ó height in pixels (e.g., 1920√ó1080).  \n",
    "- Higher resolution ‚Üí more detail; lower resolution ‚Üí more blocky or pixelated.\n",
    "\n",
    "<div style=\"text-align: center; padding-top: 10px;\">\n",
    "    <img src=\"../assets/images/third_party/Pixel-Art-Fish-3-1009x1024.jpeg\" alt=\"Pixel-Art\" \n",
    "         style=\"min-width: 128px; max-width: 40%; height: auto; border-radius: 16px;\">\n",
    "    <p><em>Figure 10: Pixel representation and resolution</em> (<a href=\"https://www.megavoxels.com/learn/learn-how-to-make-pixel-art/\" target=\"_blank\">source</a>)</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_2_'></a>[üé® Bit depth and color channels](#toc0_)\n",
    "\n",
    "- **Bit depth:** number of discrete intensity levels per channel.  \n",
    "  - 8-bit ‚Üí 256 levels  \n",
    "  - 16-bit ‚Üí 65,536 levels  \n",
    "- **Color channels:** grayscale (1 channel), RGB (3 channels), RGBA (4 channels with alpha).  \n",
    "- Determines color fidelity and image dynamic range.\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; gap: 10px; padding-top: 10px;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"../assets/images/wikipedia/1_bit.png\" alt=\"1_bit.png\" \n",
    "             style=\"height: 60%; width: auto; border-radius: 16px;\">\n",
    "        <p><em>Figure 11: 1 bit (2 colors)</em> \n",
    "           (<a href=\"https://en.wikipedia.org/wiki/Color_depth\" target=\"_blank\">source</a>)</p>\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"../assets/images/wikipedia/2_bit.png\" alt=\"2_bit.png\" \n",
    "             style=\"height: 60%; width: auto; background-color: #DBDBDB; border-radius: 16px;\">\n",
    "        <p><em>Figure 12: 2 bit (4 colors)</em> \n",
    "           (<a href=\"https://en.wikipedia.org/wiki/Color_depth\" target=\"_blank\">source</a>)</p>\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"../assets/images/wikipedia/4_bit.png\" alt=\"4_bit.png\" \n",
    "             style=\"height: 60%; width: auto; border-radius: 16px;\">\n",
    "        <p><em>Figure 13: 4 bit (16 colors)</em> \n",
    "           (<a href=\"https://en.wikipedia.org/wiki/Color_depth\" target=\"_blank\">source</a>)</p>\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"../assets/images/wikipedia/8_bit.png\" alt=\"8_bit.png\" \n",
    "             style=\"height: 60%; width: auto; border-radius: 16px;\">\n",
    "        <p><em>Figure 14: 8 bit (256 colors)</em> \n",
    "           (<a href=\"https://en.wikipedia.org/wiki/Color_depth\" target=\"_blank\">source</a>)</p>\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"../assets/images/wikipedia/24_bit.png\" alt=\"24_bit.png\" \n",
    "             style=\"height: 60%; width: auto; border-radius: 16px;\">\n",
    "        <p><em>Figure 15: 24 bit (16,777,216 colors)</em> \n",
    "           (<a href=\"https://en.wikipedia.org/wiki/Color_depth\" target=\"_blank\">source</a>)</p>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_3_'></a>[üñäÔ∏è Raster vs. vector images](#toc0_)\n",
    "\n",
    "- **Raster:** pixel-based, resolution dependent (JPEG, PNG, BMP).  \n",
    "- **Vector:** mathematically defined shapes, scalable without quality loss (SVG, EPS).  \n",
    "- Key idea: raster = ‚Äúgrid of colors‚Äù; vector = ‚Äúinstructions to draw shapes‚Äù.\n",
    "\n",
    "<div style=\"text-align: center; padding-top: 10px;\">\n",
    "    <img src=\"../assets/images/third_party/vector_vs_raster.jpg\" alt=\"vector_vs_raster.jpg\" \n",
    "         style=\"min-width: 128px; max-width: 50%; height: auto; border-radius: 16px;\">\n",
    "    <p><em>Figure 16: Raster vs. Vector</em> (<a href=\"https://vector-conversions.com/vectorizing/raster_vs_vector.html\" target=\"_blank\">source</a>)</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_4_'></a>[üíæ Common file formats (JPEG, PNG, TIFF, SVG‚Ä¶)](#toc0_)\n",
    "\n",
    "- **JPEG:** lossy compression, smaller files.  \n",
    "- **PNG, BMP, TIFF:** lossless, larger files, retain full detail.  \n",
    "- **SVG, EPS:** vector graphics, scalable.  \n",
    "- **HDR:** high dynamic range formats (EXR, HDR) for wide brightness/color range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_5_'></a>[üåà Color spaces in simple terms (RGB, HSV, YCbCr, CMYK)](#toc0_)\n",
    "\n",
    "- **RGB:** additive model for screens (Red, Green, Blue).  \n",
    "- **HSV:** intuitive manipulation (Hue, Saturation, Value).  \n",
    "- **YCbCr / YUV:** separates luminance and chrominance, useful in compression.  \n",
    "- **CMYK:** subtractive model for printing (Cyan, Magenta, Yellow, Black).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[üñ•Ô∏è Visualization a Digital Image](#toc0_)\n",
    "\n",
    "- Displaying a digital image involves mapping pixel values to the physical properties of a screen (light emission or reflection) so that humans can perceive the image correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_1_'></a>[üí° How digital images appear on screens](#toc0_)\n",
    "\n",
    "- Each pixel emits or modulates light corresponding to its stored value.  \n",
    "- Subpixels (Red, Green, Blue) combine to produce perceived colors.  \n",
    "- Image appearance depends on **pixel arrangement, density, and display technology**.\n",
    "\n",
    "<div style=\"text-align: center; padding-top: 10px;\">\n",
    "    <img src=\"../assets/images/third_party/pixel_geometry.jpg\" alt=\"pixel_geometry.jpg\" \n",
    "         style=\"min-width: 128px; max-width: 50%; height: auto; border-radius: 16px;\">\n",
    "    <p><em>Figure 17: Pixel Geometry</em> (<a href=\"https://en.wikipedia.org/wiki/Pixel_geometry\" target=\"_blank\">source</a>)</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_2_'></a>[‚ö° Display pipeline (basic idea)](#toc0_)\n",
    "\n",
    "- Pixels are sent from graphics memory ‚Üí processed by GPU ‚Üí displayed on screen.  \n",
    "- Adjustments like **gamma correction** and **color mapping** ensure accurate brightness and color.  \n",
    "- Scaling and anti-aliasing improve appearance on different screen sizes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_3_'></a>[üì∫ Overview of display technologies (LCD, LED, OLED, E-Ink)](#toc0_)\n",
    "\n",
    "- **LCD:** liquid crystals modulate backlight.  \n",
    "- **LED:** LED backlight improves brightness and contrast.  \n",
    "- **OLED:** self-emissive pixels ‚Üí true blacks, high contrast.  \n",
    "- **E-Ink:** reflective, low-power, high-contrast displays (e-readers).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_4_'></a>[üé® Factors affecting perceived image quality (contrast, brightness, gamut)](#toc0_)\n",
    "\n",
    "- **Resolution & pixel density (PPI)**: higher density ‚Üí sharper images.  \n",
    "- **Color gamut & calibration**: affects color accuracy.  \n",
    "- **Brightness & contrast**: perceived details in shadows/highlights.  \n",
    "- **Scaling & anti-aliasing**: smooth edges and reduce pixelation.\n"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "media-processing-workshop-sxUc00b2-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  },
  "origin_repo": "https://github.com/mr-pylin/media-processing-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
