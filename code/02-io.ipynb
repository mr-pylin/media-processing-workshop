{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
    "    <div style=\"text-align: left; flex: 4;\">\n",
    "        <strong>Author:</strong> Amirhossein Heydari ‚Äî \n",
    "        üìß <a href=\"mailto:amirhosseinheydari78@gmail.com\">amirhosseinheydari78@gmail.com</a> ‚Äî \n",
    "        üêô <a href=\"https://github.com/mr-pylin/media-processing-workshop\" target=\"_blank\" rel=\"noopener\">github.com/mr-pylin</a>\n",
    "    </div>\n",
    "    <div style=\"display: flex; justify-content: flex-end; flex: 1; gap: 8px; align-items: center; padding: 0;\">\n",
    "        <a href=\"https://opencv.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/libraries/opencv/logo/OpenCV_logo_no_text-1.svg\"\n",
    "                 alt=\"OpenCV Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "        <a href=\"https://pillow.readthedocs.io/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/libraries/pillow/logo/pillow-logo-248x250.png\"\n",
    "                 alt=\"PIL Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "        <a href=\"https://scikit-image.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/libraries/scikit-image/logo/logo.png\"\n",
    "                 alt=\"scikit-image Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "        <a href=\"https://scipy.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/libraries/scipy/logo/logo.svg\"\n",
    "                 alt=\"SciPy Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "    </div>\n",
    "</div>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Dependencies](#toc1_)    \n",
    "- [I/O](#toc2_)    \n",
    "  - [Read/Open Images](#toc2_1_)    \n",
    "    - [Using Matplotlib](#toc2_1_1_)    \n",
    "    - [Using scikit-image](#toc2_1_2_)    \n",
    "    - [Using OpenCV](#toc2_1_3_)    \n",
    "    - [Using PIL](#toc2_1_4_)    \n",
    "  - [Types of Digital Images](#toc2_2_)    \n",
    "    - [Binary Image](#toc2_2_1_)    \n",
    "      - [Bit Plane Extraction](#toc2_2_1_1_)    \n",
    "    - [GrayScale Image](#toc2_2_2_)    \n",
    "    - [CMYK Images](#toc2_2_3_)    \n",
    "    - [RGB image](#toc2_2_4_)    \n",
    "    - [RGBA images](#toc2_2_5_)    \n",
    "    - [Indexed Color Images (Palette-Based)](#toc2_2_6_)    \n",
    "    - [Multispectral & Hyperspectral Image](#toc2_2_7_)    \n",
    "    - [HDR (High Dynamic Range) Images](#toc2_2_8_)    \n",
    "    - [Depth Maps & Alpha Masks](#toc2_2_9_)    \n",
    "  - [Converting Pixels to Physical Dimensions](#toc2_3_)    \n",
    "  - [Basic Modifications](#toc2_4_)    \n",
    "    - [‚úÇÔ∏è Cropping](#toc2_4_1_)    \n",
    "      - [Manual](#toc2_4_1_1_)    \n",
    "      - [Using PIL](#toc2_4_1_2_)    \n",
    "    - [ü™û Flipping](#toc2_4_2_)    \n",
    "      - [Manual](#toc2_4_2_1_)    \n",
    "      - [Using OpenCV](#toc2_4_2_2_)    \n",
    "      - [Using PIL](#toc2_4_2_3_)    \n",
    "    - [üîÉ Circular Shift](#toc2_4_3_)    \n",
    "      - [Manual](#toc2_4_3_1_)    \n",
    "      - [Using NumPy](#toc2_4_3_2_)    \n",
    "  - [Save Images](#toc2_5_)    \n",
    "      - [Using Matplotlib](#toc2_5_1_1_)    \n",
    "      - [Using scikit-image](#toc2_5_1_2_)    \n",
    "      - [Using OpenCV](#toc2_5_1_3_)    \n",
    "      - [Using PIL](#toc2_5_1_4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Dependencies](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage as ski\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from numpy.typing import NDArray\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[I/O](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Read/Open Images](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_1_'></a>[Using Matplotlib](#toc0_)\n",
    "\n",
    "**Color Types and Layouts**:\n",
    "\n",
    "- **Grayscale** ‚Üí Single-channel `(H, W)`\n",
    "- **RGB** ‚Üí `(H, W, 3)`\n",
    "- **RGBA** ‚Üí `(H, W, 4)`\n",
    "- **CMYK** ‚Üí `(H, W, 4)`\n",
    "- **Indexed** ‚Üí `(H, W, 4)` (expanded to RGBA)\n",
    "\n",
    "**Output**:\n",
    "\n",
    "- **Type:** `numpy.ndarray`\n",
    "- **Preserves Metadata:** ‚ùå\n",
    "\n",
    "‚úçÔ∏è **Notes**:\n",
    "\n",
    "- PNG images are returned as **float** arrays (`0‚Äì1` range).\n",
    "- Other formats are returned as **int** arrays, with bit depth determined by the file contents.\n",
    "- Although metadata (e.g., ICC profile, EXIF orientation) is **not preserved**, it is **applied during decoding** to produce the final pixel values.\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `matplotlib.pyplot.imread`: [matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imread.html](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imread.html)\n",
    "\n",
    "üîé **Source Code**:\n",
    "- `matplotlib.image.imread`: [github.com/matplotlib/matplotlib/blob/v3.10.3/lib/matplotlib/image.py#L1448-L1523](https://github.com/matplotlib/matplotlib/blob/v3.10.3/lib/matplotlib/image.py#L1448-L1523)\n",
    "- `matplotlib.image.pil_to_array`: [github.com/matplotlib/matplotlib/blob/v3.10.3/lib/matplotlib/image.py#L1660-L1692](https://github.com/matplotlib/matplotlib/blob/v3.10.3/lib/matplotlib/image.py#L1660-L1692)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary image\n",
    "# matplotlib converts binary images to RGBA in range [0, 255]\n",
    "im_binary = plt.imread(fname=\"../assets/images/original/raster/test_binary.tif\")\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_binary)} | dtype: {im_binary.dtype} | shape: {im_binary.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grayscale image\n",
    "im_grayscale = plt.imread(fname=\"../assets/images/dip_3rd/CH02_Fig0222(b)(cameraman).tif\")\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_grayscale)} | dtype: {im_grayscale.dtype} | shape: {im_grayscale.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMYK image\n",
    "# matplotlib converts CMYK images to RGBA\n",
    "im_cmyk = plt.imread(fname=\"../assets/images/misc/color_bars_cmyk.tif\")\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_cmyk)} | dtype: {im_cmyk.dtype} | shape: {im_cmyk.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB image\n",
    "im_rgb = plt.imread(fname=\"../assets/images/dip_3rd/CH06_Fig0638(a)(lenna_RGB).tif\")\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_rgb)} | dtype: {im_rgb.dtype} | shape: {im_rgb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGBA image\n",
    "im_rgba = plt.imread(fname=\"../assets/images/misc/lenna_rgba.png\")\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_rgba)} | dtype: {im_rgba.dtype} | shape: {im_rgba.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexed RGBA image\n",
    "im_indexed_rgba = plt.imread(fname=\"../assets/images/misc/lenna_rgba_indexed.png\")\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_indexed_rgba)} | dtype: {im_indexed_rgba.dtype} | shape: {im_indexed_rgba.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Visualize Images using matplotlib package\")\n",
    "axs[0, 0].imshow(im_binary, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axs[0, 0].set_title(\"im_binary\")\n",
    "axs[0, 1].imshow(im_grayscale, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axs[0, 1].set_title(\"im_grayscale\")\n",
    "axs[0, 2].imshow(im_cmyk, vmin=0, vmax=255)\n",
    "axs[0, 2].set_title(\"im_cmyk\")\n",
    "axs[1, 0].imshow(im_rgb, vmin=0, vmax=255)\n",
    "axs[1, 0].set_title(\"im_rgb\")\n",
    "axs[1, 1].imshow(im_rgba, vmin=0, vmax=255)\n",
    "axs[1, 1].set_title(\"im_rgba\")\n",
    "axs[1, 2].imshow(im_indexed_rgba, vmin=0, vmax=255)\n",
    "axs[1, 2].set_title(\"im_indexed_rgba\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_2_'></a>[Using scikit-image](#toc0_)\n",
    "\n",
    "**Color Types and Layouts**:\n",
    "\n",
    "- **Grayscale** ‚Üí `(H, W)`\n",
    "- **RGB** ‚Üí `(H, W, 3)`\n",
    "- **RGBA** ‚Üí `(H, W, 4)`\n",
    "- **CMYK** ‚Üí `(H, W, 4)`\n",
    "- **Indexed** ‚Üí converted to RGB `(H, W, 3)`\n",
    "\n",
    "**Output**:\n",
    "\n",
    "- **Type:** `numpy.ndarray`\n",
    "- **Preserves Metadata:** ‚ùå\n",
    "\n",
    "**Notes**:\n",
    "- Binary TIFFs with photometric interpretation **WhiteIsZero** load **inverted** (`0` ‚Üî `1`).\n",
    "- Although metadata (e.g., ICC profile, EXIF orientation) is **not preserved**, it is **applied during decoding** to produce the final pixel values.\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `skimage.io.imread`: [scikit-image.org/docs/stable/api/skimage.io.html](https://scikit-image.org/docs/stable/api/skimage.io.html#skimage.io.imread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary image\n",
    "# this image has WhiteIsZero flag (0: white, 1: black)\n",
    "im_binary = ski.io.imread(fname=\"../assets/images/original/raster/test_binary.tif\")\n",
    "\n",
    "# invert im_binary from WhiteIsZero to BlackIsZero\n",
    "im_binary = ~im_binary\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_binary)} | dtype: {im_binary.dtype} | shape: {im_binary.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grayscale image\n",
    "im_grayscale = ski.io.imread(fname=\"../assets/images/dip_3rd/CH02_Fig0222(b)(cameraman).tif\")\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_grayscale)} | dtype: {im_grayscale.dtype} | shape: {im_grayscale.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMYK image\n",
    "# skimage loads CMYK as it is (needs to be manually converted to RGB)\n",
    "im_cmyk = ski.io.imread(fname=\"../assets/images/misc/color_bars_cmyk.tif\")\n",
    "\n",
    "# convert im_cmyk from CMYK to RGB\n",
    "im_cmyk = np.array(Image.fromarray(im_cmyk, mode=\"CMYK\").convert(\"RGB\"))\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_cmyk)} | dtype: {im_cmyk.dtype} | shape: {im_cmyk.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB image\n",
    "im_rgb = ski.io.imread(fname=\"../assets/images/dip_3rd/CH06_Fig0638(a)(lenna_RGB).tif\")\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_rgb)} | dtype: {im_rgb.dtype} | shape: {im_rgb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGBA image\n",
    "im_rgba = ski.io.imread(fname=\"../assets/images/misc/lenna_rgba.png\")\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_rgba)} | dtype: {im_rgba.dtype} | shape: {im_rgba.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexed RGBA image\n",
    "# skimage doesn't support indexed RGBA images (converts to RGB)\n",
    "im_indexed_rgba = ski.io.imread(fname=\"../assets/images/misc/lenna_rgba_indexed.png\")\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_indexed_rgba)} | dtype: {im_indexed_rgba.dtype} | shape: {im_indexed_rgba.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Visualize Images using matplotlib package\")\n",
    "axs[0, 0].imshow(im_binary, cmap=\"gray\", vmin=0, vmax=1)\n",
    "axs[0, 0].set_title(\"im_binary\")\n",
    "axs[0, 1].imshow(im_grayscale, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axs[0, 1].set_title(\"im_grayscale\")\n",
    "axs[0, 2].imshow(im_cmyk, vmin=0, vmax=255)\n",
    "axs[0, 2].set_title(\"im_cmyk\")\n",
    "axs[1, 0].imshow(im_rgb, vmin=0, vmax=255)\n",
    "axs[1, 0].set_title(\"im_rgb\")\n",
    "axs[1, 1].imshow(im_rgba, vmin=0, vmax=255)\n",
    "axs[1, 1].set_title(\"im_rgba\")\n",
    "axs[1, 2].imshow(im_indexed_rgba, vmin=0, vmax=255)\n",
    "axs[1, 2].set_title(\"im_indexed_rgba\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_3_'></a>[Using OpenCV](#toc0_)\n",
    "\n",
    "**Color Types and Layouts**:\n",
    "\n",
    "- **Grayscale** ‚Üí depends on `flags`\n",
    "- **Color (default)** ‚Üí **BGR** `(H, W, 3)`\n",
    "- **RGBA** ‚Üí **BGRA** `(H, W, 4)` (if `cv2.IMREAD_UNCHANGED` or similar flag used)\n",
    "- **CMYK** ‚Üí converted internally (OpenCV does not natively store CMYK)\n",
    "- **Indexed** ‚Üí palette is resolved to **BGR**\n",
    "\n",
    "**Output**:\n",
    "\n",
    "- **Type:** `numpy.ndarray`\n",
    "- **Preserves Metadata:** ‚ùå\n",
    "\n",
    "‚úçÔ∏è **Notes**:\n",
    "\n",
    "- OpenCV uses **BGR/BGRA** channel order by default instead of **RGB/RGBA**.\n",
    "- Although metadata (e.g., ICC profile, EXIF orientation) is **not preserved**, it is **applied during decoding** to produce the final pixel values.\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `cv2.imread`: [docs.opencv.org/master/d4/da8/group__imgcodecs.html](https://docs.opencv.org/master/d4/da8/group__imgcodecs.html#gacbaa02cffc4ec2422dfa2e24412a99e2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary image\n",
    "im_binary = cv2.imread(filename=\"../assets/images/original/raster/test_binary.tif\", flags=cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_binary)} | dtype: {im_binary.dtype} | shape: {im_binary.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grayscale image\n",
    "im_grayscale = cv2.imread(\n",
    "    filename=\"../assets/images/dip_3rd/CH02_Fig0222(b)(cameraman).tif\", flags=cv2.IMREAD_GRAYSCALE\n",
    ")\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_grayscale)} | dtype: {im_grayscale.dtype} | shape: {im_grayscale.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMYK image\n",
    "# OpenCV converts CMYK images to BGRA\n",
    "im_cmyk = cv2.imread(filename=\"../assets/images/misc/color_bars_cmyk.tif\", flags=cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# BGRA to RGBA\n",
    "im_cmyk = cv2.cvtColor(im_cmyk, cv2.COLOR_BGRA2RGBA)\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_cmyk)} | dtype: {im_cmyk.dtype} | shape: {im_cmyk.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGR image\n",
    "im_rgb = cv2.imread(filename=\"../assets/images/dip_3rd/CH06_Fig0638(a)(lenna_RGB).tif\", flags=cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# BGR to RGB\n",
    "im_rgb = cv2.cvtColor(im_rgb, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_rgb)} | dtype: {im_rgb.dtype} | shape: {im_rgb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGRA image\n",
    "im_rgba = cv2.imread(filename=\"../assets/images/misc/lenna_rgba.png\", flags=cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# BGRA to RGBA\n",
    "im_rgba = cv2.cvtColor(im_rgba, cv2.COLOR_BGRA2RGBA)\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_rgba)} | dtype: {im_rgba.dtype} | shape: {im_rgba.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexed RGBA image\n",
    "im_indexed_rgba = cv2.imread(filename=\"../assets/images/misc/lenna_rgba_indexed.png\", flags=cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# BGRA to RGBA\n",
    "im_indexed_rgba = cv2.cvtColor(im_indexed_rgba, cv2.COLOR_BGRA2RGBA)\n",
    "\n",
    "# log\n",
    "print(f\"type: {type(im_indexed_rgba)} | dtype: {im_indexed_rgba.dtype} | shape: {im_indexed_rgba.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Visualize Images using matplotlib package\")\n",
    "axs[0, 0].imshow(im_binary, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axs[0, 0].set_title(\"im_binary\")\n",
    "axs[0, 1].imshow(im_grayscale, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axs[0, 1].set_title(\"im_grayscale\")\n",
    "axs[0, 2].imshow(im_cmyk, vmin=0, vmax=255)\n",
    "axs[0, 2].set_title(\"im_cmyk\")\n",
    "axs[1, 0].imshow(im_rgb, vmin=0, vmax=255)\n",
    "axs[1, 0].set_title(\"im_rgb\")\n",
    "axs[1, 1].imshow(im_rgba, vmin=0, vmax=255)\n",
    "axs[1, 1].set_title(\"im_rgba\")\n",
    "axs[1, 2].imshow(im_indexed_rgba, vmin=0, vmax=255)\n",
    "axs[1, 2].set_title(\"im_indexed_rgba\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_4_'></a>[Using PIL](#toc0_)\n",
    "\n",
    "**Color Types and Layouts**:\n",
    "\n",
    "- **Grayscale** ‚Üí `(H, W)`\n",
    "- **RGB** ‚Üí `(H, W, 3)`\n",
    "- **RGBA** ‚Üí `(H, W, 4)`\n",
    "- **CMYK** ‚Üí `(H, W, 4)`\n",
    "- **Indexed** ‚Üí Indexed palette `(H, W)`\n",
    "\n",
    "**Output**:\n",
    "\n",
    "- **Type:** `PIL.Image.Image`\n",
    "- **Preserves Metadata:** ‚úÖ\n",
    "\n",
    "‚úçÔ∏è **Notes**:\n",
    "\n",
    "- `PIL.Image` objects can be displayed or processed directly.\n",
    "- Metadata such as EXIF, ICC profiles, and DPI settings are **accessible** via image attributes or `info` dictionary.\n",
    "- Conversion to `numpy.ndarray` **does not automatically apply metadata**, you should:\n",
    "  1. Apply `ImageOps.exif_transpose()` to handle orientation.\n",
    "  1. Convert the image to the appropriate mode (`.convert(\"RGB\")`, `.convert(\"RGBA\")`) for CMYK or palette images.\n",
    "  1. Apply any TIFF-specific adjustments (e.g., WhiteIsZero binary inversion).\n",
    "  1. Then use `np.array(img)` to get the array.\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `PIL.Image.open`: [pillow.readthedocs.io/en/stable/reference/Image.html](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.open)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_binary = Image.open(fp=\"../assets/images/original/raster/test_binary.tif\")\n",
    "im_grayscale = Image.open(fp=\"../assets/images/dip_3rd/CH02_Fig0222(b)(cameraman).tif\")\n",
    "im_cmyk = Image.open(fp=\"../assets/images/misc/color_bars_cmyk.tif\")\n",
    "im_rgb = Image.open(fp=\"../assets/images/dip_3rd/CH06_Fig0638(a)(lenna_RGB).tif\")\n",
    "im_rgba = Image.open(fp=\"../assets/images/misc/lenna_rgba.png\")\n",
    "im_indexed_rgba = Image.open(fp=\"../assets/images/misc/lenna_rgba_indexed.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Visualize Images using matplotlib package\")\n",
    "axs[0, 0].imshow(im_binary, cmap=\"gray\", vmin=0, vmax=1)\n",
    "axs[0, 0].set_title(\"im_binary\")\n",
    "axs[0, 1].imshow(im_grayscale, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axs[0, 1].set_title(\"im_grayscale\")\n",
    "axs[0, 2].imshow(im_cmyk, vmin=0, vmax=255)\n",
    "axs[0, 2].set_title(\"im_cmyk\")\n",
    "axs[1, 0].imshow(im_rgb, vmin=0, vmax=255)\n",
    "axs[1, 0].set_title(\"im_rgb\")\n",
    "axs[1, 1].imshow(im_rgba, vmin=0, vmax=255)\n",
    "axs[1, 1].set_title(\"im_rgba\")\n",
    "axs[1, 2].imshow(im_indexed_rgba, vmin=0, vmax=255)\n",
    "axs[1, 2].set_title(\"im_indexed_rgba\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL.Image.Image to np.ndarray (metadata is lost)\n",
    "im_1 = np.array(im_binary)\n",
    "im_2 = np.array(im_grayscale)\n",
    "im_3 = np.array(im_cmyk)\n",
    "im_4 = np.array(im_rgb)\n",
    "im_5 = np.array(im_rgba)\n",
    "im_6 = np.array(im_indexed_rgba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 8), layout=\"compressed\")\n",
    "fig.suptitle(\"Visualize Images using matplotlib package\")\n",
    "axs[0, 0].imshow(im_1, cmap=\"gray\", vmin=0, vmax=1)\n",
    "axs[0, 0].set_title(\"Binary\")\n",
    "axs[0, 1].imshow(im_2, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axs[0, 1].set_title(\"GrayScale\")\n",
    "axs[0, 2].imshow(im_3, vmin=0, vmax=255)\n",
    "axs[0, 2].set_title(\"CMYK [Corrupted]\")\n",
    "axs[1, 0].imshow(im_4, vmin=0, vmax=255)\n",
    "axs[1, 0].set_title(\"RGB\")\n",
    "axs[1, 1].imshow(im_5, vmin=0, vmax=255)\n",
    "axs[1, 1].set_title(\"RGBA\")\n",
    "axs[1, 2].imshow(im_6, vmin=0, vmax=255)\n",
    "axs[1, 2].set_title(\"Indexed [Corrupted]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Types of Digital Images](#toc0_)\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- The Image Class: [pillow.readthedocs.io/en/stable/reference/Image.html#the-image-class](https://pillow.readthedocs.io/en/stable/reference/Image.html#the-image-class)\n",
    "- image Attributes: [pillow.readthedocs.io/en/stable/reference/Image.html#image-attributes](https://pillow.readthedocs.io/en/stable/reference/Image.html#image-attributes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_1_'></a>[Binary Image](#toc0_)\n",
    "\n",
    "- Each pixel is either black (0) or white (1), with no shades of gray.\n",
    "- **Bit Depth**: 1-bit per pixel (only two possible values).\n",
    "- **File Formats**:\n",
    "  - **PBM (Portable Bitmap)** ‚Äì part of Netpbm format\n",
    "  - **BMP (1-bit mode)**\n",
    "  - **TIFF (bi-level mode)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log\n",
    "print(f\"type(im_binary)                    : {type(im_binary)}\")\n",
    "print(f\"im_binary.format                   : {im_binary.format}\")\n",
    "print(f\"im_binary.mode                     : {im_binary.mode}\")\n",
    "print(f\"im_binary.size                     : {im_binary.size}\")\n",
    "print(f\"im_binary.has_transparency_data    : {im_binary.has_transparency_data}\")\n",
    "print(f\"im_binary.info.get('transparency') : {im_binary.info.get(\"transparency\")}\")\n",
    "print(f\"im_binary.info.get('compression')  : {im_binary.info.get(\"compression\")}\")\n",
    "print(f\"im_binary.info.get('dpi')          : {im_binary.info.get(\"dpi\")}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.figure(figsize=(4, 5), layout=\"compressed\")\n",
    "plt.title(im_binary.filename.split(\"/\")[-1])\n",
    "im = plt.imshow(im_1, cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.colorbar(im, location=\"bottom\", label=\"Binary\").set_ticks([0, 1])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_1_1_'></a>[Bit Plane Extraction](#toc0_)\n",
    "\n",
    "- Bit-plane extraction is a technique used in image processing to visualize and analyze the significance of individual bits in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_planes = []\n",
    "for i in range(8):\n",
    "    bit_plane = (im_2 >> i) & 1  # shift and mask\n",
    "    bit_planes.append(bit_plane * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6), layout=\"compressed\")\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(bit_planes[i], cmap=\"gray\")\n",
    "    ax.set_title(f\"Bit {i}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_2_'></a>[GrayScale Image](#toc0_)\n",
    "\n",
    "- Images with varying shades of gray, ranging from black (0 intensity) to white (max intensity).\n",
    "- **Bit Depth**:\n",
    "  - **8-bit** (0-255 intensity levels, standard grayscale)\n",
    "  - **16-bit** (0-65,535 intensity levels, used in high-precision imaging)\n",
    "- **File Formats**:\n",
    "  - **JPEG (grayscale mode)**\n",
    "  - **PNG (supports 8-bit and 16-bit grayscale)**\n",
    "  - **TIFF (widely used in medical and scientific imaging)**\n",
    "  - **PGM (Portable GrayMap, part of Netpbm format)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log\n",
    "print(f\"type(im_grayscale)                    : {type(im_grayscale)}\")\n",
    "print(f\"im_grayscale.format                   : {im_grayscale.format}\")\n",
    "print(f\"im_grayscale.mode                     : {im_grayscale.mode}\")\n",
    "print(f\"im_grayscale.size                     : {im_grayscale.size}\")\n",
    "print(f\"im_grayscale.has_transparency_data    : {im_grayscale.has_transparency_data}\")\n",
    "print(f\"im_grayscale.info.get('transparency') : {im_grayscale.info.get(\"transparency\")}\")\n",
    "print(f\"im_grayscale.info.get('compression')  : {im_grayscale.info.get(\"compression\")}\")\n",
    "print(f\"im_grayscale.info.get('dpi')          : {im_grayscale.info.get(\"dpi\")}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.figure(figsize=(4, 5), layout=\"compressed\")\n",
    "plt.title(im_grayscale.filename.split(\"/\")[-1])\n",
    "im = plt.imshow(im_2, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.colorbar(im, location=\"bottom\", label=\"GrayLevels\").set_ticks([0, 255])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_3_'></a>[CMYK Images](#toc0_)\n",
    "\n",
    "- A subtractive color model used in printing.\n",
    "- **Bit Depth**:\n",
    "  - **32-bit (8-bit per channel)**\n",
    "  - **Higher precision (16-bit per channel)**\n",
    "- **File Formats**:\n",
    "  - **TIFF** (used in print production).\n",
    "  - **PDF** (for print-ready documents).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log\n",
    "print(f\"type(im_cmyk)                    : {type(im_cmyk)}\")\n",
    "print(f\"im_cmyk.format                   : {im_cmyk.format}\")\n",
    "print(f\"im_cmyk.mode                     : {im_cmyk.mode}\")\n",
    "print(f\"im_cmyk.size                     : {im_cmyk.size}\")\n",
    "print(f\"im_cmyk.has_transparency_data    : {im_cmyk.has_transparency_data}\")\n",
    "print(f\"im_cmyk.info.get('transparency') : {im_cmyk.info.get(\"transparency\")}\")\n",
    "print(f\"im_cmyk.info.get('compression')  : {im_cmyk.info.get(\"compression\")}\")\n",
    "print(f\"im_cmyk.info.get('dpi')          : {im_cmyk.info.get(\"dpi\")}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate CMYK channels\n",
    "im_cmyk_c, im_cmyk_m, im_cmyk_y, im_cmyk_k = im_cmyk.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig = plt.figure(figsize=(14, 8), layout=\"constrained\")\n",
    "gs = GridSpec(2, 4, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax1.imshow(im_cmyk, vmin=0, vmax=1)\n",
    "ax1.set_title(im_cmyk.filename.split(\"/\")[-1])\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "ax2.imshow(im_cmyk_c, cmap=\"gray\", vmin=0, vmax=255)\n",
    "ax2.set_title(\"cyan channel\")\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "ax3.imshow(im_cmyk_m, cmap=\"gray\", vmin=0, vmax=255)\n",
    "ax3.set_title(\"magenta channel\")\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "ax4.imshow(im_cmyk_y, cmap=\"gray\", vmin=0, vmax=255)\n",
    "ax4.set_title(\"yellow channel\")\n",
    "ax5 = fig.add_subplot(gs[1, 3])\n",
    "ax5.imshow(im_cmyk_k, cmap=\"gray\", vmin=0, vmax=255)\n",
    "ax5.set_title(\"key/black channel\")\n",
    "for ax in fig.axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_4_'></a>[RGB image](#toc0_)\n",
    "\n",
    "- Each pixel consists of three color channels‚ÄîRed (R), Green (G), and Blue (B)‚Äîcombined to produce various colors.\n",
    "- **Bit Depth**:\n",
    "  - **24-bit (8-bit per channel)** ‚Üí 16.7 million possible colors.\n",
    "  - **48-bit (16-bit per channel)** ‚Üí High dynamic range (HDR) images.\n",
    "- **File Formats**:\n",
    "  - **JPEG** (lossy compression, widely used for photos).\n",
    "  - **PNG** (lossless compression, used for web graphics).\n",
    "  - **BMP** (uncompressed, used in early Windows applications).\n",
    "  - **TIFF** (used in professional photography and printing).\n",
    "  - **PPM (Portable PixMap)** (simple raw format used in Netpbm).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log\n",
    "print(f\"type(im_rgb)                    : {type(im_rgb)}\")\n",
    "print(f\"im_rgb.format                   : {im_rgb.format}\")\n",
    "print(f\"im_rgb.mode                     : {im_rgb.mode}\")\n",
    "print(f\"im_rgb.size                     : {im_rgb.size}\")\n",
    "print(f\"im_rgb.has_transparency_data    : {im_rgb.has_transparency_data}\")\n",
    "print(f\"im_rgb.info.get('transparency') : {im_rgb.info.get(\"transparency\")}\")\n",
    "print(f\"im_rgb.info.get('compression')  : {im_rgb.info.get(\"compression\")}\")\n",
    "print(f\"im_rgb.info.get('dpi')          : {im_rgb.info.get(\"dpi\")}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate RGB channels\n",
    "im_rgb_r, im_rgb_g, im_rgb_b = im_rgb.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig = plt.figure(figsize=(16, 10), layout=\"constrained\")\n",
    "gs = GridSpec(2, 4, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[:, 0])\n",
    "ax1.imshow(im_4, vmin=0, vmax=255)\n",
    "ax1.set_title(im_rgb.filename.split(\"/\")[-1])\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "im = ax2.imshow(im_rgb_r, cmap=\"Reds\", vmin=0, vmax=255)\n",
    "ax2.set_title(\"R[256 distinct colors]\")\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "im = ax3.imshow(im_rgb_g, cmap=\"Greens\", vmin=0, vmax=255)\n",
    "ax3.set_title(\"G[256 distinct colors]\")\n",
    "ax4 = fig.add_subplot(gs[0, 3])\n",
    "im = ax4.imshow(im_rgb_b, cmap=\"Blues\", vmin=0, vmax=255)\n",
    "ax4.set_title(\"B[256 distinct colors]\")\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "im = ax5.imshow(im_rgb_r, cmap=\"gray\", vmin=0, vmax=255)\n",
    "ax5.set_title(\"R[256 distinct colors]\")\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "im = ax6.imshow(im_rgb_g, cmap=\"gray\", vmin=0, vmax=255)\n",
    "ax6.set_title(\"G[256 distinct colors]\")\n",
    "ax7 = fig.add_subplot(gs[1, 3])\n",
    "im = ax7.imshow(im_rgb_b, cmap=\"gray\", vmin=0, vmax=255)\n",
    "ax7.set_title(\"B[256 distinct colors]\")\n",
    "for ax in fig.axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "fig.colorbar(im, ax=ax2, location=\"top\", label=\"Red\").set_ticks([0, 255])\n",
    "fig.colorbar(im, ax=ax3, location=\"top\", label=\"Green\").set_ticks([0, 255])\n",
    "fig.colorbar(im, ax=ax4, location=\"top\", label=\"Blue\").set_ticks([0, 255])\n",
    "fig.colorbar(im, ax=ax5, location=\"bottom\", label=\"Red\").set_ticks([0, 255])\n",
    "fig.colorbar(im, ax=ax6, location=\"bottom\", label=\"Green\").set_ticks([0, 255])\n",
    "fig.colorbar(im, ax=ax7, location=\"bottom\", label=\"Blue\").set_ticks([0, 255])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_5_'></a>[RGBA images](#toc0_)\n",
    "\n",
    "- Similar to RGB, but includes an **Alpha (A) channel** for transparency control.\n",
    "- **Bit Depth**:\n",
    "  - **32-bit (8-bit per channel + 8-bit alpha)** ‚Üí Standard RGBA format.\n",
    "  - **64-bit (16-bit per channel + 16-bit alpha)** ‚Üí Used in HDR and high-precision applications.\n",
    "- **File Formats**:\n",
    "  - **PNG** (supports alpha transparency, widely used).\n",
    "  - **TIFF** (supports alpha, used in printing and professional editing).\n",
    "  - **TGA (Targa)** (used in game development and 3D rendering).\n",
    "  - **EXR (OpenEXR)** (used in visual effects and HDR imaging).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log\n",
    "print(f\"type(im_rgba)                    : {type(im_rgba)}\")\n",
    "print(f\"im_rgba.format                   : {im_rgba.format}\")\n",
    "print(f\"im_rgba.mode                     : {im_rgba.mode}\")\n",
    "print(f\"im_rgba.size                     : {im_rgba.size}\")\n",
    "print(f\"im_rgba.has_transparency_data    : {im_rgba.has_transparency_data}\")\n",
    "print(f\"im_rgba.info.get('transparency') : {im_rgba.info.get(\"transparency\")}\")\n",
    "print(f\"im_rgba.info.get('compression')  : {im_rgba.info.get(\"compression\")}\")\n",
    "print(f\"im_rgba.info.get('dpi')          : {im_rgba.info.get(\"dpi\")}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate RGBA channels\n",
    "im_rgba_r, im_rgba_g, im_rgba_b, im_rgba_a = im_rgba.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig = plt.figure(figsize=(14, 8), layout=\"constrained\")\n",
    "gs = GridSpec(2, 4, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax1.imshow(im_5, vmin=0, vmax=1)\n",
    "ax1.set_title(im_rgba.filename.split(\"/\")[-1])\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "ax2.imshow(im_rgba_r, cmap=\"Reds\", vmin=0, vmax=255)\n",
    "ax2.set_title(\"red channel\")\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "ax3.imshow(im_rgba_g, cmap=\"Greens\", vmin=0, vmax=255)\n",
    "ax3.set_title(\"green channel\")\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "ax4.imshow(im_rgba_b, cmap=\"Blues\", vmin=0, vmax=255)\n",
    "ax4.set_title(\"blue channel\")\n",
    "ax5 = fig.add_subplot(gs[1, 3])\n",
    "ax5.imshow(im_rgba_a, cmap=\"gray\", vmin=0, vmax=255)\n",
    "ax5.set_title(\"alpha channel\")\n",
    "for ax in fig.axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_6_'></a>[Indexed Color Images (Palette-Based)](#toc0_)\n",
    "\n",
    "- Uses a limited color palette, with each pixel storing an index to a predefined color table.\n",
    "- **Bit Depth**:\n",
    "  - **8-bit (256 colors)**\n",
    "  - **4-bit (16 colors), 2-bit (4 colors), 1-bit (monochrome)**\n",
    "- **File Formats**:\n",
    "  - **GIF** (supports animation and transparency).\n",
    "  - **PNG-8** (optimized lossless compression).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log\n",
    "print(f\"type(im_indexed_rgba)                    : {type(im_indexed_rgba)}\")\n",
    "print(f\"im_indexed_rgba.format                   : {im_indexed_rgba.format}\")\n",
    "print(f\"im_indexed_rgba.mode                     : {im_indexed_rgba.mode}\")\n",
    "print(f\"im_indexed_rgba.size                     : {im_indexed_rgba.size}\")\n",
    "print(f\"im_indexed_rgba.has_transparency_data    : {im_indexed_rgba.has_transparency_data}\")\n",
    "print(f\"im_indexed_rgba.info.get('transparency') : {im_indexed_rgba.info.get(\"transparency\")}\")\n",
    "print(f\"im_indexed_rgba.info.get('compression')  : {im_indexed_rgba.info.get(\"compression\")}\")\n",
    "print(f\"im_indexed_rgba.info.get('dpi')          : {im_indexed_rgba.info.get(\"dpi\")}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.array(im_indexed_rgba.getpalette(), dtype=np.uint8).reshape(-1, 3)\n",
    "alpha_idx = im_indexed_rgba.info.get(\"transparency\")\n",
    "\n",
    "# log\n",
    "print(f\"colors.shape : {colors.shape}\")\n",
    "print(f\"alpha index  : {alpha_idx}\")\n",
    "print(f\"colors :\\n{colors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_7_'></a>[Multispectral & Hyperspectral Image](#toc0_)\n",
    "\n",
    "- Captured across multiple bands of the electromagnetic spectrum beyond visible light.\n",
    "- **Bit Depth**: **Often 16-bit or higher per channel.**\n",
    "- **File Formats**:\n",
    "  - **ENVI** (hyperspectral imaging format).\n",
    "  - **GeoTIFF** (for GIS applications).\n",
    "  - **DICOM** (for medical imaging).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_8_'></a>[HDR (High Dynamic Range) Images](#toc0_)\n",
    "- Stores a wider range of brightness and color depth.\n",
    "- **Bit Depth**: **10-bit, 12-bit, 16-bit, or 32-bit floating point per channel**.\n",
    "- **File Formats**:\n",
    "  - **EXR (OpenEXR)** (used in professional CGI and VFX).\n",
    "  - **HDR (Radiance HDR)** (for HDR photography).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_9_'></a>[Depth Maps & Alpha Masks](#toc0_)\n",
    "\n",
    "- Stores depth information (distance from the camera) or transparency levels.\n",
    "- **Bit Depth**:\n",
    "  - **8-bit (0‚Äì255 depth levels or transparency values).**\n",
    "  - **16-bit / 32-bit for higher precision.**\n",
    "- **File Formats**:\n",
    "  - **EXR** (for depth and transparency maps in 3D rendering).\n",
    "  - **PNG** (grayscale alpha masks).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[Converting Pixels to Physical Dimensions](#toc0_)\n",
    "\n",
    "- When working with images, we often need to switch between **digital units (pixels)** and **physical units (inches or centimeters)**.  \n",
    "- This conversion is essential for tasks like cropping by real-world size, printing images at the right dimensions, or resizing images for publications.  \n",
    "\n",
    "‚úç **Key Concepts**:\n",
    "\n",
    "- **Pixel dimensions**: The width and height of an image in pixels (e.g., 1920√ó1080 px).  \n",
    "- **Physical dimensions**: The size of the image in real-world units (inches, cm, mm).  \n",
    "- **DPI (dots per inch) / PPI (pixels per inch)**: The scaling factor that links pixels to physical size.  \n",
    "\n",
    "üî¢ **Converting Between Pixels and Inches/cm**:\n",
    "\n",
    "- $1$ inch = $2.54$ cm\n",
    "\n",
    "$$\n",
    "\\text{pixels} = \\text{inches} \\times \\text{DPI}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_px, x_px = im_2.shape                  # vertical, horizontal pixels\n",
    "x_dpi, y_dpi = im_grayscale.info[\"dpi\"]  # horizontal, vertical DPI\n",
    "\n",
    "# log\n",
    "print(f\"y_px  : {y_px} px\")\n",
    "print(f\"x_px  : {x_px} px\")\n",
    "print(f\"y_dpi : {y_dpi:.0f} dpi\")\n",
    "print(f\"x_dpi : {x_dpi:.0f} dpi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel to inch\n",
    "y_px2in = y_px / y_dpi\n",
    "x_px2in = x_px / x_dpi\n",
    "\n",
    "# pixel to cm\n",
    "y_px2cm = y_px2in * 2.54\n",
    "x_px2cm = x_px2in * 2.54\n",
    "\n",
    "# log\n",
    "print(f\"y_px2in : {y_px2in:.2f} in\")\n",
    "print(f\"x_px2in : {x_px2in:.2f} in\")\n",
    "print(f\"y_px2cm : {y_px2cm:.2f} cm\")\n",
    "print(f\"x_px2cm : {x_px2cm:.2f} cm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_4_'></a>[Basic Modifications](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_4_1_'></a>[‚úÇÔ∏è Cropping](#toc0_)\n",
    "\n",
    "Cropping an image involves selecting a region of interest (ROI) and discarding the rest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_4_1_1_'></a>[Manual](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image: NDArray, x_start: int, x_end: int, y_start: int, y_end: int) -> NDArray:\n",
    "    return image[y_start:y_end, x_start:x_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_2_crop_1 = crop(im_2, 0, 128, 0, 128)\n",
    "im_2_crop_2 = crop(im_2, 64, 192, 64, 192)\n",
    "im_2_crop_3 = crop(im_2, 100, 150, 50, 100)\n",
    "im_4_crop_1 = crop(im_4, 0, 256, 0, 256)\n",
    "im_4_crop_2 = crop(im_4, 120, 300, 120, 300)\n",
    "im_4_crop_3 = crop(im_4, 240, 290, 250, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(16, 8), layout=\"compressed\")\n",
    "images = [\n",
    "    [im_2, im_2_crop_1, im_2_crop_2, im_2_crop_3],\n",
    "    [im_4, im_4_crop_1, im_4_crop_2, im_4_crop_3],\n",
    "]\n",
    "titles = [\n",
    "    [\"im_2\", \"im_2[:128, :128]\", \"im_2[64:192, 64:192]\", \"im_2[50:100, 100:150]\"],\n",
    "    [\"im_4\", \"im_4[:256, :256]\", \"im_4[120:300, 120:300]\", \"im_4[250:300, 240:290]\"],\n",
    "]\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        axs[i, j].imshow(images[i][j], cmap=\"gray\")\n",
    "        axs[i, j].set_title(titles[i][j], fontdict={\"family\": \"consolas\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_4_1_2_'></a>[Using PIL](#toc0_)\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `PIL.Image.Image.crop`: [pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.crop](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.crop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_grayscale_crop_1 = im_grayscale.crop(box=(0, 0, 128, 128))\n",
    "im_grayscale_crop_2 = im_grayscale.crop(box=(64, 64, 192, 192))\n",
    "im_grayscale_crop_3 = im_grayscale.crop(box=(100, 50, 150, 100))\n",
    "im_rgb_crop_1 = im_rgb.crop(box=(0, 0, 256, 256))\n",
    "im_rgb_crop_2 = im_rgb.crop(box=(120, 120, 300, 300))\n",
    "im_rgb_crop_3 = im_rgb.crop(box=(240, 250, 290, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(16, 8), layout=\"compressed\")\n",
    "images = [\n",
    "    [im_grayscale, im_grayscale_crop_1, im_grayscale_crop_2, im_grayscale_crop_3],\n",
    "    [im_rgb, im_rgb_crop_1, im_rgb_crop_2, im_rgb_crop_3],\n",
    "]\n",
    "titles = [\n",
    "    [\"im_grayscale\", \"im_grayscale_crop_1\", \"im_grayscale_crop_2\", \"im_grayscale_crop_3\"],\n",
    "    [\"im_rgb\", \"im_rgb_crop_1\", \"im_rgb_crop_2\", \"im_rgb_crop_3\"],\n",
    "]\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        axs[i, j].imshow(images[i][j], cmap=\"gray\")\n",
    "        axs[i, j].set_title(titles[i][j], fontdict={\"family\": \"consolas\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_4_2_'></a>[ü™û Flipping](#toc0_)\n",
    "Flipping can be done horizontally or vertically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_4_2_1_'></a>[Manual](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(image: NDArray, axis: int) -> NDArray:\n",
    "    if axis == 0:\n",
    "        return image[::-1]\n",
    "    elif axis == 1:\n",
    "        return image[:, ::-1]\n",
    "    elif axis == 2:\n",
    "        return image[:, :, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_2_flip_1 = flip(im_2, axis=0)\n",
    "im_2_flip_2 = flip(im_2, axis=1)\n",
    "im_2_flip_3 = flip(im_2_flip_1, axis=1)\n",
    "im_4_flip_1 = flip(im_4, axis=0)\n",
    "im_4_flip_2 = flip(im_4, axis=1)\n",
    "im_4_flip_3 = flip(im_4_flip_1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(2, 4, figsize=(16, 8), layout=\"compressed\")\n",
    "images = [\n",
    "    [im_2, im_2_flip_1, im_2_flip_2, im_2_flip_3],\n",
    "    [im_4, im_4_flip_1, im_4_flip_2, im_4_flip_3],\n",
    "]\n",
    "titles = [\n",
    "    [\"im_2\", \"im_2_flip_1\", \"im_2_flip_2\", \"im_2_flip_3\"],\n",
    "    [\"im_4\", \"im_4_flip_1\", \"im_4_flip_2\", \"im_4_flip_3\"],\n",
    "]\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        axs[i, j].imshow(images[i][j], cmap=\"gray\")\n",
    "        axs[i, j].set_title(titles[i][j], fontdict={\"family\": \"consolas\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_4_2_2_'></a>[Using OpenCV](#toc0_)\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `cv2.flip`: [docs.opencv.org/master/d2/de8/group__core__array.html#gaca7be533e3dac7feb70fc60635adf441](https://docs.opencv.org/master/d2/de8/group__core__array.html#gaca7be533e3dac7feb70fc60635adf441)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_2_flip_4 = cv2.flip(im_2, 0)\n",
    "im_2_flip_5 = cv2.flip(im_2, 1)\n",
    "im_2_flip_6 = cv2.flip(im_2_flip_4, 1)\n",
    "im_4_flip_4 = cv2.flip(im_4, 0)\n",
    "im_4_flip_5 = cv2.flip(im_4, 1)\n",
    "im_4_flip_6 = cv2.flip(im_4_flip_4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(16, 8), layout=\"compressed\")\n",
    "images = [\n",
    "    [im_2, im_2_flip_4, im_2_flip_5, im_2_flip_6],\n",
    "    [im_4, im_4_flip_4, im_4_flip_5, im_4_flip_6],\n",
    "]\n",
    "titles = [\n",
    "    [\"im_2\", \"im_2_flip_4\", \"im_2_flip_5\", \"im_2_flip_6\"],\n",
    "    [\"im_4\", \"im_4_flip_4\", \"im_4_flip_5\", \"im_4_flip_6\"],\n",
    "]\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        axs[i, j].imshow(images[i][j], cmap=\"gray\")\n",
    "        axs[i, j].set_title(titles[i][j], fontdict={\"family\": \"consolas\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_4_2_3_'></a>[Using PIL](#toc0_)\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `PIL.Image.Image.transpose`: [pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.transpose](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.transpose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_grayscale_flip_1 = im_grayscale.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "im_grayscale_flip_2 = im_grayscale.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "im_grayscale_flip_3 = im_grayscale_flip_1.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "im_rgb_flip_1 = im_rgb.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "im_rgb_flip_2 = im_rgb.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "im_rgb_flip_3 = im_rgb_flip_1.transpose(Image.FLIP_LEFT_RIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(2, 4, figsize=(16, 8), layout=\"compressed\")\n",
    "images = [\n",
    "    [im_grayscale, im_grayscale_flip_1, im_grayscale_flip_2, im_grayscale_flip_3],\n",
    "    [im_rgb, im_rgb_flip_1, im_rgb_flip_2, im_rgb_flip_3],\n",
    "]\n",
    "titles = [\n",
    "    [\"im_grayscale\", \"im_grayscale_flip_1\", \"im_grayscale_flip_2\", \"im_grayscale_flip_3\"],\n",
    "    [\"im_rgb\", \"im_rgb_flip_1\", \"im_rgb_flip_2\", \"im_rgb_flip_3\"],\n",
    "]\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        axs[i, j].imshow(images[i][j], cmap=\"gray\")\n",
    "        axs[i, j].set_title(titles[i][j], fontdict={\"family\": \"consolas\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_4_3_'></a>[üîÉ Circular Shift](#toc0_)\n",
    "\n",
    "Circular shifting moves pixels in a cyclic manner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_4_3_1_'></a>[Manual](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_shift(image: NDArray, dx: int, dy: int) -> NDArray:\n",
    "    x_shift = np.hstack((image[:, dx:], image[:, :dx]))\n",
    "    y_shift = np.vstack((x_shift[dy:], x_shift[:dy]))\n",
    "    return y_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_2_cshift_1 = circular_shift(im_2, dx=0, dy=128)\n",
    "im_2_cshift_2 = circular_shift(im_2, dx=128, dy=0)\n",
    "im_2_cshift_3 = circular_shift(im_2, dx=128, dy=128)\n",
    "im_4_cshift_1 = circular_shift(im_4, dx=0, dy=256)\n",
    "im_4_cshift_2 = circular_shift(im_4, dx=256, dy=0)\n",
    "im_4_cshift_3 = circular_shift(im_4, dx=256, dy=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(2, 4, figsize=(16, 8), layout=\"compressed\")\n",
    "images = [\n",
    "    [im_2, im_2_cshift_1, im_2_cshift_2, im_2_cshift_3],\n",
    "    [im_4, im_4_cshift_1, im_4_cshift_2, im_4_cshift_3],\n",
    "]\n",
    "titles = [\n",
    "    [\"im_2\", \"im_2_cshift_1\", \"im_2_cshift_2\", \"im_2_cshift_3\"],\n",
    "    [\"im_4\", \"im_4_cshift_1\", \"im_4_cshift_2\", \"im_4_cshift_3\"],\n",
    "]\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        axs[i, j].imshow(images[i][j], cmap=\"gray\")\n",
    "        axs[i, j].set_title(titles[i][j], fontdict={\"family\": \"consolas\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_4_3_2_'></a>[Using NumPy](#toc0_)\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `numpy.roll`: [numpy.org/doc/stable/reference/generated/numpy.roll.html](https://numpy.org/doc/stable/reference/generated/numpy.roll.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_2_cshift_4 = np.roll(im_2, shift=(128, 0), axis=(0, 1))\n",
    "im_2_cshift_5 = np.roll(im_2, shift=(0, 128), axis=(0, 1))\n",
    "im_2_cshift_6 = np.roll(im_2, shift=(128, 128), axis=(0, 1))\n",
    "im_4_cshift_4 = np.roll(im_4, shift=(256, 0), axis=(0, 1))\n",
    "im_4_cshift_5 = np.roll(im_4, shift=(0, 256), axis=(0, 1))\n",
    "im_4_cshift_6 = np.roll(im_4, shift=(256, 256), axis=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(2, 4, figsize=(16, 8), layout=\"compressed\")\n",
    "images = [\n",
    "    [im_2, im_2_cshift_4, im_2_cshift_5, im_2_cshift_6],\n",
    "    [im_4, im_4_cshift_4, im_4_cshift_5, im_4_cshift_6],\n",
    "]\n",
    "titles = [\n",
    "    [\"im_2\", \"im_2_cshift_4\", \"im_2_cshift_5\", \"im_2_cshift_6\"],\n",
    "    [\"im_4\", \"im_4_cshift_4\", \"im_4_cshift_5\", \"im_4_cshift_6\"],\n",
    "]\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        axs[i, j].imshow(images[i][j], cmap=\"gray\")\n",
    "        axs[i, j].set_title(titles[i][j], fontdict={\"family\": \"consolas\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_5_'></a>[Save Images](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"../output/images\")\n",
    "output_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_5_1_1_'></a>[Using Matplotlib](#toc0_)\n",
    "\n",
    "- Integrated with plotting, supports RGBA images, and automatically scales pixel values.\n",
    "- Best for visualizing images and saving plots as images.\n",
    "- It uses the Pillow library under the hood to save images!\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `plt.imsave`: [matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imsave.html](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imsave.html)\n",
    "- Image file formats: [pillow.readthedocs.io/en/stable/handbook/image-file-formats.html](https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a png file\n",
    "plt.imsave(\n",
    "    fname=f\"{output_path}/png_mpl.png\",\n",
    "    arr=im_4_crop_3,\n",
    "    vmin=0,\n",
    "    vmax=255,\n",
    "    format=\"png\",\n",
    "    pil_kwargs={\"optimize\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert RGB to grayscale\n",
    "im_4_crop_3_gs = cv2.cvtColor(im_4_crop_3, code=cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# save as a grayscale jpeg file\n",
    "plt.imsave(\n",
    "    fname=f\"{output_path}/jpg_mpl.jpg\",\n",
    "    arr=im_4_crop_3_gs,\n",
    "    cmap=\"gray\",\n",
    "    vmin=0,\n",
    "    vmax=255,\n",
    "    format=\"jpg\",\n",
    "    pil_kwargs={\"quality\": 95, \"optimize\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_5_1_2_'></a>[Using scikit-image](#toc0_)\n",
    "\n",
    "- Provides functions for saving images with `skimage.io.imsave`.\n",
    "- Automatically handles numeric arrays and scales pixel values when saving.\n",
    "- Supports a wide range of formats via Pillow and imageio backends.\n",
    "- More suitable for image processing workflows rather than plotting.\n",
    "\n",
    "‚ö†Ô∏è **Limitation:**\n",
    "\n",
    "- Cannot pass encoder-specific options (e.g., `optimize` for PNG, `quality` for JPEG).\n",
    "- For such parameters, use other available packages.\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `skimage.io.imsave`: [scikit-image.org/docs/stable/api/skimage.io.html#skimage.io.imsave](https://scikit-image.org/docs/stable/api/skimage.io.html#skimage.io.imsave)\n",
    "- Image file formats (via Pillow): [pillow.readthedocs.io/en/stable/handbook/image-file-formats.html](https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a png file\n",
    "ski.io.imsave(\n",
    "    fname=f\"{output_path}/png_ski.png\",\n",
    "    arr=im_4_crop_3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a grayscale jpeg file\n",
    "ski.io.imsave(\n",
    "    fname=f\"{output_path}/jpg_ski.jpg\",\n",
    "    arr=im_4_crop_3_gs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_5_1_3_'></a>[Using OpenCV](#toc0_)\n",
    "\n",
    "- High performance [implemented in C++], supports advanced image processing, and handles BGR format natively.\n",
    "- Best for computer vision tasks and real-time image processing.\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `cv2.imwrite`: [docs.opencv.org/master/d4/da8/group__imgcodecs.html#ga8ac397bd09e48851665edbe12aa28f25](https://docs.opencv.org/master/d4/da8/group__imgcodecs.html#ga8ac397bd09e48851665edbe12aa28f25)\n",
    "- `cv2.cvtColor`: [docs.opencv.org/master/d8/d01/group__imgproc__color__conversions.html#gaf86c09fe702ed037c03c2bc603ceab14](https://docs.opencv.org/master/d8/d01/group__imgproc__color__conversions.html#gaf86c09fe702ed037c03c2bc603ceab14)\n",
    "- `ImwriteFlags`: [docs.opencv.org/master/d8/d6a/group__imgcodecs__flags.html#ga292d81be8d76901bff7988d18d2b42ac](https://docs.opencv.org/master/d8/d6a/group__imgcodecs__flags.html#ga292d81be8d76901bff7988d18d2b42ac)\n",
    "- `ImreadModes`: [docs.opencv.org/master/d8/d6a/group__imgcodecs__flags.html#ga61d9b0126a3e57d9277ac48327799c80](https://docs.opencv.org/master/d8/d6a/group__imgcodecs__flags.html#ga61d9b0126a3e57d9277ac48327799c80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert RGB to BGR\n",
    "im_4_crop_3_bgr = cv2.cvtColor(im_4_crop_3, code=cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# save as a png file\n",
    "cv2.imwrite(\n",
    "    filename=f\"{output_path}/png_cv2.png\",\n",
    "    img=im_4_crop_3_bgr,\n",
    "    params=[cv2.IMWRITE_PNG_COMPRESSION, 9],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a jpeg file\n",
    "cv2.imwrite(\n",
    "    filename=f\"{output_path}/jpg_cv2.jpg\",\n",
    "    img=im_4_crop_3_gs,\n",
    "    params=[cv2.IMWRITE_JPEG_QUALITY, 95, cv2.IMWRITE_JPEG_OPTIMIZE, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_5_1_4_'></a>[Using PIL](#toc0_)\n",
    "\n",
    "- Simple and intuitive API, supports a wide range of image formats.\n",
    "- Best for basic image I/O and manipulation tasks.\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `Image.save`: [pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.save](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.save)\n",
    "- `PIL.Image.Image.convert`: [pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.convert](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.convert)\n",
    "- Image file formats: [pillow.readthedocs.io/en/stable/handbook/image-file-formats.html](https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a png file\n",
    "im_rgb_crop_3.save(\n",
    "    fp=f\"{output_path}/png_pil.png\",\n",
    "    format=\"png\",\n",
    "    optimize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a grayscale jpeg file\n",
    "im_rgb_crop_3.convert(\"L\").save(\n",
    "    fp=f\"{output_path}/jpg_pil.jpg\",\n",
    "    format=\"jpeg\",\n",
    "    quality=95,\n",
    "    optimize=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "media-processing-workshop (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "orig_nbformat": 4,
  "origin_repo": "https://github.com/mr-pylin/media-processing-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
