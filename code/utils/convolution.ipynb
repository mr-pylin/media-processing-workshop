{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üìù **Author:** Amirhossein Heydari - üìß **Email:** <amirhosseinheydari78@gmail.com> - üìç **Origin:** [mr-pylin/media-processing-workshop](https://github.com/mr-pylin/media-processing-workshop)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Table of contents**<a id='toc0_'></a>    \n",
        "- [Dependencies](#toc1_)    \n",
        "- [Signals and Systems](#toc2_)    \n",
        "  - [Linear Time-Invariant (LTI) Systems](#toc2_1_)    \n",
        "    - [Convolution](#toc2_1_1_)    \n",
        "      - [Circular Convolution](#toc2_1_1_1_)    \n",
        "      - [Separable Convolution](#toc2_1_1_2_)    \n",
        "  - [Cross-Correlation](#toc2_2_)    \n",
        "  - [Padding](#toc2_3_)    \n",
        "  - [Examples](#toc2_4_)    \n",
        "    - [Example 1: Apply Padding to Signals](#toc2_4_1_)    \n",
        "      - [Using NumPy](#toc2_4_1_1_)    \n",
        "      - [Using OpenCV](#toc2_4_1_2_)    \n",
        "    - [Example 2: 1D Convolution](#toc2_4_2_)    \n",
        "      - [Manual](#toc2_4_2_1_)    \n",
        "      - [Using NumPy](#toc2_4_2_2_)    \n",
        "      - [Using SciPy](#toc2_4_2_3_)    \n",
        "    - [Example 3: 2D Convolution](#toc2_4_3_)    \n",
        "      - [Manual](#toc2_4_3_1_)    \n",
        "      - [Using OpenCV](#toc2_4_3_2_)    \n",
        "      - [Using SciPy](#toc2_4_3_3_)    \n",
        "    - [Example 4: Separable Convolution](#toc2_4_4_)    \n",
        "      - [Manual](#toc2_4_4_1_)    \n",
        "    - [Example 5: 2D Cross-Correlation](#toc2_4_5_)    \n",
        "      - [Using SciPy](#toc2_4_5_1_)    \n",
        "\n",
        "<!-- vscode-jupyter-toc-config\n",
        "\tnumbering=false\n",
        "\tanchor=true\n",
        "\tflat=false\n",
        "\tminLevel=1\n",
        "\tmaxLevel=6\n",
        "\t/vscode-jupyter-toc-config -->\n",
        "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc1_'></a>[Dependencies](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from numpy.typing import NDArray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc2_'></a>[Signals and Systems](#toc0_)\n",
        "\n",
        "- A **signal** is a function that conveys information about the behavior or attributes of a **physical phenomenon**.\n",
        "  - **Continuous-time**: $x(t)$, defined for every instant of time.\n",
        "  - **Discrete-time**: $x[n]$, defined only at specific instants of time.\n",
        "- A **system** is an entity that processes an input signal to produce an output signal.\n",
        "  - **Continuous-time**:\n",
        "    $$y(t) = T\\{x(t)\\}$$\n",
        "  - **Discrete-time**:\n",
        "    $$y[n] = T\\{x[n]\\}$$\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/signal-and-system.svg\" alt=\"signal-and-system.svg\" style=\"max-width:80%; height:auto;\">\n",
        "  <figcaption>Signals and Systems</figcaption>\n",
        "</figure>\n",
        "\n",
        "üìã **Properties of Systems:**\n",
        "\n",
        "1. **Linearity**: A system is linear if it satisfies the **superposition principle**:\n",
        "   $$T\\{a x_1(t) + b x_2(t)\\} = a T\\{x_1(t)\\} + b T\\{x_2(t)\\}$$\n",
        "1. **Time-Invariance**: A system is time-invariant if a time shift in the **input** results in the same time shift in the **output**:\n",
        "   $$y(t - t_0) = T\\{x(t - t_0)\\}$$\n",
        "1. **Causality**: A system is causal if the **output** at any time $\\mathbf{t}$ depends only on the input at the **present** and **past** times, **not future** times.\n",
        "1. **Stability**: A system is stable if bounded inputs produce bounded outputs (**BIBO stability**).\n",
        "1. **Memory**: A system is **memoryless** if the output at any time $\\mathbf{t}$ depends only on the input at the same time $\\mathbf{t}$.\n",
        "\n",
        "üìù **Docs**:\n",
        "\n",
        "- Signal processing: [en.wikipedia.org/wiki/Signal_processing](https://en.wikipedia.org/wiki/Signal_processing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_1_'></a>[Linear Time-Invariant (LTI) Systems](#toc0_)\n",
        "\n",
        "- An **LTI** system is a system that is both **linear** and **time-invariant**.\n",
        "- The **impulse response** of an LTI system is the output of the system when the input is an **impulse**:\n",
        "  - For **continuous-time systems**:\n",
        "    $$h(t) = T\\{\\delta(t)\\}$$\n",
        "  - For **discrete-time systems**:\n",
        "    $$h[n] = T\\{\\delta[n]\\}$$\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/impulse.svg\" alt=\"impulse.svg\" style=\"max-width:80%; height:auto;\">\n",
        "  <figcaption>Impulse Signal</figcaption>\n",
        "</figure>\n",
        "\n",
        "- The impulse response $\\mathbf{h(t)}$ or $\\mathbf{h[n]}$ completely characterizes an LTI system.\n",
        "- Once the **impulse response** is known, the **output** for **any input** can be computed using **Convolution**.\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/lti-system.svg\" alt=\"lti-system.svg\" style=\"max-width:80%; height:auto;\">\n",
        "  <figcaption>Linear Time-Invariant Systems</figcaption>\n",
        "</figure>\n",
        "\n",
        "‚ùì **Example:**\n",
        "\n",
        "- $h[n] = \\{1, 2, 1\\}$\n",
        "- $x[n] = \\{1, 2\\}$\n",
        "- $y[n] = ?$\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/lti-example.svg\" alt=\"lti-example.svg\" style=\"max-width:100%; height:auto;\">\n",
        "  <figcaption>Linear Time-Invariant Systems Example</figcaption>\n",
        "</figure>\n",
        "\n",
        "üìù **Docs**:\n",
        "\n",
        "- Linear time-invariant system: [en.wikipedia.org/wiki/Linear_time-invariant_system](https://en.wikipedia.org/wiki/Linear_time-invariant_system)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_1_1_'></a>[Convolution](#toc0_)\n",
        "\n",
        "- Convolution is a mathematical operation that **combines** two functions to produce a third function.\n",
        "- For **LTI** systems, convolution is used to compute the **output** of the system given the **input** and the **impulse response**.\n",
        "- **Continuous-Time Convolution**\n",
        "  - For continuous-time LTI systems, the output $\\mathbf{y(t)}$ is the convolution of the input $\\mathbf{x(t)}$ and the impulse response $\\mathbf{h(t)}$:\n",
        "  $$y(t) = x(t) * h(t) = \\int_{-\\infty}^{\\infty} x(\\tau) h(t - \\tau) \\, d\\tau$$\n",
        "  - This **integral** represents the superposition of **scaled** and **shifted** versions of the **impulse response**.\n",
        "- **Discrete-Time Convolution**\n",
        "  - For discrete-time LTI systems, the output $\\mathbf{y[n]}$ is the convolution of the input $\\mathbf{x[n]}$ and the impulse response $\\mathbf{h[n]}$:\n",
        "  $$y[n] = x[n] * h[n] = \\sum_{k=-\\infty}^{\\infty} x[k] h[n - k]$$\n",
        "  - This **sum** represents the weighted **sum** of **shifted** versions of the **impulse response**.\n",
        "\n",
        "‚ùì **Example:**\n",
        "\n",
        "- $h[n] = \\{1, 2, 1\\}$\n",
        "- $x[n] = \\{1, 2\\}$\n",
        "- $y[n] = ?$\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/convolution-kernel-flip.svg\" alt=\"convolution-kernel-flip.svg\" style=\"max-width:80%; height:auto;\">\n",
        "  <figcaption>Convolution (flipped kernel)</figcaption>\n",
        "</figure>\n",
        "\n",
        "üìã **Properties of Convolution:**\n",
        "\n",
        "1. **Commutativity**:\n",
        "    $$x[n] * h[n] = h[n] * x[n]$$\n",
        "1. **Associativity**:\n",
        "    $$(x(t) * h_1(t)) * h_2(t) = x(t) * (h_1(t) * h_2(t))$$\n",
        "1. **Distributivity**:\n",
        "    $$x(t) * (h_1(t) + h_2(t)) = x(t) * h_1(t) + x(t) * h_2(t)$$\n",
        "1. **Identity**:\n",
        "    $$x(t) * \\delta(t) = x(t)$$\n",
        "\n",
        "üìù **Docs**:\n",
        "\n",
        "- Convolution: [en.wikipedia.org/wiki/Convolution](https://en.wikipedia.org/wiki/Convolution)\n",
        "- `numpy.convolve`: [numpy.org/doc/2.1/reference/generated/numpy.convolve.html](https://numpy.org/doc/2.1/reference/generated/numpy.convolve.html)\n",
        "- `scipy.signal`: [docs.scipy.org/doc/scipy/reference/signal.html](https://docs.scipy.org/doc/scipy/reference/signal.html)\n",
        "- `cv2.filter2D`: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga27c049795ce870216ddfb366086b5a04](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga27c049795ce870216ddfb366086b5a04)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_1_1_1_'></a>[Circular Convolution](#toc0_)\n",
        "\n",
        "- Circular convolution is a special type of convolution where the input signals are assumed to be **periodic**.\n",
        "- For two discrete signals $\\mathbf{x[n]}$ and $\\mathbf{h[n]}$ of length $\\mathbf{N}$, the circular convolution is defined as:\n",
        "\n",
        "$$y[n] = \\sum_{m=0}^{N-1} x[m] h[(n - m) \\mod N]$$\n",
        "\n",
        "- The result is another **finite-length** sequence of the **same length** as the **inputs**.\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/circular-convolution.svg\" alt=\"circular-convolution.svg\" style=\"max-width:90%; height:auto;\">\n",
        "  <figcaption>Circular Convolution</figcaption>\n",
        "</figure>\n",
        "\n",
        "- It is particularly important in the context of **Fourier transforms**, as **convolution** in the **time domain** corresponds to **multiplication** in the **frequency domain**:\n",
        "\n",
        "$$\\mathcal{F}\\{x[n] * h[n]\\} = X(\\omega) \\cdot H(\\omega)$$\n",
        "$$\\mathcal{F}\\{x[n] \\cdot h[n]\\} = X(\\omega) * H(\\omega)$$\n",
        "\n",
        "üÜö **Circular vs. Linear Convolution**:\n",
        "\n",
        "- **Linear Convolution**: Used for finite non-periodic signals. $\\text{length} = N+M‚àí1$.\n",
        "- **Circular Convolution**: Assumes periodicity. $\\text{length} = max(N,M)$.\n",
        "- **Key Insight**: Circular convolution **wraps around overlapping parts**, while linear convolution **zero-pads**.\n",
        "\n",
        "ü§ö **Avoiding Wrap-Around Artifacts**:\n",
        "\n",
        "- To compute **linear convolution** using **DFT**:\n",
        "  - Zero-pad both sequences to length $N+M‚àí1$.\n",
        "  - Perform circular convolution on the padded sequences.\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/linear-vs-circular-convolution.svg\" alt=\"linear-vs-circular-convolution.svg\" style=\"max-width:90%; height:auto;\">\n",
        "  <figcaption>Linear vs. Circular Convolution</figcaption>\n",
        "</figure>\n",
        "\n",
        "üî¢ **Matrix Representation (Circulant Matrix)**:\n",
        "\n",
        "- Circular convolution can be represented as multiplication by a **circulant matrix**.\n",
        "- For $h=[h_0‚Äã,h_1‚Äã,h_2‚Äã]$:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "h_0 & h_2 & h_1 \\\\\n",
        "h_1 & h_0 & h_2 \\\\\n",
        "h_2 & h_1 & h_0 \\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "x_1 \\\\\n",
        "x_2 \\\\\n",
        "x_3 \\\\\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "y_1 \\\\\n",
        "y_2 \\\\\n",
        "y_3 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_1_1_2_'></a>[Separable Convolution](#toc0_)\n",
        "\n",
        "- Separable convolution is a technique used to **reduce computation** when applying **2D** convolution filters.\n",
        "- A convolution kernel $\\mathbf{K}$ is **separable** if it can be **decomposed** into the **outer product** of two **1D kernels** (its matrix has **Rank 1**):\n",
        "\n",
        "\\begin{aligned}\n",
        "K &= k_c \\otimes k_r \\\\\n",
        "&\\text{where } k_r \\text{ is a 1D row filter and } k_c \\text{ is a 1D column filter.}\n",
        "\\end{aligned}\n",
        "\n",
        "- Instead of performing a full 2D convolution, we can apply a **row-wise** convolution first, followed by a **column-wise** convolution.\n",
        "- This reduces complexity from $\\mathcal{O}(n^2 k^2)$ to $\\mathcal{O}(n^2 k) + \\mathcal{O}(n^2 k) = \\mathcal{O}(2n^2 k)$ per dimension.\n",
        "\n",
        "**Example**:\n",
        "\n",
        "$$\n",
        "S_x = \n",
        "\\begin{bmatrix}\n",
        "1 & 0 & -1 \\\\\n",
        "2 & 0 & -2 \\\\\n",
        "1 & 0 & -1\n",
        "\\end{bmatrix} \n",
        "= \n",
        "\\underbrace{\\begin{bmatrix} 1 \\\\ 2 \\\\ 1 \\end{bmatrix}}_{k_c} \n",
        "\\cdot \n",
        "\\underbrace{\\begin{bmatrix} 1 & 0 & -1 \\end{bmatrix}}_{k_r}\n",
        "$$\n",
        "\n",
        "For example, if \\( k = 3 \\):\n",
        "\n",
        "$$\n",
        "1 - \\frac{2}{3} \\approx 33.3\\% \\text{ reduction in operations.}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_2_'></a>[Cross-Correlation](#toc0_)\n",
        "\n",
        "- It measures the **similarity** between two signals.\n",
        "- It is closely related to convolution, but unlike convolution, cross-correlation **DOES NOT** flip the kernel.\n",
        "- This makes cross-correlation particularly useful in applications like **template matching**, **signal alignment**, and **feature detection**.\n",
        "\n",
        "$$y[n] = \\sum_{k} x[k] \\cdot h[k + n]$$\n",
        "$$y[i, j] = \\sum_{m} \\sum_{n} x[m, n] \\cdot h[m + i, n + j]$$\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/convolution-vs-correlation.svg\" alt=\"convolution-vs-correlation.svg\" style=\"max-width:80%; height:auto;\">\n",
        "  <figcaption>Convolution vs. Cross-Correlation</figcaption>\n",
        "</figure>\n",
        "\n",
        "üìù **Docs**:\n",
        "\n",
        "- Cross-correlation: [en.wikipedia.org/wiki/Cross-correlation](https://en.wikipedia.org/wiki/Cross-correlation)\n",
        "- `scipy.signal`: [docs.scipy.org/doc/scipy/reference/signal.html](https://docs.scipy.org/doc/scipy/reference/signal.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_3_'></a>[Padding](#toc0_)\n",
        "\n",
        "Padding is used to control the **size** of the **output** after applying a **convolution** or **cross-correlation** operation.\n",
        "\n",
        "<table style=\"margin:0 auto;\">\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th>Category</th>\n",
        "      <th>Type</th>\n",
        "      <th>Description</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td rowspan=\"5\"><strong>Padded Values</strong></td>\n",
        "      <td>Zero Padding</td>\n",
        "      <td>Adds zeros around the input signal.</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Reflect Padding</td>\n",
        "      <td>Mirrors the input signal at the boundaries (excluding the boundary value).</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Symmetric  Padding</td>\n",
        "      <td>Mirrors the input signal at the boundaries (including the boundary value).</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Circular (Wrap) Padding</td>\n",
        "      <td>Wraps the input signal around as if it were periodic.</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Replicate (Edge) Padding</td>\n",
        "      <td>Repeats the edge values of the input signal.</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td rowspan=\"3\"><strong>Amount of Padding</strong></td>\n",
        "      <td>Valid Padding (No Padding)</td>\n",
        "      <td>No padding is added. The output size is smaller than the input size.</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Same Padding</td>\n",
        "      <td>Adds padding such that the output size matches the input size.</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Full Padding</td>\n",
        "      <td>Adds enough padding so that every element of the input is covered by the kernel at least once. The output size is larger than the input size.</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/padding-1d.svg\" alt=\"padding-1d.svg\" style=\"max-width:90%; height:auto;\">\n",
        "  <figcaption>Padding for 1D Convolution</figcaption>\n",
        "</figure>\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/padding-2d.svg\" alt=\"padding-2d.svg\" style=\"max-width:80%; height:auto;\">\n",
        "  <figcaption>Padding for 2D Convolution</figcaption>\n",
        "</figure>\n",
        "\n",
        "üìù **Docs**:\n",
        "\n",
        "- `numpy.pad`: [numpy.org/doc/stable/reference/generated/numpy.pad.html](https://numpy.org/doc/stable/reference/generated/numpy.pad.html)\n",
        "- `cv2.copyMakeBorder`: [docs.opencv.org/master/d2/de8/group__core__array.html#ga2ac1049c2c3dd25c2b41bffe17658a36](https://docs.opencv.org/master/d2/de8/group__core__array.html#ga2ac1049c2c3dd25c2b41bffe17658a36)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_4_'></a>[Examples](#toc0_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_4_1_'></a>[Example 1: Apply Padding to Signals](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_1d = np.array([1, 3, 2, 1, 2], dtype=np.float32)\n",
        "signal_2d = np.array([[1, 2, 3], [2, 1, 1], [3, 1, 2]], dtype=np.float32)\n",
        "\n",
        "# log\n",
        "print(f\"signal_1d:\\n{signal_1d}\\n\")\n",
        "print(f\"signal_2d:\\n{signal_2d}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_4_1_1_'></a>[Using NumPy](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_1d_1 = np.pad(signal_1d, pad_width=(2, 2), mode=\"constant\", constant_values=0)\n",
        "signal_1d_2 = np.pad(signal_1d, pad_width=(2, 2), mode=\"reflect\")\n",
        "signal_1d_3 = np.pad(signal_1d, pad_width=(2, 2), mode=\"symmetric\")\n",
        "signal_1d_4 = np.pad(signal_1d, pad_width=(2, 2), mode=\"wrap\")\n",
        "signal_1d_5 = np.pad(signal_1d, pad_width=(2, 2), mode=\"edge\")\n",
        "\n",
        "# plot\n",
        "padded_signals = [signal_1d_1, signal_1d_2, signal_1d_3, signal_1d_4, signal_1d_5]\n",
        "titles = [\"Constant\", \"Reflect\", \"Symmetric\", \"Wrap\", \"Edge\"]\n",
        "fig, axes = plt.subplots(5, 1, figsize=(5, 5), layout=\"compressed\")\n",
        "for ax, signal, title in zip(axes, padded_signals, titles):\n",
        "    ax.imshow(np.expand_dims(signal, axis=0), cmap=\"gray\", vmin=0, vmax=3, aspect=\"auto\")\n",
        "    ax.set(title=title, xticks=range(signal.shape[0]), yticks=[])\n",
        "    rect = plt.Rectangle((1.5, -0.5), 5, 1, edgecolor=\"red\", linewidth=3, fill=False)\n",
        "    ax.add_patch(rect)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_4_1_2_'></a>[Using OpenCV](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_2d_1 = cv2.copyMakeBorder(signal_2d, 2, 2, 2, 2, cv2.BORDER_CONSTANT, value=0)\n",
        "signal_2d_2 = cv2.copyMakeBorder(signal_2d, 2, 2, 2, 2, cv2.BORDER_REFLECT)\n",
        "signal_2d_3 = cv2.copyMakeBorder(signal_2d, 2, 2, 2, 2, cv2.BORDER_REFLECT_101)\n",
        "signal_2d_4 = cv2.copyMakeBorder(signal_2d, 2, 2, 2, 2, cv2.BORDER_WRAP)\n",
        "signal_2d_5 = cv2.copyMakeBorder(signal_2d, 2, 2, 2, 2, cv2.BORDER_REPLICATE)\n",
        "\n",
        "# plot\n",
        "padded_images = [signal_2d_1, signal_2d_2, signal_2d_3, signal_2d_4, signal_2d_5]\n",
        "titles = [\"Constant\", \"Reflect\", \"Symmetric\", \"Wrap\", \"Replicate\"]\n",
        "fig, axes = plt.subplots(1, 5, figsize=(15, 5), layout=\"compressed\")\n",
        "for ax, img, title in zip(axes, padded_images, titles):\n",
        "    ax.imshow(img, cmap=\"gray\", vmin=0, vmax=3)\n",
        "    ax.set(title=title, xticks=range(img.shape[1]), yticks=range(img.shape[0]))\n",
        "    rect = plt.Rectangle((1.5, 1.5), 3, 3, edgecolor=\"red\", linewidth=3, fill=False)\n",
        "    ax.add_patch(rect)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_4_2_'></a>[Example 2: 1D Convolution](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_1d = np.array([0, 1, 2, 3, 4, 5, 4, 3, 2, 1, 0], dtype=np.float32)\n",
        "filter_1d = np.array([1, 0, -1], dtype=np.float32)\n",
        "\n",
        "# log\n",
        "print(f\"signal_1d:\\n{signal_1d}\\n\")\n",
        "print(f\"filter_1d:\\n{filter_1d}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_4_2_1_'></a>[Manual](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def conv1d(signal: NDArray, kernel: NDArray) -> NDArray:\n",
        "    signal_len = len(signal)\n",
        "    kernel_len = len(kernel)\n",
        "    output_len = signal_len + kernel_len - 1  # full convolution length\n",
        "\n",
        "    kernel = kernel[::-1]\n",
        "    padded_signal = np.pad(signal, (kernel_len - 1, kernel_len - 1), mode=\"constant\")\n",
        "    result = np.array([np.sum(padded_signal[i : i + kernel_len] * kernel) for i in range(output_len)])\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_1d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_1d_conv_1 = conv1d(signal_1d, filter_1d)\n",
        "\n",
        "# plot\n",
        "titles = [\"Input\", \"Filter\", \"Full\"]\n",
        "signals = [signal_1d, filter_1d, signal_1d_conv_1]\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 3), layout=\"compressed\", sharex=True, sharey=True)\n",
        "for col, (ax, title, data) in enumerate(zip(axes, titles, signals)):\n",
        "    ax.stem(data, basefmt=\" \")\n",
        "    ax.set_title(title)\n",
        "    ax.grid(True, linewidth=0.5, linestyle=\"--\", color=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_4_2_2_'></a>[Using NumPy](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_1d_conv_2 = np.convolve(signal_1d, filter_1d, mode=\"valid\")\n",
        "signal_1d_conv_3 = np.convolve(signal_1d, filter_1d, mode=\"same\")\n",
        "signal_1d_conv_4 = np.convolve(signal_1d, filter_1d, mode=\"full\")\n",
        "\n",
        "# plot\n",
        "titles = [\"Input\", \"Filter\", \"Valid\", \"Same\", \"Full\"]\n",
        "signals = [signal_1d, filter_1d, signal_1d_conv_2, signal_1d_conv_3, signal_1d_conv_4]\n",
        "fig, axes = plt.subplots(1, 5, figsize=(24, 3), layout=\"compressed\", sharex=True, sharey=True)\n",
        "for col, (ax, title, data) in enumerate(zip(axes, titles, signals)):\n",
        "    ax.stem(data, basefmt=\" \")\n",
        "    ax.set_title(title)\n",
        "    ax.grid(True, linewidth=0.5, linestyle=\"--\", color=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_4_2_3_'></a>[Using SciPy](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_1d_conv_5 = sp.signal.convolve(signal_1d, filter_1d, mode=\"valid\")\n",
        "signal_1d_conv_6 = sp.signal.convolve(signal_1d, filter_1d, mode=\"same\")\n",
        "signal_1d_conv_7 = sp.signal.convolve(signal_1d, filter_1d, mode=\"full\")\n",
        "\n",
        "# plot\n",
        "titles = [\"Input\", \"Filter\", \"Valid\", \"Same\", \"Full\"]\n",
        "signals = [signal_1d, filter_1d, signal_1d_conv_5, signal_1d_conv_6, signal_1d_conv_7]\n",
        "fig, axes = plt.subplots(1, 5, figsize=(20, 3), layout=\"compressed\", sharex=True, sharey=True)\n",
        "for col, (ax, title, data) in enumerate(zip(axes, titles, signals)):\n",
        "    ax.stem(data, basefmt=\" \")\n",
        "    ax.set_title(title)\n",
        "    ax.grid(True, linewidth=0.5, linestyle=\"--\", color=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_4_3_'></a>[Example 3: 2D Convolution](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_2d = np.array([[1, 2, 3], [2, 1, 1], [3, 1, 2]], dtype=np.float32)\n",
        "filter_2d = np.array([[3, 1, 2], [1, 2, 1], [3, 1, 1]], dtype=np.float32)\n",
        "\n",
        "# log\n",
        "print(f\"signal_2d:\\n{signal_2d}\\n\")\n",
        "print(f\"filter_2d:\\n{filter_2d}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_4_3_1_'></a>[Manual](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def conv2d(image: NDArray, kernel: NDArray) -> NDArray:\n",
        "    image_h, image_w = image.shape\n",
        "    kernel_h, kernel_w = kernel.shape\n",
        "    output_h = image_h + kernel_h - 1  # full convolution height\n",
        "    output_w = image_w + kernel_w - 1  # full convolution width\n",
        "    kernel = np.flipud(np.fliplr(kernel))\n",
        "\n",
        "    # pad the image with zeros\n",
        "    pad_h, pad_w = kernel_h - 1, kernel_w - 1\n",
        "    padded_image = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), mode=\"constant\", constant_values=0)\n",
        "\n",
        "    # compute convolution\n",
        "    result = np.zeros((output_h, output_w))\n",
        "    for i in range(output_h):\n",
        "        for j in range(output_w):\n",
        "            result[i, j] = np.sum(padded_image[i : i + kernel_h, j : j + kernel_w] * kernel)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_2d_conv_1 = conv2d(signal_2d, filter_2d)\n",
        "\n",
        "# plot\n",
        "signals = [signal_2d, filter_2d, signal_2d_conv_1]\n",
        "titles = [\"signal_2d\", \"filter_2d\", \"signal_2d_conv_1\"]\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3), layout=\"compressed\")\n",
        "for ax, signal, title in zip(axes, signals, titles):\n",
        "    ax.imshow(signal, cmap=\"gray\")\n",
        "    ax.set(title=title, xticks=range(signal.shape[1]), yticks=range(signal.shape[0]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_4_3_2_'></a>[Using OpenCV](#toc0_)\n",
        "\n",
        "- It performs convolution operations using the **same** mode by default.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kernel_h, kernel_w = filter_2d.shape\n",
        "pad_h, pad_w = kernel_h - 1 - 1, kernel_w - 1 - 1\n",
        "signal_2d_padded = cv2.copyMakeBorder(signal_2d, pad_h, pad_h, pad_w, pad_w, borderType=cv2.BORDER_CONSTANT, value=0)\n",
        "filter_2d_flip = np.flipud(np.fliplr(filter_2d))\n",
        "signal_2d_conv_2 = cv2.filter2D(signal_2d_padded, ddepth=-1, kernel=filter_2d_flip, borderType=cv2.BORDER_CONSTANT)\n",
        "\n",
        "# plot\n",
        "signals = [signal_2d, filter_2d, signal_2d_conv_2]\n",
        "titles = [\"signal_2d\", \"filter_2d\", \"signal_2d_conv_2\"]\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3), layout=\"compressed\")\n",
        "for ax, signal, title in zip(axes, signals, titles):\n",
        "    ax.imshow(signal, cmap=\"gray\")\n",
        "    ax.set(title=title, xticks=range(signal.shape[1]), yticks=range(signal.shape[0]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_4_3_3_'></a>[Using SciPy](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_2d_conv_3 = sp.signal.convolve2d(signal_2d, filter_2d, mode=\"full\", boundary=\"fill\", fillvalue=0)\n",
        "\n",
        "# plot\n",
        "signals = [signal_2d, filter_2d, signal_2d_conv_3]\n",
        "titles = [\"signal_2d\", \"filter_2d\", \"signal_2d_conv_3\"]\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3), layout=\"compressed\")\n",
        "for ax, signal, title in zip(axes, signals, titles):\n",
        "    ax.imshow(signal, cmap=\"gray\")\n",
        "    ax.set(title=title, xticks=range(signal.shape[1]), yticks=range(signal.shape[0]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_4_4_'></a>[Example 4: Separable Convolution](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_2d = np.array([[1, 2, 3], [2, 1, 1], [3, 1, 2]], dtype=np.float32)\n",
        "filter_2d = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32)\n",
        "\n",
        "# log\n",
        "print(f\"signal_2d:\\n{signal_2d}\\n\")\n",
        "print(f\"filter_2d:\\n{filter_2d}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_4_4_1_'></a>[Manual](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def separate_kernel(kernel: NDArray) -> tuple[np.ndarray, np.ndarray] | None:\n",
        "    U, S, Vt = np.linalg.svd(kernel)\n",
        "    S = np.sqrt(S[0])\n",
        "    k_c = U[:, 0] * S\n",
        "    k_r = Vt[0, :] * S\n",
        "\n",
        "    reconstructed_kernel = np.outer(k_c, k_r)\n",
        "    if not np.allclose(kernel, reconstructed_kernel, atol=1e-6):\n",
        "        return None\n",
        "\n",
        "    return k_r, k_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def conv2d_separable(image: NDArray, k_r: NDArray, k_c: NDArray) -> NDArray:\n",
        "    image_h, image_w = image.shape\n",
        "    k_r = np.flip(k_r)\n",
        "    k_c = np.flip(k_c)\n",
        "    pad_r = len(k_r) - 1\n",
        "    pad_c = len(k_c) - 1\n",
        "\n",
        "    padded_image = np.pad(image, ((0, 0), (pad_r, pad_r)), mode=\"constant\", constant_values=0)\n",
        "    intermediate = np.zeros((image_h, image_w + pad_r))\n",
        "    for i in range(image_h):\n",
        "        for j in range(image_w + pad_r):\n",
        "            intermediate[i, j] = np.sum(padded_image[i, j : j + len(k_r)] * k_r)\n",
        "\n",
        "    padded_intermediate = np.pad(intermediate, ((pad_c, pad_c), (0, 0)), mode=\"constant\", constant_values=0)\n",
        "    output_h, output_w = image_h + pad_c, image_w + pad_r\n",
        "    output = np.zeros((output_h, output_w))\n",
        "    for i in range(output_h):\n",
        "        for j in range(output_w):\n",
        "            output[i, j] = np.sum(padded_intermediate[i : i + len(k_c), j] * k_c)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "k_r, k_c = separate_kernel(filter_2d)\n",
        "signal_2d_conv_4 = conv2d(signal_2d, filter_2d)\n",
        "signal_2d_conv_5 = conv2d_separable(signal_2d, k_r, k_c)\n",
        "\n",
        "# log\n",
        "print(f\"k_r                : {k_r}\")\n",
        "print(f\"k_c                : {k_c}\")\n",
        "print(f\"np.outer(k_c, k_r) :\\n{np.outer(k_c, k_r)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot\n",
        "signals = [signal_2d, signal_2d_conv_4, signal_2d_conv_5]\n",
        "titles = [\"signal_2d\", \"2D Convolution\", \"Separable Convolution\"]\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3), layout=\"compressed\")\n",
        "for ax, signal, title in zip(axes, signals, titles):\n",
        "    ax.imshow(signal, cmap=\"gray\")\n",
        "    ax.set(title=title, xticks=range(signal.shape[1]), yticks=range(signal.shape[0]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_4_5_'></a>[Example 5: 2D Cross-Correlation](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_2d = np.array([[1, 2, 3], [2, 1, 1], [3, 1, 2]], dtype=np.float32)\n",
        "filter_2d = np.array([[3, 1, 2], [1, 2, 1], [3, 1, 1]], dtype=np.float32)\n",
        "\n",
        "# log\n",
        "print(f\"signal_2d:\\n{signal_2d}\\n\")\n",
        "print(f\"filter_2d:\\n{filter_2d}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_4_5_1_'></a>[Using SciPy](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_2d_corr_1 = sp.signal.correlate2d(signal_2d, filter_2d, mode=\"full\", boundary=\"fill\", fillvalue=0)\n",
        "\n",
        "# plot\n",
        "signals = [signal_2d, filter_2d, signal_2d_corr_1]\n",
        "titles = [\"signal_2d\", \"filter_2d\", \"signal_2d_corr_1\"]\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3), layout=\"compressed\")\n",
        "for ax, signal, title in zip(axes, signals, titles):\n",
        "    ax.imshow(signal, cmap=\"gray\")\n",
        "    ax.set(title=title, xticks=range(signal.shape[1]), yticks=range(signal.shape[0]))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "author_email": "AmirhosseinHeydari78@gmail.com",
    "author_github": "https://github.com/mr-pylin",
    "author_name": "Amirhossein Heydari",
    "kernelspec": {
      "display_name": "media-processing-workshop-sxUc00b2-py3.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "origin_repo": "https://github.com/mr-pylin/media-processing-workshop"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
