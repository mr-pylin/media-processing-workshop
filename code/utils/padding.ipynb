{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
    "    <div style=\"text-align: left; flex: 4;\">\n",
    "        <strong>Author:</strong> Amirhossein Heydari ‚Äî \n",
    "        üìß <a href=\"mailto:amirhosseinheydari78@gmail.com\">amirhosseinheydari78@gmail.com</a> ‚Äî \n",
    "        üêô <a href=\"https://github.com/mr-pylin/media-processing-workshop\" target=\"_blank\" rel=\"noopener\">github.com/mr-pylin</a>\n",
    "    </div>\n",
    "    <div style=\"display: flex; justify-content: flex-end; flex: 1; gap: 8px; align-items: center; padding: 0;\">\n",
    "        <a href=\"https://opencv.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../../assets/images/libraries/opencv/logo/OpenCV_logo_no_text-1.svg\"\n",
    "                 alt=\"OpenCV Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "        <a href=\"https://pillow.readthedocs.io/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../../assets/images/libraries/pillow/logo/pillow-logo-248x250.png\"\n",
    "                 alt=\"PIL Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "        <a href=\"https://scikit-image.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../../assets/images/libraries/scikit-image/logo/logo.png\"\n",
    "                 alt=\"scikit-image Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "        <a href=\"https://scipy.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../../assets/images/libraries/scipy/logo/logo.svg\"\n",
    "                 alt=\"SciPy Logo\"\n",
    "                 style=\"max-height: 48px; width: auto;\">\n",
    "        </a>\n",
    "    </div>\n",
    "</div>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Dependencies](#toc1_)    \n",
    "- [Load Images](#toc2_)    \n",
    "- [Padding](#toc3_)    \n",
    "  - [Introduction](#toc3_1_)    \n",
    "  - [Padding Strategies](#toc3_2_)    \n",
    "  - [Padding Modes](#toc3_3_)    \n",
    "  - [Applications](#toc3_4_)    \n",
    "  - [Implementation](#toc3_5_)    \n",
    "    - [Manual](#toc3_5_1_)    \n",
    "    - [Using NumPy](#toc3_5_2_)    \n",
    "    - [Using OpenCV](#toc3_5_3_)    \n",
    "  - [Visualization](#toc3_6_)    \n",
    "    - [Random 1D Signal](#toc3_6_1_)    \n",
    "    - [Random 2D Signal](#toc3_6_2_)    \n",
    "    - [Grayscale (2D) Image](#toc3_6_3_)    \n",
    "    - [RGB (3D) Image](#toc3_6_4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Dependencies](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from numpy.typing import NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Load Images](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_1 = cv2.imread(\"../../assets/images/dip_3rd/CH02_Fig0222(b)(cameraman).tif\", cv2.IMREAD_GRAYSCALE)\n",
    "im_2 = cv2.imread(\"../../assets/images/dip_3rd/CH06_Fig0638(a)(lenna_RGB).tif\", cv2.IMREAD_COLOR_RGB)\n",
    "\n",
    "# plot\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 4), layout=\"compressed\")\n",
    "axs[0].imshow(im_1, vmin=0, vmax=255, cmap=\"gray\")\n",
    "axs[0].set_title(\"CH02_Fig0222(b)(cameraman).tif\")\n",
    "axs[1].imshow(im_2, vmin=0, vmax=255)\n",
    "axs[1].set_title(\"CH06_Fig0638(a)(lenna_RGB).tif\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Padding](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[Introduction](#toc0_)\n",
    "\n",
    "- Padding refers to the process of adding extra data (often around the borders of a signal) to expand its size before further processing.  \n",
    "- In the context of image processing, this usually means adding rows and columns of pixels around the original image.\n",
    "\n",
    "<figure style=\"text-align:center; margin:0;\">\n",
    "  <img src=\"../../assets/images/original/vector/lti/padding-2d.svg\" alt=\"padding-2d.svg\" style=\"max-width:80%; height:auto;\">\n",
    "</figure>\n",
    "\n",
    "üìà **Use Cases of Padding**:\n",
    "\n",
    "- **Preserving spatial dimensions:**  \n",
    "  In convolution and filtering, padding can help keep the output size the same as the input size.\n",
    "\n",
    "- **Improving edge handling:**  \n",
    "  Many algorithms (e.g., convolution, interpolation, morphological operations) require data beyond the borders.  \n",
    "  Padding provides a way to simulate or extend this data.\n",
    "\n",
    "- **Reducing information loss:**  \n",
    "  Without padding, pixels near the edges may not be processed with the same context as central pixels.\n",
    "\n",
    "- **Optimizing algorithms:**  \n",
    "  In frequency-domain processing (e.g., FFT), padding to certain sizes can improve computational efficiency.\n",
    "\n",
    "- **Alignment for neural networks:**  \n",
    "  Some architectures require inputs of specific sizes; padding can ensure compatibility.\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- `numpy.pad`: [numpy.org/doc/stable/reference/generated/numpy.pad.html](https://numpy.org/doc/stable/reference/generated/numpy.pad.html)\n",
    "- `cv2.copyMakeBorder`: [docs.opencv.org/master/d2/de8/group__core__array.html#ga2ac1049c2c3dd25c2b41bffe17658a36](https://docs.opencv.org/master/d2/de8/group__core__array.html#ga2ac1049c2c3dd25c2b41bffe17658a36)\n",
    "- `BorderTypes` **[OpenCV]**: [docs.opencv.org/master/d2/de8/group__core__array.html#ga209f2f4869e304c82d07739337eae7c5](https://docs.opencv.org/master/d2/de8/group__core__array.html#ga209f2f4869e304c82d07739337eae7c5)\n",
    "- `scipy.ndimage.convolve`: [docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[Padding Strategies](#toc0_)\n",
    "\n",
    "- Padding strategy defines **how much** we extend the input data before processing.  \n",
    "- In many algorithms ‚Äî especially convolution and filtering ‚Äî the amount of padding determines the **output size** and how edges are treated.\n",
    "\n",
    "üìà **Common Padding Strategies:**\n",
    "\n",
    "1. **`valid` Padding (No Padding):**  \n",
    "   - No extra pixels/values are added around the input.\n",
    "   - The operation is applied only where the kernel fits entirely inside the data.  \n",
    "   - **Effect:**  \n",
    "     - Output size is smaller than input.  \n",
    "     - Edges lose information because the kernel cannot go beyond the original boundary.  \n",
    "   - **Example:**  \n",
    "     - Input: $5 \\times 5$ , Kernel: $3 \\times 3$ $\\quad \\rightarrow \\quad$ Output: $3 \\times 3$ \n",
    "\n",
    "1. **`same` Padding:**  \n",
    "   - Padding is chosen so that the output size is the **same** as the input size (for stride $= 1$).  \n",
    "   - **Effect:**  \n",
    "     - All input pixels, including edges, are processed with equal kernel context.  \n",
    "     - Common in deep learning to preserve feature map resolution.  \n",
    "   - **Formula:**  \n",
    "      $$p = \\frac{k - 1}{2} \\quad \\text{for odd kernel size, stride = 1}$$\n",
    "      where $p$ is padding on each side, $k$ is kernel size.  \n",
    "   - **Example:**  \n",
    "     - Input: $5 \\times 5$, Kernel: $3 \\times 3$, Stride: $1$ $\\quad \\rightarrow \\quad p = 1 \\quad \\rightarrow \\quad$ Padded Input: $7 \\times 7$ $\\quad \\rightarrow \\quad$ Output: $5 \\times 5$\n",
    "\n",
    "1. **`full` Padding:**  \n",
    "   - Padding is applied so the kernel can be centered on every possible position, including where it extends completely outside the original data.  \n",
    "   - **Effect:**  \n",
    "     - Output is **larger** than the input.  \n",
    "     - Often used in correlation operations or to capture all possible partial overlaps.  \n",
    "   - **Formula:**  \n",
    "     $$ p = k - 1 $$\n",
    "     where $p$ is the padding on each side and $k$ is the kernel size.\n",
    "   - **Example:**  \n",
    "     - Input: $5 \\times 5$, Kernel: $3 \\times 3$ $\\quad \\rightarrow \\quad p = 2 \\quad \\rightarrow \\quad$ Padded Input: $9 \\times 9$ $\\quad \\rightarrow \\quad$ Output: $7 \\times 7$\n",
    "\n",
    "‚úçÔ∏è **General Output Size Formula**\n",
    "\n",
    "$$\n",
    "O = \\left\\lfloor \\frac{I + 2p - k - (k-1)(d-1)}{s} \\right\\rfloor + 1\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- $O$ = output size (height or width)  \n",
    "- $I$ = input size (height or width)  \n",
    "- $k$ = kernel size  \n",
    "- $p$ = padding on each side  \n",
    "- $s$ = stride  \n",
    "- $d$ = dilation factor (default $d=1$ if not used)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_3_'></a>[Padding Modes](#toc0_)\n",
    "\n",
    "- **Padding mode** defines **how the values are filled** in the padded region around the input.  \n",
    "- Choosing the right mode affects the edges and can influence the results of filtering, convolution, or other operations.  \n",
    "\n",
    "üìà **Common Padding Modes:**  \n",
    "\n",
    "1. **Zero Padding (constant 0):**  \n",
    "   - Padded values are filled with **0**.  \n",
    "   - Often used in CNNs and basic convolution.  \n",
    "   - **Effect:** May introduce artificial black borders around the image.  \n",
    "   - **Example:** `[1 2 3 4 5]` ‚Üí Padded: `[0 0 0 | 1 2 3 4 5 | 0 0 0]`\n",
    "\n",
    "1. **Constant Padding (custom value):**  \n",
    "   - Padded values are filled with a **specific constant** $c$ (not necessarily 0).  \n",
    "   - Useful when you want a uniform border of a given intensity.  \n",
    "   - **Example**: `[1 2 3 4 5]` ‚Üí Padded: `[9 9 9 | 1 2 3 4 5 | 9 9 9]`  \n",
    "\n",
    "1. **Reflect Padding:**  \n",
    "   - Padded values **mirror the input values** without repeating the edge pixel.  \n",
    "   - **Example**: `[1 2 3 4 5]` ‚Üí Padded: `[4 3 2 | 1 2 3 4 5 | 4 3 2]`  \n",
    "\n",
    "1. **Replicate / Edge Padding:**  \n",
    "   - The edge pixels of the input are **replicated** into the padding region.  \n",
    "   - **Example**: `[1 2 3 4 5]` ‚Üí Padded: `[1 1 1 | 1 2 3 4 5 | 5 5 5]`  \n",
    "\n",
    "1. **Circular / Wrap Padding:**  \n",
    "   - Padding is filled by **wrapping around the input** (treats input as circular).  \n",
    "   - **Example**: `[1 2 3 4 5]` ‚Üí Padded: `[3 4 5 | 1 2 3 4 5 | 1 2 3]`  \n",
    "\n",
    "1. **Symmetric Padding:**  \n",
    "   - Like reflect, but **includes the edge pixel** in the mirror.  \n",
    "   - **Example**: `[1 2 3 4 5]` ‚Üí Padded: `[3 2 1 | 1 2 3 4 5 | 5 4 3]`  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_4_'></a>[Applications](#toc0_)\n",
    "\n",
    "- **Padding** is widely used in digital image processing and related fields to handle boundaries, maintain spatial dimensions, and improve algorithm performance.  \n",
    "\n",
    "üìå **Common Applications:**  \n",
    "\n",
    "1. **Convolution / Filtering:**  \n",
    "   - Ensures kernels can be applied to **all pixels**, including edges.  \n",
    "   - Helps maintain **output size** (e.g., `same` padding in CNNs).  \n",
    "   - More details about spatial filtering: [**spatial-filtering**](../07-spatial-filtering.ipynb) notebook.\n",
    "\n",
    "1. **Morphological Operations:**  \n",
    "   - Dilation, erosion, opening, and closing require padding to process edge pixels correctly.  \n",
    "   - More details about morphology: [**morphological-processing**](../11-morphological-processing.ipynb) notebook.\n",
    "\n",
    "1. **Fourier / Frequency Domain Processing:**  \n",
    "   - Padding can reduce **circular artifacts** when performing FFT-based convolution.  \n",
    "   - More details about frequency filtering: [**frequency-filtering**](../08-frequency-filtering.ipynb) notebook.\n",
    "\n",
    "1. **Image Resizing / Alignment:**  \n",
    "   - Adding padding can maintain **aspect ratio** or align images to a desired size.  \n",
    "\n",
    "1. **Data Augmentation:**  \n",
    "   - Padding allows **random crops**, translations, and rotations without losing information at edges.  \n",
    "\n",
    "1. **Deep Learning / CNNs:**  \n",
    "   - Preserves **feature map dimensions** across layers.  \n",
    "   - Helps maintain **spatial context** for edge pixels.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_5_'></a>[Implementation](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_1d = rng.integers(0, 10, size=5)\n",
    "array_2d = rng.integers(0, 10, size=(3, 4))\n",
    "\n",
    "# log\n",
    "print(f\"array_1d:\\n{array_1d}\\n\")\n",
    "print(f\"array_2d:\\n{array_2d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_5_1_'></a>[Manual](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_pad(array: NDArray, pad_width: int, value: int = 0) -> NDArray:\n",
    "\n",
    "    if array.ndim == 1:\n",
    "        padded_arr = np.full(array.shape[0] + 2 * pad_width, value, dtype=array.dtype)\n",
    "        padded_arr[pad_width : pad_width + array.shape[0]] = array\n",
    "        return padded_arr\n",
    "\n",
    "    elif array.ndim == 2:\n",
    "        padded_arr = np.full((array.shape[0] + 2 * pad_width, array.shape[1] + 2 * pad_width), value, dtype=array.dtype)\n",
    "        padded_arr[pad_width : pad_width + array.shape[0], pad_width : pad_width + array.shape[1]] = array\n",
    "        return padded_arr\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Only 1D or 2D arrays are supported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_1d_pad = constant_pad(array_1d, pad_width=2)\n",
    "array_2d_pad = constant_pad(array_2d, pad_width=1, value=8)\n",
    "\n",
    "# log\n",
    "print(f\"array_1d_pad:\\n{array_1d_pad}\\n\")\n",
    "print(f\"array_2d_pad:\\n{array_2d_pad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_5_2_'></a>[Using NumPy](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_1d = rng.integers(0, 10, size=5)\n",
    "array_1d_pad = np.pad(array_1d, pad_width=2, mode=\"constant\", constant_values=0)\n",
    "\n",
    "# log\n",
    "print(f\"array_1d     : {array_1d}\")\n",
    "print(f\"array_1d_pad : {array_1d_pad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2d = rng.integers(0, 10, size=(3, 3))\n",
    "array_2d_pad = np.pad(array_2d, pad_width=((1, 1), (2, 2)), mode=\"symmetric\")\n",
    "\n",
    "# log\n",
    "print(f\"array_2d:\\n{array_2d}\\n\")\n",
    "print(f\"array_2d_pad:\\n{array_2d_pad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2d = rng.integers(0, 10, size=(3, 3))\n",
    "array_2d_pad = np.pad(array_2d, pad_width=((1, 1), (2, 2)), mode=\"reflect\")\n",
    "\n",
    "# log\n",
    "print(f\"array_2d:\\n{array_2d}\\n\")\n",
    "print(f\"array_2d_pad:\\n{array_2d_pad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_5_3_'></a>[Using OpenCV](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2d = rng.integers(0, 10, size=(3, 3)).astype(np.uint8)\n",
    "array_2d_pad = cv2.copyMakeBorder(array_2d, top=1, bottom=1, left=1, right=1, borderType=cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "# log\n",
    "print(f\"array_2d:\\n{array_2d}\\n\")\n",
    "print(f\"array_2d_pad:\\n{array_2d_pad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2d = rng.integers(0, 10, size=(3, 3)).astype(np.uint8)\n",
    "array_2d_pad = cv2.copyMakeBorder(array_2d, 1, 1, 2, 2, borderType=cv2.BORDER_REFLECT)\n",
    "\n",
    "# log\n",
    "print(f\"array_2d:\\n{array_2d}\\n\")\n",
    "print(f\"array_2d_pad:\\n{array_2d_pad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2d = rng.integers(0, 10, size=(3, 3)).astype(np.uint8)\n",
    "array_2d_pad = cv2.copyMakeBorder(array_2d, 2, 2, 2, 2, borderType=cv2.BORDER_REPLICATE)\n",
    "\n",
    "# log\n",
    "print(f\"array_2d:\\n{array_2d}\\n\")\n",
    "print(f\"array_2d_pad:\\n{array_2d_pad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_6_'></a>[Visualization](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_6_1_'></a>[Random 1D Signal](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_1d = rng.integers(0, 256, 5).astype(np.uint8)\n",
    "pad = 2\n",
    "\n",
    "# padding\n",
    "array_1d_pad_1 = np.pad(array_1d, pad_width=(pad, pad), mode=\"constant\", constant_values=0)\n",
    "array_1d_pad_2 = np.pad(array_1d, pad_width=(pad, pad), mode=\"reflect\")\n",
    "array_1d_pad_3 = np.pad(array_1d, pad_width=(pad, pad), mode=\"symmetric\")\n",
    "array_1d_pad_4 = np.pad(array_1d, pad_width=(pad, pad), mode=\"wrap\")\n",
    "array_1d_pad_5 = np.pad(array_1d, pad_width=(pad, pad), mode=\"edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "padded_signals = [array_1d_pad_1, array_1d_pad_2, array_1d_pad_3, array_1d_pad_4, array_1d_pad_5]\n",
    "titles = [\"Constant\", \"Reflect\", \"Symmetric\", \"Wrap\", \"Edge\"]\n",
    "fig, axes = plt.subplots(5, 1, figsize=(5, 5), layout=\"compressed\")\n",
    "for ax, signal, title in zip(axes, padded_signals, titles):\n",
    "    ax.imshow(np.expand_dims(signal, axis=0), cmap=\"gray\", vmin=0, vmax=255, aspect=\"auto\")\n",
    "    ax.set(title=title, xticks=range(signal.shape[0]), yticks=[])\n",
    "    rect = plt.Rectangle((pad - 0.5, -0.5), array_1d.shape[0], 1, edgecolor=\"red\", linewidth=3, fill=False)\n",
    "    ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_6_2_'></a>[Random 2D Signal](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2d = rng.integers(0, 256, (3, 3)).astype(np.uint8)\n",
    "pad = 2\n",
    "\n",
    "# padding\n",
    "array_2d_pad_1 = cv2.copyMakeBorder(array_2d, pad, pad, pad, pad, cv2.BORDER_CONSTANT, value=0)\n",
    "array_2d_pad_2 = cv2.copyMakeBorder(array_2d, pad, pad, pad, pad, cv2.BORDER_REFLECT)\n",
    "array_2d_pad_3 = cv2.copyMakeBorder(array_2d, pad, pad, pad, pad, cv2.BORDER_REFLECT_101)\n",
    "array_2d_pad_4 = cv2.copyMakeBorder(array_2d, pad, pad, pad, pad, cv2.BORDER_WRAP)\n",
    "array_2d_pad_5 = cv2.copyMakeBorder(array_2d, pad, pad, pad, pad, cv2.BORDER_REPLICATE)\n",
    "\n",
    "# plot\n",
    "padded_images = [array_2d_pad_1, array_2d_pad_2, array_2d_pad_3, array_2d_pad_4, array_2d_pad_5]\n",
    "titles = [\"Constant\", \"Reflect\", \"Symmetric\", \"Wrap\", \"Replicate\"]\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 5), layout=\"compressed\")\n",
    "for ax, img, title in zip(axes, padded_images, titles):\n",
    "    ax.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    ax.set(title=title, xticks=range(img.shape[1]), yticks=range(img.shape[0]))\n",
    "    rect = plt.Rectangle(\n",
    "        (pad - 0.5, pad - 0.5), array_2d.shape[1], array_2d.shape[0], edgecolor=\"red\", linewidth=2, fill=False\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_6_3_'></a>[Grayscale (2D) Image](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 50\n",
    "\n",
    "# padding\n",
    "im_1_pad_1 = cv2.copyMakeBorder(im_1, pad, pad, pad, pad, cv2.BORDER_CONSTANT, value=0)\n",
    "im_1_pad_2 = cv2.copyMakeBorder(im_1, pad, pad, pad, pad, cv2.BORDER_REFLECT)\n",
    "im_1_pad_3 = cv2.copyMakeBorder(im_1, pad, pad, pad, pad, cv2.BORDER_REFLECT_101)\n",
    "im_1_pad_4 = cv2.copyMakeBorder(im_1, pad, pad, pad, pad, cv2.BORDER_WRAP)\n",
    "im_1_pad_5 = cv2.copyMakeBorder(im_1, pad, pad, pad, pad, cv2.BORDER_REPLICATE)\n",
    "\n",
    "# plot\n",
    "padded_images = [im_1_pad_1, im_1_pad_2, im_1_pad_3, im_1_pad_4, im_1_pad_5]\n",
    "titles = [\"Constant\", \"Reflect\", \"Symmetric\", \"Wrap\", \"Replicate\"]\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 5), layout=\"compressed\")\n",
    "for ax, img, title in zip(axes, padded_images, titles):\n",
    "    ax.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    ax.set(title=title)\n",
    "    rect = plt.Rectangle(\n",
    "        (pad - 0.5, pad - 0.5), im_1.shape[1], im_1.shape[0], edgecolor=\"white\", linewidth=2, fill=False\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_6_4_'></a>[RGB (3D) Image](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 100\n",
    "\n",
    "# padding\n",
    "im_2_pad_1 = cv2.copyMakeBorder(im_2, pad, pad, pad, pad, cv2.BORDER_CONSTANT, value=0)\n",
    "im_2_pad_2 = cv2.copyMakeBorder(im_2, pad, pad, pad, pad, cv2.BORDER_REFLECT)\n",
    "im_2_pad_3 = cv2.copyMakeBorder(im_2, pad, pad, pad, pad, cv2.BORDER_REFLECT_101)\n",
    "im_2_pad_4 = cv2.copyMakeBorder(im_2, pad, pad, pad, pad, cv2.BORDER_WRAP)\n",
    "im_2_pad_5 = cv2.copyMakeBorder(im_2, pad, pad, pad, pad, cv2.BORDER_REPLICATE)\n",
    "\n",
    "# plot\n",
    "padded_images = [im_2_pad_1, im_2_pad_2, im_2_pad_3, im_2_pad_4, im_2_pad_5]\n",
    "titles = [\"Constant\", \"Reflect\", \"Symmetric\", \"Wrap\", \"Replicate\"]\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 5), layout=\"compressed\")\n",
    "for ax, img, title in zip(axes, padded_images, titles):\n",
    "    ax.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    ax.set(title=title)\n",
    "    rect = plt.Rectangle(\n",
    "        (pad - 0.5, pad - 0.5), im_2.shape[1], im_2.shape[0], edgecolor=\"white\", linewidth=2, fill=False\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "media-processing-workshop (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "origin_repo": "https://github.com/mr-pylin/media-processing-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
