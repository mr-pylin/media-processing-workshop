{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üìù **Author:** Amirhossein Heydari - üìß **Email:** <amirhosseinheydari78@gmail.com> - üìç **Origin:** [mr-pylin/media-processing-workshop](https://github.com/mr-pylin/media-processing-workshop)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Table of contents**<a id='toc0_'></a>    \n",
        "- [Dependencies](#toc1_)    \n",
        "- [Load Images](#toc2_)    \n",
        "- [Geometric Transformations](#toc3_)    \n",
        "  - [Rigid Transformations (Isometric)](#toc3_1_)    \n",
        "    - [Translation (Shifting)](#toc3_1_1_)    \n",
        "      - [Manual](#toc3_1_1_1_)    \n",
        "      - [Using OpenCV](#toc3_1_1_2_)    \n",
        "      - [Using PIL](#toc3_1_1_3_)    \n",
        "      - [Using scikit-image](#toc3_1_1_4_)    \n",
        "    - [Rotation](#toc3_1_2_)    \n",
        "      - [Using OpenCV](#toc3_1_2_1_)    \n",
        "      - [Using PIL](#toc3_1_2_2_)    \n",
        "    - [Reflection (Flipping)](#toc3_1_3_)    \n",
        "      - [Using OpenCV](#toc3_1_3_1_)    \n",
        "  - [Affine Transformations](#toc3_2_)    \n",
        "    - [Scaling](#toc3_2_1_)    \n",
        "      - [Using OpenCV](#toc3_2_1_1_)    \n",
        "    - [Shear](#toc3_2_2_)    \n",
        "      - [Using OpenCV](#toc3_2_2_1_)    \n",
        "  - [Projective Transformations (Homography)](#toc3_3_)    \n",
        "    - [Perspective](#toc3_3_1_)    \n",
        "      - [Using OpenCV](#toc3_3_1_1_)    \n",
        "\n",
        "<!-- vscode-jupyter-toc-config\n",
        "\tnumbering=false\n",
        "\tanchor=true\n",
        "\tflat=false\n",
        "\tminLevel=1\n",
        "\tmaxLevel=6\n",
        "\t/vscode-jupyter-toc-config -->\n",
        "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc1_'></a>[Dependencies](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import skimage as ski\n",
        "from numpy.typing import NDArray\n",
        "from PIL import Image, ImageChops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc2_'></a>[Load Images](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "im_1 = cv2.imread(\"../assets/images/dip_3rd/CH02_Fig0222(b)(cameraman).tif\", flags=cv2.IMREAD_GRAYSCALE)\n",
        "im_2 = cv2.cvtColor(\n",
        "    cv2.imread(\"../assets/images/dip_3rd/CH06_Fig0638(a)(lenna_RGB).tif\"),\n",
        "    cv2.COLOR_BGR2RGB,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_1 = Image.fromarray(im_1)\n",
        "img_2 = Image.fromarray(im_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(8, 4), layout=\"compressed\")\n",
        "axs[0].imshow(im_1, cmap=\"gray\")\n",
        "axs[0].set_title(\"CH02_Fig0222(b)(cameraman).tif\")\n",
        "axs[0].axis(\"off\")\n",
        "axs[1].imshow(im_2)\n",
        "axs[1].set_title(\"CH06_Fig0638(a)(lenna_RGB).tif\")\n",
        "axs[1].axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc3_'></a>[Geometric Transformations](#toc0_)\n",
        "\n",
        "- Geometric transformations **modify** the **spatial relationships of pixels** in an image.\n",
        "- They change an image‚Äôs **position**, **size**, or **shape** by mapping input coordinates to new locations.\n",
        "\n",
        "üÜö **Forward vs. Inverse Mapping:**\n",
        "\n",
        "To apply a geometric transformation, two methods exist:\n",
        "- **Forward Mapping**\n",
        "  - **Directly** maps each pixel from **input** to **output**.\n",
        "  - **Problem**: Some output pixels may not be assigned a value, causing holes.\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "x' \\\\ y' \\\\ 1\n",
        "\\end{bmatrix}\n",
        "= M \\cdot\n",
        "\\begin{bmatrix}\n",
        "x \\\\ y \\\\ 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "- **Inverse Mapping (Preferred)**\n",
        "  - Computes where each output pixel came from in the input image.\n",
        "  - Uses interpolation (**bilinear** or **bicubic**) to fill gaps.\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "x \\\\ y \\\\ 1\n",
        "\\end{bmatrix}\n",
        "= M^{-1} \\cdot\n",
        "\\begin{bmatrix}\n",
        "x' \\\\ y' \\\\ 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "üìù **Docs**:\n",
        "\n",
        "- Affine Transformations: [docs.opencv.org/master/d4/d61/tutorial_warp_affine.html](https://docs.opencv.org/master/d4/d61/tutorial_warp_affine.html)\n",
        "- `cv2.warpAffine`: [docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga0203d9ee5fcd28d40dbc4a1ea4451983](https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga0203d9ee5fcd28d40dbc4a1ea4451983)\n",
        "- `cv2.warpPerspective`: [docs.opencv.org/master/da/d54/group__imgproc__transform.html#gaf73673a7e8e18ec6963e3774e6a94b87](https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#gaf73673a7e8e18ec6963e3774e6a94b87)\n",
        "- `PIL.ImageChops.offset`: [pillow.readthedocs.io/en/stable/reference/ImageChops.html#PIL.ImageChops.offset](https://pillow.readthedocs.io/en/stable/reference/ImageChops.html#PIL.ImageChops.offset)\n",
        "- `PIL.Image.Image.transform`: [pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.transform](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.transform)\n",
        "- `skimage.transform.warp`: [scikit-image.org/docs/stable/api/skimage.transform.html#skimage.transform.warp](https://scikit-image.org/docs/stable/api/skimage.transform.html#skimage.transform.warp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_geometric_transform(image: NDArray, transform_matrix: NDArray) -> NDArray:\n",
        "\n",
        "    h, w = image.shape[:2]\n",
        "    is_color = len(image.shape) == 3\n",
        "    c = image.shape[2] if is_color else 1\n",
        "\n",
        "    inv_matrix = np.linalg.inv(transform_matrix)\n",
        "\n",
        "    # generate output pixel grid (x', y')\n",
        "    x_out, y_out = np.meshgrid(np.arange(w), np.arange(h))\n",
        "    ones = np.ones_like(x_out)\n",
        "    coords_out = np.stack([x_out, y_out, ones], axis=-1)  # (H, W, 3)\n",
        "\n",
        "    # compute input coordinates (x, y) via inverse transformation\n",
        "    coords_in = coords_out @ inv_matrix.T\n",
        "\n",
        "    # normalize\n",
        "    x_in = coords_in[..., 0] / coords_in[..., 2]\n",
        "    y_in = coords_in[..., 1] / coords_in[..., 2]\n",
        "\n",
        "    # initialize output image\n",
        "    transformed = np.zeros_like(image)\n",
        "\n",
        "    # round coordinates to nearest integer\n",
        "    x = np.round(x_in).astype(int)\n",
        "    y = np.round(y_in).astype(int)\n",
        "\n",
        "    # create valid pixel mask\n",
        "    mask = (x >= 0) & (x < w) & (y >= 0) & (y < h)\n",
        "\n",
        "    # assign pixels\n",
        "    if is_color:\n",
        "        for channel in range(c):\n",
        "            transformed[..., channel][mask] = image[y[mask], x[mask], channel]\n",
        "    else:\n",
        "        transformed[mask] = image[y[mask], x[mask]]\n",
        "\n",
        "    return transformed.astype(image.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_1_'></a>[Rigid Transformations (Isometric)](#toc0_)\n",
        "\n",
        "- They preserve the **Euclidean distance** (straight-line distances) and **angles** **between points** in an image.\n",
        "- They are called **rigid** because they **do not alter the shape or size** of objects, only their **position** and **orientation** in space.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_1_1_'></a>[Translation (Shifting)](#toc0_)\n",
        "\n",
        "- Moves every point in the image by a fixed amount $(t_x,t_y)$.\n",
        "- **Matrix Representation:**\n",
        "\n",
        "$$\n",
        "M = \\begin{bmatrix}\n",
        "1 & 0 & t_x \\\\\n",
        "0 & 1 & t_y \\\\\n",
        "0 & 0 & 1\n",
        "\\end{bmatrix}, \\quad\n",
        "M^{-1} = \\begin{bmatrix}\n",
        "1 & 0 & -t_x \\\\\n",
        "0 & 1 & -t_y \\\\\n",
        "0 & 0 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc3_1_1_1_'></a>[Manual](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "im_1_shift_1 = apply_geometric_transform(image=im_1, transform_matrix=np.array([[1, 0, 60], [0, 1, 0], [0, 0, 1]]))\n",
        "im_1_shift_2 = apply_geometric_transform(image=im_1, transform_matrix=np.array([[1, 0, 0], [0, 1, 60], [0, 0, 1]]))\n",
        "im_1_shift_3 = apply_geometric_transform(image=im_1, transform_matrix=np.array([[1, 0, 60], [0, 1, 60], [0, 0, 1]]))\n",
        "\n",
        "im_2_shift_1 = apply_geometric_transform(image=im_2, transform_matrix=np.array([[1, 0, 120], [0, 1, 0], [0, 0, 1]]))\n",
        "im_2_shift_2 = apply_geometric_transform(image=im_2, transform_matrix=np.array([[1, 0, 0], [0, 1, 120], [0, 0, 1]]))\n",
        "im_2_shift_3 = apply_geometric_transform(image=im_2, transform_matrix=np.array([[1, 0, 120], [0, 1, 120], [0, 0, 1]]))\n",
        "\n",
        "# plot\n",
        "fig, axs = plt.subplots(1, 6, figsize=(18, 4), layout=\"compressed\")\n",
        "images = [im_1_shift_1, im_1_shift_2, im_1_shift_3, im_2_shift_1, im_2_shift_2, im_2_shift_3]\n",
        "titles = [\"x:60\", \"y:60\", \"x:60, y:60 [bilinear]\", \"x:120\", \"y:120\", \"x:120, y:120 [bilinear]\"]\n",
        "cmaps = [\"gray\", \"gray\", \"gray\", None, None, None]\n",
        "for ax, img, cm, title in zip(axs, images, cmaps, titles):\n",
        "    ax.imshow(img, cmap=cm)\n",
        "    ax.set_title(title)\n",
        "    ax.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc3_1_1_2_'></a>[Using OpenCV](#toc0_)\n",
        "\n",
        "- OpenCV simplifies the $3 \\times 3$ mapping matrix $M$ by dropping the redundant third row ($[0, 0, 1]$)\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "x' \\\\ y'\n",
        "\\end{bmatrix}\n",
        "= M_{2 \\times 3} \\cdot\n",
        "\\begin{bmatrix}\n",
        "x \\\\ y \\\\ 1\n",
        "\\end{bmatrix}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "im_1_shift_4 = cv2.warpAffine(\n",
        "    im_1,\n",
        "    np.array([[1, 0, 60], [0, 1, 0]], dtype=np.float32),\n",
        "    dsize=(im_1.shape[1], im_1.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "\n",
        "im_1_shift_5 = cv2.warpAffine(\n",
        "    im_1,\n",
        "    np.array([[1, 0, 0], [0, 1, 60]], dtype=np.float32),\n",
        "    dsize=(im_1.shape[1], im_1.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "\n",
        "im_1_shift_6 = cv2.warpAffine(\n",
        "    im_1,\n",
        "    np.array([[1, 0, 60], [0, 1, 60]], dtype=np.float32),\n",
        "    dsize=(im_1.shape[1], im_1.shape[0]),\n",
        "    borderMode=cv2.BORDER_REPLICATE,\n",
        ")\n",
        "\n",
        "im_2_shift_4 = cv2.warpAffine(\n",
        "    im_2,\n",
        "    np.array([[1, 0, 120], [0, 1, 0]], dtype=np.float32),\n",
        "    dsize=(im_2.shape[1], im_2.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "\n",
        "im_2_shift_5 = cv2.warpAffine(\n",
        "    im_2,\n",
        "    np.array([[1, 0, 0], [0, 1, 120]], dtype=np.float32),\n",
        "    dsize=(im_2.shape[1], im_2.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "\n",
        "im_2_shift_6 = cv2.warpAffine(\n",
        "    im_2,\n",
        "    np.array([[1, 0, 120], [0, 1, 120]], dtype=np.float32),\n",
        "    dsize=(im_2.shape[1], im_2.shape[0]),\n",
        "    borderMode=cv2.BORDER_REPLICATE,\n",
        ")\n",
        "\n",
        "# plot\n",
        "fig, axs = plt.subplots(1, 6, figsize=(18, 4), layout=\"compressed\")\n",
        "images = [im_1_shift_4, im_1_shift_5, im_1_shift_6, im_2_shift_4, im_2_shift_5, im_2_shift_6]\n",
        "titles = [\"x:60\", \"y:60\", \"x:60, y:60 [bilinear]\", \"x:120\", \"y:120\", \"x:120, y:120 [bilinear]\"]\n",
        "cmaps = [\"gray\", \"gray\", \"gray\", None, None, None]\n",
        "for ax, img, cm, title in zip(axs, images, cmaps, titles):\n",
        "    ax.imshow(img, cmap=cm)\n",
        "    ax.set_title(title)\n",
        "    ax.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc3_1_1_3_'></a>[Using PIL](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# method 1\n",
        "im_1_shift_7 = ImageChops.offset(img_1, xoffset=60, yoffset=0)\n",
        "im_1_shift_8 = ImageChops.offset(img_1, xoffset=0, yoffset=60)\n",
        "im_1_shift_9 = ImageChops.offset(img_1, xoffset=60, yoffset=60)\n",
        "\n",
        "# method 2: more control over transformation\n",
        "im_2_shift_7 = img_2.transform(img_2.size, Image.Transform.AFFINE, (1, 0, -120, 0, 1, 0))\n",
        "im_2_shift_8 = img_2.transform(img_2.size, Image.Transform.AFFINE, (1, 0, 0, 0, 1, -120))\n",
        "im_2_shift_9 = img_2.transform(img_2.size, Image.Transform.AFFINE, (1, 0, -120, 0, 1, -120))\n",
        "\n",
        "# plot\n",
        "fig, axs = plt.subplots(1, 6, figsize=(18, 4), layout=\"compressed\")\n",
        "images = [im_1_shift_7, im_1_shift_8, im_1_shift_9, im_2_shift_7, im_2_shift_8, im_2_shift_9]\n",
        "titles = [\"x:60\", \"y:60\", \"x:60, y:60 [bilinear]\", \"x:120\", \"y:120\", \"x:120, y:120 [bilinear]\"]\n",
        "cmaps = [\"gray\", \"gray\", \"gray\", None, None, None]\n",
        "for ax, img, cm, title in zip(axs, images, cmaps, titles):\n",
        "    ax.imshow(img, cmap=cm)\n",
        "    ax.set_title(title)\n",
        "    ax.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc3_1_1_4_'></a>[Using scikit-image](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "im_1_shift_10 = ski.transform.warp(\n",
        "    im_1,\n",
        "    inverse_map=ski.transform.AffineTransform(translation=(60, 0)).inverse,\n",
        ")\n",
        "im_1_shift_11 = ski.transform.warp(\n",
        "    im_1,\n",
        "    inverse_map=ski.transform.AffineTransform(translation=(0, 60)).inverse,\n",
        ")\n",
        "im_1_shift_12 = ski.transform.warp(\n",
        "    im_1,\n",
        "    inverse_map=ski.transform.AffineTransform(translation=(60, 60)).inverse,\n",
        "    mode=\"edge\",\n",
        ")\n",
        "im_2_shift_10 = ski.transform.warp(\n",
        "    im_2,\n",
        "    inverse_map=ski.transform.AffineTransform(translation=(120, 0)).inverse,\n",
        ")\n",
        "im_2_shift_11 = ski.transform.warp(\n",
        "    im_2,\n",
        "    inverse_map=ski.transform.AffineTransform(translation=(0, 120)).inverse,\n",
        ")\n",
        "im_2_shift_12 = ski.transform.warp(\n",
        "    im_2,\n",
        "    inverse_map=ski.transform.AffineTransform(translation=(120, 120)).inverse,\n",
        "    mode=\"edge\",\n",
        ")\n",
        "\n",
        "# plot\n",
        "fig, axs = plt.subplots(1, 6, figsize=(18, 4), layout=\"compressed\")\n",
        "images = [im_1_shift_10, im_1_shift_11, im_1_shift_12, im_2_shift_10, im_2_shift_11, im_2_shift_12]\n",
        "titles = [\"x:60\", \"y:60\", \"x:60, y:60 [bilinear]\", \"x:120\", \"y:120\", \"x:120, y:120 [bilinear]\"]\n",
        "cmaps = [\"gray\", \"gray\", \"gray\", None, None, None]\n",
        "for ax, img, cm, title in zip(axs, images, cmaps, titles):\n",
        "    ax.imshow(img, cmap=cm)\n",
        "    ax.set_title(title)\n",
        "    ax.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_1_2_'></a>[Rotation](#toc0_)\n",
        "\n",
        "- Rotates points around a fixed center $(c_x,c_y)$ by an angle $\\theta$ (counterclockwise).\n",
        "- **Matrix Representation:**\n",
        "\n",
        "$$\n",
        "M = \\begin{bmatrix}\n",
        "\\cos\\theta & -\\sin\\theta & c_x(1-\\cos\\theta) + c_y\\sin\\theta \\\\\n",
        "\\sin\\theta & \\cos\\theta & c_y(1-\\cos\\theta) - c_x\\sin\\theta \\\\\n",
        "0 & 0 & 1\n",
        "\\end{bmatrix}, \\quad\n",
        "M^{-1} = \\begin{bmatrix}\n",
        "\\cos\\theta & \\sin\\theta & c_x(1-\\cos\\theta) - c_y\\sin\\theta \\\\\n",
        "-\\sin\\theta & \\cos\\theta & c_y(1-\\cos\\theta) + c_x\\sin\\theta \\\\\n",
        "0 & 0 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rotation_matrix(angle_deg: float, image_shape: tuple[int, ...]) -> NDArray[np.float32]:\n",
        "    h, w = image_shape[:2]\n",
        "    cx = (w - 1) / 2.0\n",
        "    cy = (h - 1) / 2.0\n",
        "    theta = np.radians(angle_deg)\n",
        "\n",
        "    cos_theta = np.cos(theta)\n",
        "    sin_theta = np.sin(theta)\n",
        "\n",
        "    tx = cx * (1 - cos_theta) + cy * sin_theta\n",
        "    ty = cy * (1 - cos_theta) - cx * sin_theta\n",
        "\n",
        "    return np.array([[cos_theta, -sin_theta, tx], [sin_theta, cos_theta, ty], [0, 0, 1]], dtype=np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc3_1_2_1_'></a>[Using OpenCV](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# method 1\n",
        "im_1_rotate_1 = cv2.warpAffine(\n",
        "    im_1,\n",
        "    rotation_matrix(45, im_1.shape)[:2],\n",
        "    dsize=(im_1.shape[1], im_1.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "im_1_rotate_2 = cv2.warpAffine(\n",
        "    im_1,\n",
        "    rotation_matrix(90, im_1.shape)[:2],\n",
        "    dsize=(im_1.shape[1], im_1.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "im_1_rotate_3 = cv2.warpAffine(\n",
        "    im_1,\n",
        "    rotation_matrix(257, im_1.shape)[:2],\n",
        "    dsize=(im_1.shape[1], im_1.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "\n",
        "# method 2\n",
        "im_1_rotate_4 = cv2.rotate(im_1, rotateCode=cv2.ROTATE_90_CLOCKWISE)\n",
        "im_1_rotate_5 = cv2.rotate(im_1, rotateCode=cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "im_1_rotate_6 = cv2.rotate(im_1, rotateCode=cv2.ROTATE_180)\n",
        "\n",
        "# plot\n",
        "fig, axs = plt.subplots(1, 6, figsize=(18, 4), layout=\"compressed\")\n",
        "images = [im_1_rotate_1, im_1_rotate_2, im_1_rotate_3, im_1_rotate_4, im_1_rotate_5, im_1_rotate_6]\n",
        "titles = [\"im_1_rotate_1\", \"im_1_rotate_2\", \"im_1_rotate_3\", \"im_1_rotate_4\", \"im_1_rotate_5\", \"im_1_rotate_6\"]\n",
        "for ax, img, title in zip(axs, images, titles):\n",
        "    ax.imshow(img, cmap=\"gray\")\n",
        "    ax.set_title(title)\n",
        "    ax.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc3_1_2_2_'></a>[Using PIL](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# method 1\n",
        "im_2_rotate_1 = img_2.transform(\n",
        "    img_2.size,\n",
        "    Image.Transform.AFFINE,\n",
        "    rotation_matrix(45, im_2.shape).ravel()[:6],\n",
        "    resample=Image.BILINEAR,\n",
        ")\n",
        "im_2_rotate_2 = img_2.transform(\n",
        "    img_2.size,\n",
        "    Image.Transform.AFFINE,\n",
        "    rotation_matrix(90, im_2.shape).ravel()[:6],\n",
        "    resample=Image.BILINEAR,\n",
        ")\n",
        "im_2_rotate_3 = img_2.transform(\n",
        "    img_2.size,\n",
        "    Image.Transform.AFFINE,\n",
        "    rotation_matrix(257, im_2.shape).ravel()[:6],\n",
        "    resample=Image.BILINEAR,\n",
        ")\n",
        "\n",
        "# method 2\n",
        "im_2_rotate_4 = img_2.rotate(45, resample=Image.BILINEAR, expand=True)\n",
        "im_2_rotate_5 = img_2.rotate(90, resample=Image.BILINEAR, expand=True)\n",
        "im_2_rotate_6 = img_2.rotate(257, resample=Image.BILINEAR, expand=True)\n",
        "\n",
        "# plot\n",
        "fig, axs = plt.subplots(1, 6, figsize=(18, 4), layout=\"compressed\")\n",
        "images = [im_2_rotate_1, im_2_rotate_2, im_2_rotate_3, im_2_rotate_4, im_2_rotate_5, im_2_rotate_6]\n",
        "titles = [\"im_2_rotate_1\", \"im_2_rotate_2\", \"im_2_rotate_3\", \"im_2_rotate_4\", \"im_2_rotate_5\", \"im_2_rotate_6\"]\n",
        "for ax, img, title in zip(axs, images, titles):\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(title)\n",
        "    ax.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_1_3_'></a>[Reflection (Flipping)](#toc0_)\n",
        "\n",
        "- Mirrors the image over an axis (e.g., vertical/horizontal flip).\n",
        "- **Matrix Representation:**\n",
        "  - To reflect around a vertical line at $x = c_x$:\n",
        "  $$\n",
        "  M = M^{-1} = \\begin{bmatrix}\n",
        "  -1 & 0 & 2c_x \\\\\n",
        "  0 & 1 & 0 \\\\\n",
        "  0 & 0 & 1\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "\n",
        "  - To reflect around a Horizontal line at $y = c_y$:\n",
        "  $$\n",
        "  M =  M^{-1} = \\begin{bmatrix}\n",
        "  1 & 0 & 0 \\\\\n",
        "  0 & -1 & 2c_y \\\\\n",
        "  0 & 0 & 1\n",
        "  \\end{bmatrix}\n",
        "  $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc3_1_3_1_'></a>[Using OpenCV](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "im_1_flip_1 = cv2.warpAffine(\n",
        "    im_1,\n",
        "    np.array([[-1, 0, im_1.shape[1]], [0, 1, 0]], dtype=np.float32),\n",
        "    dsize=(im_1.shape[1], im_1.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "\n",
        "im_1_flip_2 = cv2.warpAffine(\n",
        "    im_1,\n",
        "    np.array([[1, 0, 0], [0, -1, im_1.shape[0]]], dtype=np.float32),\n",
        "    dsize=(im_1.shape[1], im_1.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "\n",
        "im_1_flip_3 = cv2.warpAffine(\n",
        "    im_1,\n",
        "    np.array([[-1, 0, im_1.shape[1]], [0, -1, im_1.shape[0]]], dtype=np.float32),\n",
        "    dsize=(im_1.shape[1], im_1.shape[0]),\n",
        "    borderMode=cv2.BORDER_REPLICATE,\n",
        ")\n",
        "\n",
        "im_2_flip_1 = cv2.warpAffine(\n",
        "    im_2,\n",
        "    np.array([[-1, 0, im_2.shape[1]], [0, 1, 0]], dtype=np.float32),\n",
        "    dsize=(im_2.shape[1], im_2.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "\n",
        "im_2_flip_2 = cv2.warpAffine(\n",
        "    im_2,\n",
        "    np.array([[1, 0, 0], [0, -1, im_2.shape[0]]], dtype=np.float32),\n",
        "    dsize=(im_2.shape[1], im_2.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "\n",
        "im_2_flip_3 = cv2.warpAffine(\n",
        "    im_2,\n",
        "    np.array([[-1, 0, im_2.shape[1]], [0, -1, im_2.shape[0]]], dtype=np.float32),\n",
        "    dsize=(im_2.shape[1], im_2.shape[0]),\n",
        "    borderMode=cv2.BORDER_REPLICATE,\n",
        ")\n",
        "\n",
        "# plot\n",
        "fig, axs = plt.subplots(1, 6, figsize=(18, 4), layout=\"compressed\")\n",
        "images = [im_1_flip_1, im_1_flip_2, im_1_flip_3, im_2_flip_1, im_2_flip_2, im_2_flip_3]\n",
        "titles = [\"im_1_flip_1\", \"im_1_flip_2\", \"im_1_flip_3\", \"im_2_flip_1\", \"im_2_flip_2\", \"im_2_flip_3\"]\n",
        "cmaps = [\"gray\", \"gray\", \"gray\", None, None, None]\n",
        "for ax, img, cm, title in zip(axs, images, cmaps, titles):\n",
        "    ax.imshow(img, cmap=cm)\n",
        "    ax.set_title(title)\n",
        "    ax.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_2_'></a>[Affine Transformations](#toc0_)\n",
        "\n",
        "- Affine transformations are a generalization of rigid transformations.\n",
        "- These transformations **preserve parallel lines** but not necessarily **distances** or **angles**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_2_1_'></a>[Scaling](#toc0_)\n",
        "\n",
        "- It changes the size of the object but preserves its shape if the scaling is uniform.\n",
        "- **Matrix Representation:**\n",
        "\n",
        "  $$\n",
        "  M = \\begin{bmatrix}\n",
        "  S_x & 0 & 0 \\\\\n",
        "  0 & S_y & 0 \\\\\n",
        "  0 & 0 & 1\n",
        "  \\end{bmatrix}, \\quad\n",
        "  M^{-1} = \\begin{bmatrix}\n",
        "  \\frac{1}{S_x} & 0 & 0 \\\\\n",
        "  0 & \\frac{1}{S_y} & 0 \\\\\n",
        "  0 & 0 & 1\n",
        "  \\end{bmatrix}\n",
        "  $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc3_2_1_1_'></a>[Using OpenCV](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "im_1_scale_1 = cv2.warpAffine(\n",
        "    im_1, np.array([[1.5, 0, 0], [0, 0.5, 0]], dtype=np.float32), dsize=(im_1.shape[1], im_1.shape[0])\n",
        ")\n",
        "\n",
        "im_1_scale_2 = cv2.warpAffine(\n",
        "    im_1, np.array([[1, 0, 0], [0, 1.5, 0]], dtype=np.float32), dsize=(im_1.shape[1], im_1.shape[0])\n",
        ")\n",
        "\n",
        "im_1_scale_3 = cv2.warpAffine(\n",
        "    im_1, np.array([[1.5, 0, 0], [0, 1.5, 0]], dtype=np.float32), dsize=(im_1.shape[1], im_1.shape[0])\n",
        ")\n",
        "\n",
        "im_2_scale_1 = cv2.warpAffine(\n",
        "    im_2, np.array([[1.5, 0, 0], [0, 0.5, 0]], dtype=np.float32), dsize=(im_2.shape[1], im_2.shape[0])\n",
        ")\n",
        "\n",
        "im_2_scale_2 = cv2.warpAffine(\n",
        "    im_2, np.array([[1, 0, 0], [0, 1.5, 0]], dtype=np.float32), dsize=(im_2.shape[1], im_2.shape[0])\n",
        ")\n",
        "\n",
        "im_2_scale_3 = cv2.warpAffine(\n",
        "    im_2, np.array([[1.5, 0, 0], [0, 1.5, 0]], dtype=np.float32), dsize=(im_2.shape[1], im_2.shape[0])\n",
        ")\n",
        "\n",
        "# plot\n",
        "fig, axs = plt.subplots(1, 6, figsize=(18, 4), layout=\"compressed\")\n",
        "images = [im_1_scale_1, im_1_scale_2, im_1_scale_3, im_2_scale_1, im_2_scale_2, im_2_scale_3]\n",
        "titles = [\"im_1_scale_1\", \"im_1_scale_2\", \"im_1_scale_3\", \"im_2_scale_1\", \"im_2_scale_2\", \"im_2_scale_3\"]\n",
        "cmaps = [\"gray\", \"gray\", \"gray\", None, None, None]\n",
        "for ax, img, cm, title in zip(axs, images, cmaps, titles):\n",
        "    ax.imshow(img, cmap=cm)\n",
        "    ax.set_title(title)\n",
        "    ax.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_2_2_'></a>[Shear](#toc0_)\n",
        "\n",
        "- It changes the shape of the object but preserves its area.\n",
        "- **Matrix Representation:**\n",
        "  - Vertical Shear:\n",
        "  $$\n",
        "  M = \\begin{bmatrix}\n",
        "  1 & 0 & 0 \\\\\n",
        "  h_y & 1 & 0 \\\\\n",
        "  0 & 0 & 1\n",
        "  \\end{bmatrix}, \\quad\n",
        "  M^{-1} = \\begin{bmatrix}\n",
        "  1 & 0 & 0 \\\\\n",
        "  -h_y & 1 & 0 \\\\\n",
        "  0 & 0 & 1\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "\n",
        "  - Horizontal Shear:\n",
        "  $$\n",
        "  M = \\begin{bmatrix}\n",
        "  1 & h_x & 0 \\\\\n",
        "  0 & 1 & 0 \\\\\n",
        "  0 & 0 & 1\n",
        "  \\end{bmatrix}, \\quad\n",
        "  M^{-1} = \\begin{bmatrix}\n",
        "  1 & -h_x & 0 \\\\\n",
        "  0 & 1 & 0 \\\\\n",
        "  0 & 0 & 1\n",
        "  \\end{bmatrix}\n",
        "  $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc3_2_2_1_'></a>[Using OpenCV](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "im_1_shear_1 = cv2.warpAffine(\n",
        "    im_1,\n",
        "    np.array([[1, 0, 0], [0.2, 1, 0]], dtype=np.float32),\n",
        "    dsize=(im_1.shape[1], im_1.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "\n",
        "im_1_shear_2 = cv2.warpAffine(\n",
        "    im_1,\n",
        "    np.array([[1, 0.2, 0], [0, 1, 0]], dtype=np.float32),\n",
        "    dsize=(im_1.shape[1], im_1.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "\n",
        "im_1_shear_3 = cv2.warpAffine(\n",
        "    im_1,\n",
        "    np.array([[1, 0.4, 0], [0.4, 1, 0]], dtype=np.float32),\n",
        "    dsize=(im_1.shape[1], im_1.shape[0]),\n",
        "    borderMode=cv2.BORDER_REPLICATE,\n",
        ")\n",
        "\n",
        "im_2_shear_1 = cv2.warpAffine(\n",
        "    im_2,\n",
        "    np.array([[1, 0, 0], [0.2, 1, 0]], dtype=np.float32),\n",
        "    dsize=(im_2.shape[1], im_2.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "\n",
        "im_2_shear_2 = cv2.warpAffine(\n",
        "    im_2,\n",
        "    np.array([[1, 0.2, 0], [0, 1, 0]], dtype=np.float32),\n",
        "    dsize=(im_2.shape[1], im_2.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "\n",
        "im_2_shear_3 = cv2.warpAffine(\n",
        "    im_2,\n",
        "    np.array([[1, 0.4, 0], [0.4, 1, 0]], dtype=np.float32),\n",
        "    dsize=(im_2.shape[1], im_2.shape[0]),\n",
        "    borderMode=cv2.BORDER_REPLICATE,\n",
        ")\n",
        "\n",
        "# plot\n",
        "fig, axs = plt.subplots(1, 6, figsize=(18, 4), layout=\"compressed\")\n",
        "images = [im_1_shear_1, im_1_shear_2, im_1_shear_3, im_2_shear_1, im_2_shear_2, im_2_shear_3]\n",
        "titles = [\"im_1_shear_1\", \"im_1_shear_2\", \"im_1_shear_3\", \"im_2_shear_1\", \"im_2_shear_2\", \"im_2_shear_3\"]\n",
        "cmaps = [\"gray\", \"gray\", \"gray\", None, None, None]\n",
        "for ax, img, cm, title in zip(axs, images, cmaps, titles):\n",
        "    ax.imshow(img, cmap=cm)\n",
        "    ax.set_title(title)\n",
        "    ax.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_3_'></a>[Projective Transformations (Homography)](#toc0_)\n",
        "\n",
        "- They preserve straight lines but do not preserve parallelism, distances, or angles.\n",
        "- These transformations are used to model perspective changes, such as when viewing a scene from a different angle.\n",
        "- They do not have a predefined matrix structure with fixed parameters.\n",
        "\n",
        "  $$\n",
        "  M = \\begin{bmatrix}\n",
        "  h_{11} & h_{12} & h_{13} \\\\\n",
        "  h_{21} & h_{22} & h_{23} \\\\\n",
        "  h_{31} & h_{32} & h_{33}\n",
        "  \\end{bmatrix}\n",
        "  $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_3_1_'></a>[Perspective](#toc0_)\n",
        "\n",
        "**Examples:**\n",
        "- Perspective Tilt\n",
        "  $$\n",
        "  M = \\begin{bmatrix}\n",
        "  1 & 0 & 0 \\\\\n",
        "  0 & 1 & 0 \\\\\n",
        "  0.001 & 0.001 & 1\n",
        "  \\end{bmatrix}, \\quad\n",
        "  M^{-1} = \\begin{bmatrix}\n",
        "  1 & 0 & 0 \\\\\n",
        "  0 & 1 & 0 \\\\\n",
        "  -0.001 & -0.001 & 1\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "  \n",
        "- Perspective Scaling\n",
        "  $$\n",
        "  M = \\begin{bmatrix}\n",
        "  0.8 & 0 & 0 \\\\\n",
        "  0 & 0.8 & 0 \\\\\n",
        "  0.0005 & 0.0005 & 1\n",
        "  \\end{bmatrix}, \\quad\n",
        "  M^{-1} = \\begin{bmatrix}\n",
        "  1.25 & 0 & 0 \\\\\n",
        "  0 & 1.25 & 0 \\\\\n",
        "  -0.000625 & -0.000625 & 1\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "  \n",
        "- Perspective Rotation\n",
        "  $$\n",
        "  M = \\begin{bmatrix}\n",
        "  \\cos \\theta & -\\sin \\theta & 0 \\\\\n",
        "  \\sin \\theta & \\cos \\theta & 0 \\\\\n",
        "  0.0005 & 0.0005 & 1\n",
        "  \\end{bmatrix}, \\quad\n",
        "  M^{-1} = \\begin{bmatrix}\n",
        "  \\cos \\theta & \\sin \\theta & 0 \\\\\n",
        "  -\\sin \\theta & \\cos \\theta & 0 \\\\\n",
        "  -0.0005 \\cos \\theta + 0.0005 \\sin \\theta & -0.0005 \\sin \\theta - 0.0005 \\cos \\theta & 1\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "  \n",
        "- Perspective Translation\n",
        "  $$\n",
        "  M = \\begin{bmatrix}\n",
        "  1 & 0 & 100 \\\\\n",
        "  0 & 1 & 50 \\\\\n",
        "  0.0005 & 0.0005 & 1\n",
        "  \\end{bmatrix}, \\quad\n",
        "  M^{-1} = \\begin{bmatrix}\n",
        "  1 & 0 & -100 \\\\\n",
        "  0 & 1 & -50 \\\\\n",
        "  -0.0005 & -0.0005 & 1\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "  \n",
        "- Warping for Image Stitching\n",
        "  $$\n",
        "  M = \\begin{bmatrix}\n",
        "  0.9 & -0.1 & 50 \\\\\n",
        "  0.1 & 0.9 & 20 \\\\\n",
        "  0.0002 & 0.0002 & 1\n",
        "  \\end{bmatrix}, \\quad\n",
        "  M^{-1} = \\begin{bmatrix}\n",
        "  0.9 & 0.1 & -50 \\cdot 0.9 - 20 \\cdot 0.1 \\\\\n",
        "  -0.1 & 0.9 & -50 \\cdot (-0.1) - 20 \\cdot 0.9 \\\\\n",
        "  0.0002 & 0.0002 & 0.9 \\cdot 0.9 - (-0.1) \\cdot 0.1\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc3_3_1_1_'></a>[Using OpenCV](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "H_perspective_1 = np.array([[1, 0, 0], [0, 1, 0], [0.001, 0.001, 1]], dtype=np.float32)\n",
        "H_perspective_2 = np.array([[1, 0, 0], [0, 1, 0], [0.002, 0.002, 1]], dtype=np.float32)\n",
        "H_perspective_3 = np.array([[1, 0, 0], [0, 1, 0], [0.005, 0.005, 1]], dtype=np.float32)\n",
        "\n",
        "im_1_perspective_1 = cv2.warpPerspective(\n",
        "    im_1,\n",
        "    H_perspective_1,\n",
        "    dsize=(im_1.shape[1], im_1.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "\n",
        "im_1_perspective_2 = cv2.warpPerspective(\n",
        "    im_1,\n",
        "    H_perspective_2,\n",
        "    dsize=(im_1.shape[1], im_1.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "\n",
        "im_1_perspective_3 = cv2.warpPerspective(\n",
        "    im_1,\n",
        "    H_perspective_3,\n",
        "    dsize=(im_1.shape[1], im_1.shape[0]),\n",
        "    borderMode=cv2.BORDER_REPLICATE,\n",
        ")\n",
        "\n",
        "im_2_perspective_1 = cv2.warpPerspective(\n",
        "    im_2,\n",
        "    H_perspective_1,\n",
        "    dsize=(im_2.shape[1], im_2.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "\n",
        "im_2_perspective_2 = cv2.warpPerspective(\n",
        "    im_2,\n",
        "    H_perspective_2,\n",
        "    dsize=(im_2.shape[1], im_2.shape[0]),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        ")\n",
        "\n",
        "im_2_perspective_3 = cv2.warpPerspective(\n",
        "    im_2,\n",
        "    H_perspective_3,\n",
        "    dsize=(im_2.shape[1], im_2.shape[0]),\n",
        "    borderMode=cv2.BORDER_REPLICATE,\n",
        ")\n",
        "\n",
        "# Plot\n",
        "fig, axs = plt.subplots(1, 6, figsize=(18, 4), layout=\"compressed\")\n",
        "images = [\n",
        "    im_1_perspective_1,\n",
        "    im_1_perspective_2,\n",
        "    im_1_perspective_3,\n",
        "    im_2_perspective_1,\n",
        "    im_2_perspective_2,\n",
        "    im_2_perspective_3,\n",
        "]\n",
        "titles = [\n",
        "    \"im_1_perspective_1\",\n",
        "    \"im_1_perspective_2\",\n",
        "    \"im_1_perspective_3\",\n",
        "    \"im_2_perspective_1\",\n",
        "    \"im_2_perspective_2\",\n",
        "    \"im_2_perspective_3\",\n",
        "]\n",
        "cmaps = [\"gray\", \"gray\", \"gray\", None, None, None]\n",
        "for ax, img, cm, title in zip(axs, images, cmaps, titles):\n",
        "    ax.imshow(img, cmap=cm)\n",
        "    ax.set_title(title)\n",
        "    ax.axis(\"off\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "author_email": "AmirhosseinHeydari78@gmail.com",
    "author_github": "https://github.com/mr-pylin",
    "author_name": "Amirhossein Heydari",
    "kernelspec": {
      "display_name": "media-processing-workshop-sxUc00b2-py3.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "origin_repo": "https://github.com/mr-pylin/media-processing-workshop"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
